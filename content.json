{"pages":[{"title":"archives","permalink":"https://kricsleo.github.io/archives/index.html","text":""},{"title":"categories","permalink":"https://kricsleo.github.io/categories/index.html","text":""}],"posts":[{"title":"yahoo-best-practices-for-speeding-up-your-Web-Site","permalink":"https://kricsleo.github.io/yahoo-best-practices-for-speeding-up-your-Web-Site/","text":"yahoo 的网站优化实践军规yahoo 的网站优化军规已经出来很多年了, 我是最近才看到, 然后做一下笔记, 也比对一下自己现在做的怎么样. 原文地址: Best Practices for Speeding Up Your Web Site掘金上也有不少好文章来详细阐述的: 前端性能优化之雅虎35条军规 减少 HTTP 请求 使用 CDN 添加Expires或者Cache-Control缓存控制头 对除了图片和 PDF 这类文件以外的文件(如 CSS, JS, 或者 application/json等)使用 Gzip 样式放在头部 脚本放在底部 避免使用 CSS 表达式 脚本和样式使用外链形式 减少 DNS 查询 压缩脚本和样式文件 避免重定向 移除重复的脚本 配置 ETags 缓存 Ajax 数据 尽早刷新缓冲区 Ajax 尽量使用 GET 方式 延迟加载暂时不必要的资源 预先加载可能用到的资源 减少页面 DOM 元素数量 资源分散到不同的域上 减少 iframes 的数量 避免404 减少 cookie 大小 把资源部署到不用发送 cookie 的域上 减少访问 DOM 的次数 合适处理事件绑定 使用&lt;link&gt;而不是@import CSS 中避免使用 AlphaImageLoader 优化及压缩图片 优化 CSS 雪碧图 选用尺寸刚好合适的图片, 不要缩放使用 使用小的 favicon, 同时注意缓存该文件 文件大小不要超过25k(这一条目前来说可能过时了, 后期查证) 把多个文件合并成一个文件, 减少 HTTP 数量 避免空src的img"},{"title":"nginx","permalink":"https://kricsleo.github.io/nginx/","text":"nginx 的部署与配置笔记现在很多网站用的都是 nginx 作为代理服务器, 所以为了进行 web 性能的优化, 自然也要折腾一下 nginx 的配置的. 我的远程主机环境: # linux 通用查看系统版本lsb_release -a# LSB Version: :core-4.1-amd64:core-4.1-noarch# Distributor ID: CentOS# Description: CentOS Linux release 7.4.1708 (Core)# Release: 7.4.1708# Codename: Core nginx 的安装参考文章: nginx服务器详细安装过程（使用yum 和 源码包两种安装方式，并说明其区别） 安装 nginx 前要先安装 nginx 编译及运行的依赖环境 # yum -y install gcc gcc-c++ make libtool zlib zlib-devel openssl openssl-devel pcre pcre-devel nginx 一般来说有两种安装方式: yum安装和源码包自行编译安装, 新手推荐前一种, 想折腾的话或者老手使用后一种 yum安装是在线安装, 好处是简单方便, 不易出错, 但是缺点是使用的其实是别人编译好的二进制版本, 不能自定义其中加载的模块, 不过目前来 centos 官方提供的那个版本还是比较实用的 # 首先把 nginx 的源加载 yum 里面vi /etc/yum.repo.d/nginx.repo 然后在文件里添加如下内容 [nginx]name=nginx repobaseurl=http://nginx.org/packages/centos/$releasever/$basearch/gpgcheck=0enabled=1 然后就可以使用yum install nginx安装最新版了, 也可以yum install nginx-1.6.3安装指定版本.安装之后可以使用rpm -ql nginx查看安装目录, 卸载时使用rpm -e nginx, 如果因为依赖包导致卸载失败，可以尝试rpm -e --nodeps nginx来卸载，这个命令相当于强制卸载，不考虑依赖问题。 使用这种方式安装之后 nginx 会被自动添加到系统服务里面, 也就是说可以直接使用serivce nginx {option}来启动或者关闭 nginx. 源码包编译安装, 好处是编译的时候是根据你本机的条件和环境进行编译的, 性能更好一些,同时也可以在编译的时候自定义模块 # 可以获取指定版本的 nginx, 可以使用 -P 指定下载目录wget -c &lt;-P&gt; &lt;destDir&gt; https://nginx.org/download/nginx-1.11.6.tar.gz# 然后解压下载的压缩包, 可以使用 -C 指定解压目录tar -zxvf nginx-1.11.6.tar.gz &lt;-C&gt; &lt;destDir&gt;# 然后进行解压后的目录cd nginx-1.11.6# 然后先进行编译配置, 直接使用 ./configure 表示使用默认配置, 也可以在后面附加参数表示一些其他的模块之类的, 请具体根据使用来配置./configure# 然后进行编译安装make &amp;&amp; make install 一般来说编译安装后的二进制文件都在/usr/local/目录下, 如果需要卸载的话直接在这里删除对应的目录就可以, 同时启动 nginx 也可以在这里使用二进制文件直接启动, 见下文 nginx 的使用. 使用源码包编译安装的好处是是可以后期为 nginx 添加各种各样的模块. 比如我在第一次安装的并没有安装 SSL 相关的模块, 后期我想开启 SSL, 这个时候就需要给 nginx 添加ngx_http_ssl_module模块.注意在添加的时候为了保留之前的一些配置, 我们需要先查看之前编译的configure配置项, 你可以使用./nginx -V来查看, 我的输出如下: nginx version: nginx/1.15.2built by gcc 4.8.5 20150623 (Red Hat 4.8.5-28) (GCC)configure arguments: --prefix=/usr/local/nginx 可以看到我的版本是1.15.2, 我之前的编译参数是--prefix=/usr/local/nginx, 也就是只制定了 nginx 的配置文件路径, 那么我现在需要在原来的基础上添加新的参数--with-http_ssl_module才能编译一个新的带有 SSL 模块的 nginx 二进制文件. 找到原来的源码包, 没有的话就下载一个跟你现在用的是同一个版本的 nginx 源码包, 然后解压, 进入解压后的目录 在解压后的目录执行编译前的配置./configure --prefix=/usr/local/nginx --with-http_ssl_module, 注意这里一定要把你原来的参数都拷贝过来, 然后在后面添加新的, 要不然编译出来的东西可能跟你原来的不兼容 接下来执行make, 这里可千万别手快执行make &amp;&amp; make install, 如果你insall了那么你之前的 nginx 的配就都丢了, 所以我们这里只需要编译出一个可用的 nginx 的二进制版本, 然后手动替换掉原来的即可. 新编译的 nginx 文件在 objs/nginx # 将原来的`/usr/local/nginx/sbin/nginx`备份cp /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginx.back# 请先停止 nginx 服务, 然后再删除原来的 nginx 文件rm -f /usr/local/nginx/sbin/nginx# 把新的 nginx 文件拷贝到原来的地方cp objs/nginx /usr/local/nginx/sbin/nginx 然后再正常启动 nginx 即可使得新的功能生效 nginx 的使用有两种方式启动 nginx, 但是后一种相对来说方便一些, 推荐使用. 直接在安装目录使用 nginx 的命令进行 nginx 的启动和关闭 # 启动/usr/local/nginx/sbin/nginx# 检查默认配置文件/usr/nginx/sbin/nginx -t# 检查指定配置文件/usr/nginx/sbin/nginx -t -c &#123;configFileDir&#125;# 使用指定配置文件启动 nginx/usr/nginx/sbin/nginx -c &#123;configFileDir&#125;# 关闭 stop 表示立即停止, quit 表示平滑停止, reopen 表示重新启动 reload 不中断服务重新加载配置文件/usr/local/nginx/sbin/nginx -s &#123;stop|quit|reload|reopen&#125;# 通过进程查看及关闭 nginxps -ef | grep nginx# 从容停止Nginx：kill -QUIT 主进程号# 快速停止Nginx：kill -TERM 主进程号# 强制停止Nginx：kill -9 nginx 配置 nginx 的启动和关闭到系统服务 在/etc/init.d/目录下新建文件nginx, 把这些内容拷贝到文件中 赋予脚本可执行权限chmod +x /etc/init.d/nginx 修改系统服务之后使用systemctl daemon-reload重新加载一下才能生效 可以吧 nginx 服务配置成开机启动 chkconfig nginx on 有如下命令可执行: service nginx &#123;start|stop|status|restart|condrestart|try-restart|reload|force-reload|configtest&#125;# 参数说明# start 启动 nginx# stop 停止 nginx# status 查看 nginx 的状态# restart 重启 nginx, 会先中断 nginx, 然后重新启动, 如果配置文件有误, 那么将无法启动 nginx# reload 重新加载配置文件, 不会中断 nginx 服务, 如果新的配置文件有误, 那么会使用上一次正确的配置文件, 保证服务正常运行# configtest 检查配置文件是否正确 nginx 的配置nginx 的配置相对来说是比较繁杂的, 所以我放到最下面来说, 后期持续补充.参考文档: nginx服务器安装及配置文件详解 gzip压缩功能设置gzip 相关配置可放在 http{} 或 server{} 或 location{} 层级，若不同层级有重复设置优先级为 location{} &gt; server{} &gt; http{}gzip 配置参数如下 # 打开 gzip 压缩gzip on;# 进行压缩的最小文件大小, 小于这个大小的不进行压缩gzip_min_length 1k;# 压缩结果数据流存储所用空间，下面表示以16k为单位，按照原始数据大小以16k为单位的4倍申请内存。默认值是申请跟原始数据相同大小的内存空间去存储gzip压缩结果。gzip_buffers 4 16k;# 采用http协议版本 默认是1.1 ，对于1.0的请求不会压缩，如果设置成1.0，表示http1.0以上 的版本都会压缩。(如果使用了 proxy_pass 进行反向代理，那么nginx和后端的 upstream server之间默认是用 HTTP/1.0协议通信的。)gzip_http_version 1.0;# 压缩级别（1~9，一般为平衡文件大小和CPU使用，5是常用值，当然跟实际机器的情况有关） 级别越高, 压缩比越大, 但是 cpu 的性能消耗也越高, 同时在压缩到一定程度之后即使再进行压缩文件体积也不会再有明显的减小了. 一般取值在4~6, 这里有一组测试数据; text/html - phpinfo():; 0 55.38 KiB (100.00% of original size); 1 11.22 KiB ( 20.26% of original size); 2 10.89 KiB ( 19.66% of original size); 3 10.60 KiB ( 19.14% of original size); 4 10.17 KiB ( 18.36% of original size); 5 9.79 KiB ( 17.68% of original size); 6 9.62 KiB ( 17.37% of original size); 7 9.50 KiB ( 17.15% of original size); 8 9.45 KiB ( 17.06% of original size); 9 9.44 KiB ( 17.05% of original size); application/x-javascript - jQuery 1.8.3 (Uncompressed):; 0 261.46 KiB (100.00% of original size); 1 95.01 KiB ( 36.34% of original size); 2 90.60 KiB ( 34.65% of original size); 3 87.16 KiB ( 33.36% of original size); 4 81.89 KiB ( 31.32% of original size); 5 79.33 KiB ( 30.34% of original size); 6 78.04 KiB ( 29.85% of original size); 7 77.85 KiB ( 29.78% of original size); 8 77.74 KiB ( 29.73% of original size); 9 77.75 KiB ( 29.74% of original size)gzip_comp_level 5;# 压缩文件类型（默认总是压缩 text/html类型，其中特别说明的是application/javascript和text/javascript最好都加上，若页面script标签的type不同则有可能发生部分js文件不会压缩，默认type为application/javascript） 一般来说对图片不进行压缩, 因为图片压缩比较耗时而且压缩比也很低gzip_types application/atom+xml application/javascript application/json application/rss+xml application/vnd.ms-fontobject application/x-font-ttf application/x-web-app-manifest+json application/xhtml+xml application/xml font/opentype image/svg+xml image/x-icon text/css text/plain text/javascript text/x-component;# 代表缓存压缩和原始版本资源，避免客户端因Accept-Encoding不支持gzip而发生错误的现象（现在一般都采用gzip） 开启此参数以后会在返回头里面看到一个 Vary 字段, 里面会有一个 Accept-Encoding 字段, 代表此资源有着多个版本, 比如 gzip 压缩版 和不压缩版, 关于 Vary 字段的解释可以查看这里: https://imququ.com/post/vary-header-in-http.htmlgzip_vary on;# 禁止IE6进行gzip压缩（当然现在已经基本没有人使用IE6了）gzip_disable &quot;MSIE [1-6]&quot;; 参考文章:Nginx配置指北之gzip HTTPS 配置如果要启用 nginx 的 SSL 配置, 那么需要 nginx 安装的时候包含了http_ssl_module模块, 默认 nginx 是不会安装这个模块的, 可以使用./nginx -V查看 nginx 安装时的配置参数里面有没有这个模块, 如果没有这个模块, 那么我们可以按照上面编译安装的步骤编译一个新的包含这个模块的 nginx 二进制文件, 然后替换掉现在的即可. 然后在 server{} 层级中加入如下配置(请根据自己情况修改) 详细配置说明可以查看Nginx 配置 HTTPS 服务器 # 网站域名server_name example.com# 表示监听 443 端口, 协议为 ssllisten 443 ssl;# 证书文件的位置ssl_certificate example.com.crt;# 证书私钥文件的位置ssl_certificate_key example.com.key;# SSL 协议具体版本ssl_protocols TLSv1 TLSv1.1 TLSv1.2;# SSL 算法ssl_ciphers HIGH:!aNULL:!MD5; 上面的配置是必须的, 另外还有一些配置依据个人情况可以添加. 另外你需要首先申请自己的网站证书才行. 例如安全协议的具体版本ssl_protocols和算法ssl_ciphers, 由于这两个命令的默认值已经好几次发生了改变，因此不建议显性定义，除非有需要额外定义的值，如定义 D-H 算法, 具体查看Nginx 配置 HTTPS 服务器进行配置. HTTP/2.0 配置既然已经上了 HTTPS, 那么干脆一鼓作气上到 HTTP/2.0, 根据规范来说 HTTP/2.0 是不需要依赖 HTTPS 的, 但是目前的现状来说, 各个浏览器都是要求在 HTTPS 的环境中才能启用 HTTP/2.0. nginx 要启用 HTTP/2.0 需要http_v2_module和http_ssl_module这两个模块, 如果之前的编译安装时没有这两个模块, 那么就需要重新加上参数再编译一份. 这里省略我再次编译的过程(同上), 只是编译参数改为./configure --prefix=/usr/local/nginx --with-http_ssl_module --with-http_v2_module. 更新了 nginx 之后就要在 nginx 的配置文件里面开启 HTTP/2.0, 告诉客户端我们支持 HTTP/2.0 了. 配置很简单, 只需要在之前的listen字段中增加一个http2即可. 目前 IE11+ 以及其他主流浏览器都已经支持 HTTP/2.0, 而且就算客户端不支持结果也是正常的使用现在的 HTTP/1.1, 不会影响页面访问. 例如: # 改为listen 443 ssl http2; 这里有一个小坑, 在启用 HTTP/2.0 之前, 我们可能把80端口和443端口放在同一个 server 里面监听, 但是如果我们想要启用 HTTP/2.0, 那么就必须把80端口拿出去单独放在一个 server 里面, 监听80端口的并不能启用 HTTP/2.0, 所以如果你想要为网站同时启用 HTTP 和 HTTP/2.0, 那么你在 nginx 配置文件里面就至少需要写两个 server, 一个监听80端口, 另一个监听443端口. 关于 HTTP/2.0 的相关文章, 尤其是升级及浏览器兼容问题可以查看屈屈的博客谈谈 HTTP/2 的协议协商机制. 我自己的总结如下: 在浏览器和服务端建立 TCP 连接之后, 如果是 http 协议, 那么此时就可以进行数据传输了, 如果是 https 协议, 那么就还需要建立安全的 TLS 连接, 由于 TLS 有多个版本, 也有不同的加密算法, 那么浏览器和服务器就需要进行协商, 确定一个版本和算法等信息来进行数据加密, 协商是通过握手来实现的, 首先客户端会发送一个client hello握手信息, 里面包含了客户端支持的各种协议以及算法等信息, 然后服务端收到这个信息之后会在这些支持的协议里面选出自己也支持的协议和算法, 然后确定最后要采用的协议和算法(例如 HTTP/2.0 &gt; HTTP/1.1)通过server hello握手信息返给客户端, 这样双方就确定了一组对应的协议和算法进行后续的数据传输. 所以可以看到服务器在升级到了 HTTP/2.0 之后, 如果用户使用的浏览器也支持 HTTP/2.0, 那么协商之后双方就会无痛升级到 HTTP/2.0 进行通信, 享受 HTTP/2.0 带来的种种好处, 而如果用户的浏览器不支持 HTTP/2.0, 那么协商之后就会采用原来的 HTTP/1.1进行通信, 并不会影响现在的业务."},{"title":"length-of-url","permalink":"https://kricsleo.github.io/length-of-url/","text":"关于URL长度的笔记在了解 cookie 的大小限制的时候看到了一片记录关于 URL 长度的博客, 所以收藏了下来. 原文: GET传参最大长度的理解误区作者: zhongxia 为防止原文丢失, 这里直接转载一份. GET传参最大长度的理解误区时间：2016-10-17 14:59:38作者：zhongxia 零、总结文章数据来源于网络，可能存在变动，但是原理是一样的。 HTTP 协议 未规定 GET 和POST的长度限制GET的最大长度显示是因为 浏览器和 web服务器限制了 URI的长度不同的浏览器和WEB服务器，限制的最大长度不一样要支持IE，则最大长度为2083byte，若只支持Chrome，则最大长度 8182byte一、误解大家都知道http 中 存在 GET 和 POST 这两种最常用的请求方式。（PUT，DELETE不在本文讨论范围之内） 误解：HTTP 协议下的 Get 请求参数长度是有大小限制的，最大不能超过XX，而 Post 是无限制的。 1、首先即使有长度限制，也是限制的是整个 URI 长度，而不仅仅是你的参数值数据长度。 2、HTTP 协议从未规定 GET/POST 的请求长度限制是多少。 以下内容摘自 《关于 HTTP GET/POST 请求参数长度最大值的一个理解误区》， 文章时间为 2013年的。可能以当前最新的浏览器有出入 The HTTP protocol does not place any a priori limit on the length of a URI. Servers MUST be able to handle the URI of any resource they serve, and SHOULD be able to handle URIs of unbounded length if they provide GET-based forms that could generate such URIs. A server SHOULD return 414 (Request-URI Too Long) status if a URI is longer than the server can handle (see section 10.4.15).Note: Servers ought to be cautious about depending on URI lengths above 255 bytes, because some older client or proxy implementations might not properly support these lengths. 3、所谓的请求长度限制是由浏览器和 web 服务器决定和设置的，各种浏览器和 web 服务器的设定均不一样，这依赖于各个浏览器厂家的规定或者可以根据 web 服务器的处理能力来设定。 The limit is in MSIE and Safari about 2KB, in Opera about 4KB and in Firefox about 8KB, (255 bytes if we count very old browsers) . We may thus assume that 8KB is the maximum possible length and that 2KB is a more affordable length to rely on at the server side and that 255 bytes is the safest length to assume that the entire URL will come in.If the limit is exceeded in either the browser or the server, most will just truncate the characters outside the limit without any warning. Some servers however may send a HTTP 414 error. If you need to send large data, then better use POST instead of GET. Its limit is much higher, but more dependent on the server used than the client. Usually up to around 2GB is allowed by the average webserver. This is also configureable somewhere in the server settings. The average server will display a server-specific error/exception when the POST limit is exceeded, usually as HTTP 500 error. IE 和 Safari 浏览器 限制 2kOpera 限制4kFirefox 限制 8k（非常老的版本 256byte） 如果超出了最大长度，大部分的服务器直接截断，也有一些服务器会报414错误。 HTTP 1.1 defines Status Code 414 Request-URI Too Long for the cases where a server-defined limit is reached. You can see further details on RFC 2616. For the case of client-defined limits, there is no sense on the server returning something, because the server won’t receive the request at all. 详细可以看 RFC2616 The server is refusing to service the request because the Request-URI is longer than the server is willing to interpret. This rare condition is only likely to occur when a client has improperly converted a POST request to a GET request with long query information, when the client has descended into a URI “black hole” of redirection (e.g., a redirected URI prefix that points to a suffix of itself), or when the server is under attack by a client attempting to exploit security holes present in some servers using fixed-length buffers for reading or manipulating the Request-URI. 二、各个浏览器和web服务器的最大长度总结 以下内容摘自《GET请求中URL的最大长度限制总结》， 文章内容是 2016年9月，相对比较符合当前的最新现状。 在网上查询之后，浏览器和服务器对url长度都有限制，现总结如下。 浏览器1、IE IE浏览器（Microsoft Internet Explorer） 对url长度限制是2083（2K+53），超过这个限制，则自动截断（若是form提交则提交按钮不起作用）。 2、firefox firefox（火狐浏览器）的url长度限制为 65 536字符，但实际上有效的URL最大长度不少于100,000个字符。 3、chrome chrome（谷歌）的url长度限制超过8182个字符返回本文开头时列出的错误。 4、Safari Safari的url长度限制至少为 80 000 字符。 5、Opera Opera 浏览器的url长度限制为190 000 字符。Opera 9 地址栏中输入190 000字符时依然能正常编辑。 服务器1、Apache Apache能接受url长度限制为8 192 字符 2、IIS Microsoft Internet Information Server(IIS)能接受url长度限制为16 384个字符。这个是可以通过修改的（IIS7） configuration/system.webServer/security/requestFiltering/requestLimits@maxQueryStringsetting.&lt;requestLimits maxQueryString=&quot;length&quot;/&gt; 3、Perl HTTP::Daemon Perl HTTP::Daemon 至少可以接受url长度限制为8000字符。Perl HTTP::Daemon中限制HTTP request headers的总长度不超过16 384字节(不包括post,file uploads等)。但当url超过8000字符时会返回413错误。这个限制可以被修改，在Daemon.pm查找16×1024并更改成更大的值。 4、ngnix 可以通过修改配置来改变url请求串的url长度限制。 client_header_buffer_size 默认值：client_header_buffer_size 1k large_client_header_buffers默认值 ：large_client_header_buffers 4 4k/8k 由于jsonp跨域请求只能通过get请求，url长度根据浏览器及服务器的不同而有不同限制。若要支持IE的话，url长度限制为2083字符，若是中文字符的话只有2083/9=231个字符。若是Chrome浏览器支持的最大中文字符只有8182/9=909个。 三、参考文章GET请求中URL的最大长度限制总结关于 HTTP GET/POST 请求参数长度最大值的一个理解误区"},{"title":"service-worker","permalink":"https://kricsleo.github.io/service-worker/","text":"service-workerservice worker (服务工作线程)可以为网页提供离线访问的功能, 除此之外当然也有推送通知和后台同步的功能, 它是一种 JavaScript 线程, 可以独立在主线程外独立运行, 但是无法直接访问和操作 DOM , 服务工作线程通过响应 postMessage 接口发送的消息来与其控制的页面通信, 页面可在必要时对 DOM 执行操作. 使用前提网站必须是 https 的, 本地开发的话也可以使用 localhost 和 127.0.0.1 兼容性目前来说 IE 系列都不支持, Edge 从17开始支持, 其他PC段浏览器基本都没有太大问题, 移动端 IOS Safari 从11.4开始支持, 安卓浏览器从67(发布于2017.03)开始支持, QQ和UC等都已经支持. 一般来说在注册 service worker 之前可以先通过&#39;serviceWorker&#39; in navigator检查一下是否支持, 不支持则不进行注册. 注册 service worker如果在页面加载完成之前就直接注册 service worker, 会影响到页面的加载过程, 所以推荐的做法是在load事件里面去注册 if ('serviceWorker' in navigator) &#123; window.addEventListener('load', function() &#123; navigator.serviceWorker.register('/sw.js').then(function(registration) &#123; // Registration was successful console.log('ServiceWorker registration successful with scope: ', registration.scope); &#125;).catch(function(err) &#123; // registration failed :( console.log('ServiceWorker registration failed: ', err); &#125;); &#125;);&#125; 需要注意的是 service worker 文件的位置决定了这个它能控制的页面和请求范围, 最多只能控制到本目录, 可以通过scope参数指定目录, 但是也不能高于所在目录, 所以经常会把这个文件直接放在根目录, 这样就可以控制到整个域下面的文件和请求. chrome 里面可以通过chrome://serviceworker-internals来查看已经开启的 service worker, 在控制台的 Application 里的 Servie Worker 也可以查看. 安装 service worker页面在注册了 service worker 之后就可以到下一个生命周期install, 一般在这个生命周期里进行一些文件的缓存, 有如下三个过程: 打开缓存 缓存文件 确认所需文件是否全部缓存成功 const CACHE_NAME = 'my-site-cache-v1';const urlsToCache = [ '/', '/styles/main.css', '/script/main.js'];self.addEventListener('install', evt =&gt; &#123; // Perform install steps evt.waitUntil( caches.open(CACHE_NAME) .then(cache =&gt; &#123; console.log('Opened cache'); return cache.addAll(urlsToCache); &#125;) );&#125;); caches.open()用来打开一个特定名称的缓存, 你可以理解为名称空间, 将要被缓存的文件都会被存在这个空间里面.cache.addAll()用来缓存一个 url 列表的所有文件, 它会根据 url 创建对应的 request, 如果本地没有这个请求对应的 response, 那么就会发起请求拿到对应的 response, 然后以 requst 为键名, 对应的 response 为键值, 对响应数据进行缓存. 添加单个缓存 url 可使用cache.add().event.waitUntil()用来延长一个事件的生命周期, 例如在上面的调用中, 它延迟将被安装的worker视为 installing ，直到传递的 Promise 被成功地resolve. 这主要用于确保：服务工作线程在所有依赖的核心cache被缓存之前都不会被安装. 如果有文件缓存失败, 那么本次安装就会失败, 之后会自动重试. 激活 service worker当一个 service worker 被安装了以后在生命时间进入激活(activate)状态呢? 一般来说如果是首次加载此页面, 那么在安装install完成以后就会进入激活状态, 但是如果此页面之前被旧的 service worker 控制, 那么新的 service worker 会进入waiting状态, 等到此页面被关闭然后被重新打开的时候, 新的 servie worker 才会接管这个页面, 你也可以使用skipWaiting()使得新的 service worker 跳过waiting状态, 直接进入activate状态, 当新的 servie worker 进入activate状态以后, 如果页面是在新的 service worker 被激活之前就加载了的, 那么这个页面的请求仍然还不受 service worker 控制, 如果你希望之前打开或加载的页面也能收到新的 servie worker控制, 一种方式是你可以使用clients.claim()来使得新的 servie worker 控制还未受控制的页面, 另一种方式就是关闭并重新打开页面, 注意如果只是刷新本页面, 那么本页面仍然还是受原来的 service worker 控制的. 通过navigator.serviceWorker.controller(其将为null或一个服务工作线程实例)检测客户端是否受控制 缓存 fetch当 service worker 被安装以后, service worker 就可以拦截 fetch 请求, 可以在这个时候返回缓存中的数据, 如果没有对应的缓存的话, 你可以手动发起这个请求, 然后将请求的结果返回给页面, 这里的作用相当于一个网络代理. self.addEventListener('fetch', function(event) &#123; event.respondWith( caches.match(event.request) .then(function(response) &#123; // Cache hit - return response if (response) &#123; return response; &#125; // IMPORTANT: Clone the request. A request is a stream and // can only be consumed once. Since we are consuming this // once by cache and once by the browser for fetch, we need // to clone the response. var fetchRequest = event.request.clone(); return fetch(fetchRequest).then( function(response) &#123; // Check if we received a valid response if(!response || response.status !== 200 || response.type !== 'basic') &#123; return response; &#125; // IMPORTANT: Clone the response. A response is a stream // and because we want the browser to consume the response // as well as the cache consuming the response, we need // to clone it so we have two streams. var responseToCache = response.clone(); caches.open(CACHE_NAME) .then(function(cache) &#123; cache.put(event.request, responseToCache); &#125;); return response; &#125; ); &#125;) );&#125;); 对所有的 fetch 请求进行拦截, 然后在缓存中搜索这个 request, 如果找到了, 那么就直接返回之前缓存的对应的 response, 如果没有找到, 那么就需要手动发起一个同样的请求, 注意 resquest 和 response 都是流对象, 只能读取一次, 所以在上面的代码中需要复制clone()这个流一份, 然后才能再次使用, 当获得返回数据的时候, 判断是正常响应的数据 status === 200然后就把这个数据缓存一份备用, 同时这个数据也会给浏览器一份作为响应. 更新 service worker页面每次加载时都会下载一份 service worker 文件然后和以前的作对比, 如果发现不一样, 那么就会安装新的 service worker, 同时旧的不会被马上删除, 而是可以继续控制它已经控制的页面, 只是新打开的页面会被新的 service worker 接管, 当旧的页面全部都被关闭的时候, 旧的 service worker 就全面失效了, 新的 service worker 就是唯一的控制者了. 那么在新旧交替的一个时间, 新的 service worker 虽然已经安装完成, 且触发了 install 事件, 但是在旧的页面上会处于 waiting 状态, 如果希望新的 service worker 能够在安装后马上生效, 那么可以使用skipWaiting()来跳过 waiting 状态, 直接进入 activate 状态. 更新缓存有时候我们希望能够更新缓存, 让页面能够取到最新的数据. 手动更新缓存的方法 self.addEventListener('activate', function(event) &#123; var cacheWhitelist = ['pages-cache-v1', 'blog-posts-cache-v1']; event.waitUntil( caches.keys().then(function(cacheNames) &#123; return Promise.all( cacheNames.map(function(cacheName) &#123; if (cacheWhitelist.indexOf(cacheName) === -1) &#123; return caches.delete(cacheName); &#125; &#125;) ); &#125;) );&#125;); 我们可以在 service worker 处于 activate 状态之后设置一份白名单, 然后遍历缓存, 凡是不是这个白名单里面的缓存都删除掉, 那就可以起到手动更新缓存的作用. 三大特性研究参考文章: 【PWA学习与实践】(8)使用Service Worker进行后台同步 - Background Sync 资源请求(fetch)这一点在上面的文件和请求缓存里面已经涉及到了. 推送通知(push)推动通知(push)依赖Notification API和PUSH API, 目前来说这两个 API 的兼容性也不容乐观, 基本没法实用, 所以暂时不做多的讨论. 如果想要了解更多, 请查看上面的那篇文章. 后台同步(sync)后台同步(sync)依赖于Background Sync API, 目前来说这个 API 的兼容惨不忍睹, 几乎只有 chrome 自家的产品支持. 所以在目前的阶段, 暂时不多去讨论后台同步这个部分. 可以查看上面那篇文章了解更多. 参考文档服务工作线程"},{"title":"web-font","permalink":"https://kricsleo.github.io/web-font/","text":"网页字体加载过程及优化现在很多网站为了视觉效果都在使用在线字体, 系统自带的字体可以直接使用, 但是自定义的在线字体需要通过@font-face来加载. 这里主要结合我自己的博客的实践来记录一下网页字体的加载过程及优化. 在线字体格式目前来说有如下四种字体格式, WOFF, SVG, EOT和OTF/TTF, 兼容性可以在caniuse上面关注最新的情况 WOFFWOFF全称是”Web Open Font Format”, 这种字体专门用于网络, 是由 Mozilla 与 Type Supply, LettError 及其他组织协同开发的一种网页字体格式, 使用了OpenType (OTF)和TrueType (TTF)字体里的存储结构和压缩算法, 所以在传输的时候可以节省带宽, 加载更快, 目前兼容性来说, IE9+以及其他绝大部分浏览器都可以使用, 是现在的大潮流, 推荐使用这种字体 OTF/TTF全称是”OpenType Font”和”TrueType Font”, 是Windows 和 Mac 系统最常用的字体格式, 不过容易被非法复制, 目前的支持情况来说IE9+以上是部分支持, 其余的主流浏览器都没问题. SVGSVG全称是”Scalable Vector Graphics”, 是一种用矢量图格式改进的字体格式，体积上比矢量图更小. 兼容性极差, 基本上只有safari系列支持 EOT微软自家开发的字体, 也只有IE全系列支持, 连Edge都不支持 关于字体的编辑推荐一个在线工具FontEditor, 十分好用, 可以删除或者添加字体里面的字符集, 包括多个字体文件合成一个字体, 我目前就是把我博客中使用的Roboto Mono字体和Iconfont字体合成了一个字体文件, 同时删除了Roboto Mono中ASCII码字符集以外的字体, 因为我只用这个字体来渲染代码中出现的英文和数字等, 不需要其他的字符, 字体文件大小从原来的110k直接缩小成了18k. @font-face@font-face格式: /* 完整格式, 不过我们日常使用时可能只会涉及到其中少数几个 */@font-face &#123; [ font-family: &lt;family-name&gt;; ] || [ src: &lt;src&gt;; ] || [ unicode-range: &lt;unicode-range&gt;; ] || [ font-variant: &lt;font-variant&gt;; ] || [ font-feature-settings: &lt;font-feature-settings&gt;; ] || [ font-variation-settings: &lt;font-variation-settings&gt;; ] || [ font-stretch: &lt;font-stretch&gt;; ] || [ font-weight: &lt;font-weight&gt;; ] || [ font-style: &lt;font-style&gt;; ] [ font-daipsy: &lt;font-display&gt;;]&#125;/* 例如, src 中可以使用 local 加载本地计算机的字体, url 用来加载在线的字体(注意跨域问题), 指定 format 可以帮助浏览器更快解析字体 可选 format 有 【truetype(.ttf)、opentype（.otf）、truetype-aat、embedded-opentype(.eot)、svg(.svg)、woff(.woff)】 */@font-face &#123; font-family: MyHelvetica; src: local(\"Helvetica Neue Bold\"), local(\"HelveticaNeue-Bold\"), url(MgOpenModernaBold.ttf) format('turetype'); font-weight: bold;&#125; 在css中使用@font-face定义字体, 当浏览器在解析到这一行css时并不会马上去下载这个字体, 而是会继续解析建立DOM树和CSSOM树, 只有当DOM树和CSSOM树结合生成渲染树的时候浏览器会进行一个判断, 如果在渲染树中存在一个会被渲染出来的节点(也就是display不能为none, 见下面”什么样的节点不会出现在渲染树中”)使用了这个字体, 那么浏览器在这个时候才会开始下载这个字体, 至于字体什么时候下载完毕那就不一定了, 同时渲染过程并不会被这个下载过程给阻塞, 那么在此时不确定所需字体是否加载完毕的时候该如何处理采用了这个字体的文字呢? 什么样的节点不会出现在渲染树中只有display:none的节点不会出现在渲染树中, 而其他的例如visibility:hidden;或者opacity:0;都是会出现在渲染树中的, 因为后面的几种情况虽然也是元素在页面不可见, 但是会在页面上占据它自己的空间, 这会影响到页面的布局, 同时这样的元素中的字体的大小和样式是会影响这个元素所占据的空间的大小的(例如span元素等的大小是被字体撑开的), 所以这样的元素中的字体当然是会被加载的, 因为浏览器要根据元素占据的空间大小去布局. 由此引发出了三种解决方案FOUT, FOIT和FOIT 3S, 浏览器采取哪一种根据浏览器不同也有差异, 不过好消息是除了IE和Edge以外(对我来说基本是不考虑IE系列的…)的chrome, firefox, safari和opera都采用了第三种方案FOIT 3S. 下面简单介绍一下三种方案: FOUT(Flash of Unstyled Text) 当我们在 @font-face 中按优先级顺序定义了一系列字体（称之为 Font Stack）时，如果定义的最高优先级的字体在设备的字库中没有找到、或者引用了 WebFont 但是字体文件没有被加载，那么浏览器会继续轮询 Font Stack，直到找到可用的字体（这个过程就是寻找 fallback 字体）并先渲染出来；当自定义的字体文件被加载以后，浏览器会用这个字体文件重新渲染一遍画面。这有可能造成页面已经展示给用户以后页面的布局再次发生改动。而且，设计师并不喜欢 FOUT，因为这意味着有可能先让访客看到并不好看的备用字体、再看到好看的设计好的字体。但是 FOUT 不会因为字体文件无法加载而导致用户啥都看不到。IE 自从诞生之日起就在使用这种模式，现在 Edge 也在使用这种模式. FOIT(Flash of Invisible Text) 这是浏览器处理在设备的字库中没有找到、或者字体文件尚未被下载时的另一种方案。如果检测到设定了当前优先级下有设置自定义字体文件，那么浏览器就会不显示任何内容，直到字体显示出来。这有可能造成访客可能需要等待很长一段时间才能看见网页的内容；如果网络环境较为恶劣，甚至有可能会导致有的内容永久不可见。Safari 曾经在很长的一段时间内使用这种模式，并且 iOS WebKit 仍然在使用这种模式，Opera 也曾短暂使用过。(注: 目前这个方案已经被抛弃了) FOIT 3S 这应该是一个比较折中的解决方案，并且目前 Chrome、Firefox、Safari 都在使用。在 3s 内使用了自定义字体样式的使用 FOIT 模式，在一定时间内（1s，3-5s，也可能是 10s，具体看浏览器和版本）使用 FOIT，如果字体仍然没有加载出来就降级到 FOUT 以改善用户的浏览体验。–Web Font 123 - 再谈 WebFont 优化 我们可以使用@font-face中指定font-display来告诉浏览器该采用哪种方案, 一共有四个选项: auto, swap, fallback和optional 不指定的情况下默认值是auto则浏览器会采用FOIT 3S方案 指定为swap则浏览器会采用FOUT方案 指定为fallback则浏览器会等待一个极短的时间(大约100ms), 在这个时间之前不会显示任何内容, 这个时间结束之后如果字体还没有加载完成, 那么会采用优先级较低的字体来渲染, 之后等字体加载结束之后再使用正确的字体来重新渲染(根据我的测试, 如果这个字体加载的时间太长, 比如5s, 这个时间我没有准确测量过 那么即使之后字体加载完成了, chrome也不会再去重新渲染该字体, 如果短于这个时间, chrome是会去重新用正确的字体渲染的) 指定为optional则浏览器会采用和fallback类似的做法, 只不过等待字体加载的时间会更短(比如上面是5s, 那么现在可能只会等待加载1s) FontFaceSet除了在css中使用@font-face加载在线字体之外, js里面也有手动加载在线字体的API, 只不过目前还有一定兼容性问题, 但是我关心的chrome, firefox和safari的最近的版本都已经支持了, 所以对我来说是可以使用的. 关于这个API的定义可以参考CSS的这份草案, 也可以参考这篇文章的实践, 我自己归纳如下: new FontFace()这个API用来生成一个FontFace字体实例, 接受三个参数, 第一个是字体名(对应@font-face中的font-family), 第二个是字体的的路径(对应@font-face中的src), 第三个是字体的其它信息(例如@font-face中的font-style和font-weight等), 第三个参数也可以不传, 返回一个FontFace字体实例对象 const robotoMono = new FontFace('Roboto Mono', 'url(\"https://store.kricsleo.com/blog/static/fonts/RobotoMono-Regular.ttf\")', &#123; style: 'normal', weight: '400',&#125;); [FontFace].load()这个API仅用来加载字体文件, 也就是浏览器会去下载对应的字体文件, 返回一个Promise对象, resolve时会抛出对应的FontFace对象, 可以自行捕获加载错误或者定义加载成功后的行为, 需要注意的是此时字体加载成功以后页面上的文字也不会使用该字体去渲染, 还需要使用下面的add()方法把字体加到FontFaceSet中才可以使用 robotoMono.load().then(fontFace =&gt; &#123; console.log(fontFace.family, 'loaded successfully!');&#125;, fontFace =&gt; &#123; console.error('failed: ', fontFace.status);&#125;); [FontFaceSet].load()这个API也可以用来加载字体, 只不过这个API可以不用先生成一个FontFace的实例, 可以使用CSS中已经定义的字体, 然后用这个API来手动加载已经定义的字体, 可以参考MDN // 第一个参数为字体的相关信息, 分别是'font-style' 'font-weight', 'font-size'和'font-family'// 第二个参数为字体中的某个字符, 可以用来限制加载的字体中必须有这个字符document.fonts.load('italic bold 16px Roboto', 'ß').then(fontFace =&gt; &#123; console.log(fontFace.family, ' has been loaded successfully!');&#125;, fontFace =&gt; &#123; console.warn('loading error...');&#125;); [FontFaceSet].add()这个API用来把字体实例加到文档的字体列表FontFaceSet中, 使得字体可以被使用, 返回添加了字体实例之后的FontFaceSet对象 document.fonts.add(robotoMono); [FontFace.]status这个API用来访问字体的状态, 共有四种, unloaded, loading, loaded和error, 一旦加载并准备好字体，loaded的Promise就会完成 console.log(robotoMono.status);robotoMono.loaded.then(fontFace =&gt; &#123; console.log(fontFace.family, 'loaded successfully!');&#125;, fontFace =&gt; &#123; console.error('failed: ', fontFace.status);&#125;); [FontFaceSet].ready这个API用来作为一系列字体加载的结果的回调, 当所有字体都成功加载时就会触发Promise的完成 document.fonts.ready.then(fontFaceSet =&gt; &#123; console.log('All fonts have been loaded successfully!');&#125;); 轮子为了达到通过js来定义和控制CSS字体的下载及替换默认的延迟下载行为的目的, 现在已经有一些可以使用的轮子, 比如fontfaceobserver和Web Font Loader, 其实原生的API也挺好用的而且比较简洁, 如果不想引入第三方库的话自己手写一下挺好的."},{"title":"optimize-my-blog","permalink":"https://kricsleo.github.io/optimize-my-blog/","text":"hexo主题 MaterialFlow 主题改造打算对博客的访问速度和样式做一个改版优化.因为看到屈屈的博客做了很多优化, 体验很好, 所以自己私下想要pk一下 目前使用的网站评测主要有google的PageSpeed Insights和GTmetrix, 屈屈在PageSpeed Insights上的评分是97分, 那么我的目标是98分及以上. 目标 精简页面请求数-不超过5个目前已经删除掉多余的请求, 现在已经删减到5个, 分别是页面html, 脚本index.js, 样式style.css, 字体RobotoMono-Iconfont以及图标favicon.ico, 第一次请求会加载这五个, 从第二次开始就只会有一个请求, 就是页面html, 这个是必须的, 其余的四个均在缓冲中(如果用户没有手动清除缓存的话) 减少请求大小-单个请求不超过50k目前都已经控制到30k以内, 除开一些特例, 目前页面上最大的请求就是页面本身(这个是正常且自然的), 其次就是页面上的图片, 这个我会尽量压缩, 但是也是在可以接受的范围, 其他的css, js, 和字体都在20k以内 控制首屏加载时间-不超过1s目前首屏加载时间相当快了, 因为其实只是先显示一个加载动画, 然后等css加载完毕以后再显示主要内容 静态文件上cdn-七牛云cdn目前js和css还有字体文件都已经使用七牛云的cdn服务 升级https目前全站资源都切换到了https,主域名kricsleo.com已经使用github提供的免费https服务, cdn域名store.kricsleo.com也使用在阿里云上申请到的SSL证书升级到了https 干掉jquery之前的主题使用的是jquery来实现一些功能, 现在已经将相关逻辑都使用原生js改写, 目前没有任何第三方依赖 精简字体文件中文字体采用系统自带的字体渲染, 英文字体系统自带的比较难看, 加上我很喜欢google的一个字体Roboto Mono, 所以犹豫了很久决定为了网站的风格稍微牺牲一点速度, 还是采用@font-face加载网络字体, 同时因为我用到了一些图标, 所以最后我决定自己把英文字体和iconfont的图标进行合并, 同时删除掉我用不到的字体和字符, 找到了一个很好用的在线编辑字体的工具FontEditor, 把Roboto Mono中我用不到的基本都删掉了, 最后剩下的大概只有ASCII里面的字符, 同时把在阿里图标库找到的我要用的iconfont图标加了进去, 最后生成了一个适合我的RobotoMono-Iconfont字体文件, 大小只有17k, 最后将这个文件放到了我的cdn上由页面引用 优化图片加载-懒加载图片很容易会拖慢网页的加载, 所以我对图片做了懒加载, 这里涉及到一个hexo的渲染问题, 我稍后来细写这一块.目前的效果是随着页面的滚动, 当图片进入视区中时才会去下载这个图片并显示. 避免css的加载和解析拖慢首屏的展现这一块和控制首屏展现时间一起写. 过程记录对于上面的目标里面的部分记录一下达成的过程 压缩所有资源我使用的hexo生成的博客静态文件, 压缩的时候使用 相关资料关于浏览器渲染字体的过程:Web Font 123 - 再谈 WebFont 优化渲染字体的方式原生有三种: FOUT(Flash of Unstyled Text), FOIT(Flash of Invisible Text)和FOIT 3S(3s前为FOIT, 3s后还未加载完毕则降级为FOUT) 优化关键渲染路径html, css 和 JavaScript 之间的依赖关系关键渲染路径系列文章; 普通: 停止解析 dom, 单线程转为下载并立即执行 js, 在 js 处理完毕之后再继续解析 dom, 会阻塞 dom 的解析和渲染defer: 并行下载 js 文件, 但是将其执行时间推迟到 dom 构建完毕在domContentLoaded时间之前, 不会阻塞 dom 的解析但会阻塞dom 的渲染, 按照规范来说 js脚本是按照顺序执行的, 但是各个浏览器的实现可能不一样, 在实际中无法保证顺序执行这一点, 相当于把 js 脚本位置移动到&lt;body&gt;底部, 脚本在执行的时候dom 已经构建完毕, 可以操作 dom;async: 并行下载 js 文件, 下载完成后立即执行, 执行时间可能在domContentLoaded之前, 也可能在domContentLoaded之后, 但是一定在 load 事件之前, 不会阻塞 dom 的解析和渲染, 但是在执行时不保证 dom 构建完毕, 同时也不保证各个脚本的执行顺序, 也就是说如果你的脚本里面有操作 dom 的地方, 那么这个地方可能会报错, 因为对应的 dom 节点可能还没有构建完成, 所以需要避免在此类脚本中操作 dom;值得注意的是，向 document 动态添加 script 标签时，async 属性默认是 true， css 加载优化 只显示头部和右侧 css加载不会阻塞DOM树的解析css加载会阻塞DOM树的渲染css加载会阻塞后面js语句的执行、 js 可以阻塞 dom 树的构建和渲染 实际上，内联脚本始终会阻止解析器，除非您编写额外代码来推迟它们的执行–使用 JavaScript 添加交互 preload firefox不支持 总体步调 速度: 请求数: 页面初始请求不超过6个(现在是5个) 请求大小: 最大请求大小不超过150k 不超过2s 加载完毕 静态文件采用 cdn 缓存 图片懒加载 干掉 jquery 字体文件太大了, 采用在线字体处理, 去除多余文字, 加入需要的 iconfont 考虑内联或者其它方式处理 css, 目前 css 严重阻碍首屏展现 样式 整体风格天蓝色 采用卡片式布局(可以考虑重写, 既可以练习自己的建站技巧, 也可以去除原本 css 中的冗余部分) 安全 全站升级为 https 七牛云空间也一并配置 https 评论 等到前三点稳定以后再开启评论合适/速度快/国内可访问的评论系统 搜索 等到前四点稳定以后再考虑转用其他搜索实现毫秒级响应(第三方搜索或者自己部署 Elasticsearch)目前采用的是hexo-generator-search生成的站内静态文件."},{"title":"Promise-Generator","permalink":"https://kricsleo.github.io/Promise-Generator/","text":"异步解决方案本文是为了解js的异步操作解决方案发展过程. 从原始的回调地狱到ES6的Promise和Generator再到ES7提案阶段的async. 回调地狱我们之前会把异步的事件写在回调函数里面, 如果有一系列的异步事件, 并且这些事件是按照顺序触发的, 那么我们的代码最后的结构很可能就是回调里面放回调再放回调, 一层层往里面嵌套, 堪称’地狱’. fs.readFile('/etc/passwd', function (err, data) &#123; if (err) throw err; console.log(data);&#125;); Promise为了避免回调地狱的代码横向发展, 在 ES6 里面引入了 Promise 这种新的写法, 使得代码从横向发展变成了链式的纵向发展. 通过then()来执行回调, 使得代码的逻辑变得清晰, 写法也更简洁. 关键点有三个, resolve, reject和then. 常见的写法如下: // 创建一个 Promise 对象const promise = new Promise(function(resolve, reject) &#123; // ... some code if (/* 异步操作成功 */)&#123; resolve(value); &#125; else &#123; reject(error); &#125;&#125;);// 对这个 Promise 对象进行链式操作promise.then(function(value) &#123; // success&#125;, function(error) &#123; // failure&#125;).catch(function(err) &#123; // js error&#125;); GeneratorGenerator函数有一个语法糖, 叫做async函数, 两者的写法类似, 只是async有更多的优点, 但是都是配合 Promise 来使用, 毕竟在现在来说我们的异步都是使用的 Promise 来写的. const fs = require('fs');const readFile = function (fileName) &#123; return new Promise((resolve, reject) =&gt; &#123; fs.readFile(fileName, (err, data) =&gt; &#123; if(err) &#123; reject(err); &#125; resolve(data); &#125;) &#125;);&#125;// Generator函数写法const gen = function* () &#123; const f1 = yield readFile('f1'); const f2 = yield readFile('f2'); console.log(f1.toString()); console.log(f2.toString());&#125;// Generator函数的执行gen.next();gen.next();// ...// async函数写法const asy = async function () &#123; const f1 = await readFile('f1'); const f2 = await readFile('f2'); console.log(f1.toString()); console.log(f2.toString());&#125;// async函数的执行asy 从上面的比较可以看出, 从形式上来说是关键词不一样. Generator函数使用*来表示一个异步函数, async函数使用async来表示一个异步函数 Generator函数使用yield来进行一个异步操作, async函数使用await来进行一个异步操作(也可以是同步操作) 从内部的工作过程来说, Generator函数没有自动执行的功能, 如果需要内部的异步步骤一步步执行, 那么你需要手动一步步调用gen.next()方法来驱动异步的进行. 而async函数简化了这个过程, 内置了执行器, 可以自动一步一步的按照顺序执行异步操作. 我这里只是一叶障目, generator 有着更多的含义和用法. 在我能够完整的说个大概之前, 还是请参考一些别人的理解吧. 参考文章: [译] Javascript（ES6）Generator 入门 // 一个用于理解 generator 和 next()传参的问题function* gen(i) &#123; console.log(i); const j = 5 * (yield (i * 10)); console.log(j); const k = yield (2 * k / 4); console.log(k); return i + j + k;&#125;var g = gen(10);console.log(g.next(20)); // &#123;value: 100, done: false&#125;console.log(g.next(10)); // &#123;value: 25, done: false&#125;console.log(g.next(5)); // &#123;value: 65, done: true&#125;"},{"title":"same-origin-and-CORS","permalink":"https://kricsleo.github.io/same-origin-and-CORS/","text":"浏览器同源策略目前的 web 开发还相当的依赖 cookie , 而cookie的使用限制于浏览器的同源策略(same-origin policy), 同时这个策略也是保证我们网站信息安全的基础, 这篇文章主要了解一下浏览器同源策略具体的含义, 以及在实际开发中如何绕过这一限制来达到跨域请求数据的目的. 何为同源一个访问地址大致可以分为&lt;协议&gt;&lt;域名&gt;&lt;端口&gt;&lt;路径&gt;四个部分: 例如https://www.example.com:80/home/index.html?page=3, https为协议, www.example.com为域名, 域名内也可分为顶级域名, 一级域名, 二级域名, 三级域名等等, 具体如何拆分的讨论可以参考知乎的一个帖子, 你只要明白意思就可以了, 这里的话我采用其中一种说法来描述一下, com为顶级域名, example为一级域名, www为二级域名, 接下来的80为端口, /home/index.html?page=3为路径, 这样我们就把一个URL的各个部分拆分开了. 所谓同源, 就是限制了&lt;协议&gt;&lt;域名&gt;&lt;端口&gt;这三个部分必须要一模一样, 此时就称为同源, 如果这三块有任何一个地方不一样就产生了跨域. 跨域带来的限制在跨域情况下有如下几种情况会受到限制: 两个域之间无法互相读取Cookie、LocalStorage 和 IndexDB例如a.com向api.com发起请求的时候, 请求中默认是不会携带a.com域下的cookie的, 也就是说api.com默认情况下是无法获取a.com的cookie的 两个域之间无法互相获取和操作DOM例如a.com的一个页面内有一个iframe, iframe里面加载的是b.com的一个一个页面, 那么这两个页面之间是无法获取另一方的DOM来进行操作的 两个域之间无法使用ajax通信例如a.com向api.com发起一个ajax请求(XMLHttpRequest或者fetch()), 那么返回的数据默认会被浏览器拦截并且丢弃然后控制台提示产生一个跨域的错误, 所以在js中是无法拿到返回数据的 cookie的概念这里我们首先看一下cookie的相关概念, cookie是存在客户端浏览器的一小段文本, 不同的浏览器对cookie的大小有不同的限制, 可以通过document.cookie来获取本域名下的cookie信息, cookie中包含如下属性: key=value, Domain, Path, Expires, Max-Age, Secure和HttpOnly, 还有用的比较少的HostOnly等, 可以查看这篇文章, 各个属性之间用英文分号和空格（”; “）连接, 大概说一下各个属性. key=valuecookie最主要的内容, 设置cookie的值, 例如username=krics;, 代表在cookie中存储了一个username, 它的值是krics, 必填项. Domaincookie的域名, 默认是当前域名, 和Path配合指定 cookie 的具体路径. 注意在手动设置时domain是可以设置为页面本身的域名（本域），或页面本身域名的父域，但不能是公共后缀public suffix。举例说明下：如果页面域名为 www.baidu.com, domain可以设置为“www.baidu.com”，也可以设置为“baidu.com”，但不能设置为“.com”或“com”. 设置Domain时的前面带点‘.’和不带点‘.’的区别: 带点：任何 subdomain 都可以访问，包括父 domain 不带点：只有完全一样的域名才能访问，subdomain 不能（但在 IE 下比较特殊，它支持 subdomain 访问） Pathcookie的可访问路径, 默认为”/“，表示指定域下的所有路径都能访问, 它是在域名的基础下，指定可以访问的路径。例如cookie设置为”domain=.google.com.hk; path=/webhp”，那么只有”.google.com.hk/webhp”及”/webhp”下的任一子目录如”/webhp/aaa”或”/webhp/bbb”会发送cookie信息，而”.google.com.hk”就不会发送，即使它们来自同一个域。 Expirescookie的过期日期, 内容格式是GMT时间字符串, 例如Expires=&quot;Tue, 16 Oct 2018 04:01:45 GMT;&quot;代表此cookie将在这个时间过期, 在此之前cookie都是有效的, 可以使用Date类型的toGMTString()方法来获取这个时间戳, 可选属性. 如果没有设置该项那么默认 cookie 的有效期是本次会话期间, 也就是说在关闭浏览器前这个 cookie 一直有效, 但是一关闭浏览器这个 cookie 马上就失效被删除, 这种 cookie 也叫做session cookie. 现在在http/1.1中已经推荐使用Max-Age来代替这个属性, 但是由于老版本的IE(ie6、ie7 和 ie8)只可使用Expires属性, 不兼容Max-Age这个新属性, 所以使用时请考虑到这一点 Max-Agecookie的最大有效时间, 在http/1.1中引入的新属性, 单位是秒, 代表从客户端的此刻开始到多少秒后, 这个cookie会失效, 例如Max-Age=3600, 代表在客户端设置这个cookie起的3600秒后这个cookie失效, 可选属性. 默认值是-1, 含义是本次会话期间有效, 关闭浏览器则失效, 设置为0代表删除该 cookie, 设置为正整数代表的有效秒数.注意对于对于Expires和Max-Age都可以使用的浏览器而言, 这两个如果都设置了, 那么Max-Age的优先级高(IE除外, IE只使用Expires), 如果只设置一个, 那就以设置的那个为准(同样IE除外), 如果都没有设置, 那么cookie的有效时间为本次会话期间, 只要浏览器不关闭, 那么这个cookie一直有效, 如果浏览器被关闭, 那么这个cookie就会被删除, 像这样没有设置Expires和Max-Age的cookie, 我们也可以称为session cookie, 因为它是与本次会话相关联的. 可选属性 Securecookie的安全标志, 内容很简单, 只需要指定一个Secure字段就可以了, 而不是键值对的形式, 当指定是Secure之后, 这个cookie只会在使用SSL(例如HTTPS)连接时才会被发送到服务器. 默认为空, 那么默认情况下不论是不是安全的连接在可以发送 cookie 的时候都会发送这个cookie. 可选属性. 如果想在客户端即网页中通过 js 去设置secure类型的 cookie，必须保证网页是https协议的。在http协议的网页中是无法设置secure类型cookie的。 HttpOnlycookie的安全保证, 内容也很简单, 只需要指定一个HttpOnly字段就可以了, 当指定为HttpOnly后, 就无法通过js去访问或者设置这个cookie的内容, 同时也无法通过js来设置HttpOnly的cookie, 这个字段只有服务器能够操作, 这个cookie会正常的发送给服务器, 只是对客户端的js不可见而已. 可选属性 有两种方式产生cookie, 一种是服务器的响应, 而是客户端的js. 服务器响应方式如果服务器在响应的数据中添加一个响应头: Set-Cookie: name=krics; Path=/; Domain=.example.com; Max-Age=31536000, 例如下面JAVA的写法, // 生成一个cookieCookie cookie = new Cookie(\"name\", \"krics\");cookie.setPath(\"/\");cookie.setDomain(\".example.com\");//这样设置，能实现不同二级域名的两个网站共用这个cookie, 自定义cookie.setMaxAge(365 * 24 * 60 * 60);// 不设置的话，则cookies不写入硬盘,而是写在内存,只在当前页面有用,以秒为单位response.addCookie(cookie); //添加第一个Cookie// 可以重复上面的代码添加多个cookie 这样就会在响应头中添加上面示例给出的额外的头信息. 客户端js在客户端通过js方式document.cookie既能访问cookie, 也能设置cookie, 例如document.cookie=&quot;name=krics; Path=/; Domain=.example.com; Max-Age=31536000&quot;, 那么就会添加一个cookie到浏览器中, 这里比较有意思的是并不是多次设置document.cookie其实是追加内容, 不像一般js那样会覆盖内容, 之后有时间可以看一下这里的处理. 这里因为浏览器没有提供其他的api来操作cookie, 所以我们一般会自己封装一个工具类来读写cookie, 这里给出我的一个比较简单的实现Cookie.js 解决跨域这里可以参考阮一峰的文章浏览器同源政策及其规避方法. iframe形式的跨域 如果两个窗口一级域名相同，只是二级域名不同，那么可以通过设置document.domain属性为同一个值，就可以规避同源政策，拿到DOM。 片段标识符（fragment identifier）指的是，URL的#号后面的部分，比如http://example.com/x.html#fragment的#fragment。如果只是改变片段标识符，页面不会重新刷新。但是会触发window的onhashchange事件, 可以通过监听这个事件来传递数据. 监听window.name属性。这个属性的最大特点是，无论是否同源，只要在同一个窗口里，前一个网页设置了这个属性，后一个网页可以读取它, 而且这个值得容量很大, 字符串形式. 以上三种方式都属于hack, HTML5为了解决这个问题，引入了一个全新的API：跨文档通信 API（Cross-document messaging）,这个API为window对象新增了一个window.postMessage方法，允许跨窗口通信，不论这两个窗口是否同源。具体使用可以参考MDN, 需要注意的是在IE下有一定的兼容性问题. 通过window.postMessage，读写其他窗口的 LocalStorage . 也是基于window.postMessage的. AJAX这里才是重点, 一个跨域的AJAX请求要想正常交互, 有如下四种解决方案: JSONP它的基本思想是，网页通过添加一个&lt;script&gt;元素，向服务器请求JSON数据，这种做法不受同源政策限制；服务器收到请求后，将数据放在一个指定名字的回调函数里传回来。这种方式的优点是简单兼容性好, 服务器的改造小, 但是这种方式因为是通过加载js脚本的形式实现的, 所以只支持GET方式. WebSocketWebSocket是一种通信协议，使用ws://（非加密）和wss://（加密）作为协议前缀。该协议不实行同源政策，只要服务器支持，就可以通过它进行跨源通信。这种方式对服务器的改造最大, 需要更改协议 Nginx通过在服务器端布置Nginx, 通过它代理请求, 然后由Nainx将请求转发到真正的数据服务器上, 这种方式需要在服务器端安装Nginx, 然后需要配置Nginx才行 CORSCORS是跨源资源分享（Cross-Origin Resource Sharing）的缩写。它是W3C标准，是跨源AJAX请求的根本解决方法。相比JSONP只能发GET请求，CORS允许任何类型的请求。关于CORS, 可以参考阮一峰的文章跨域资源共享 CORS 详解, 简单来说是按照下文配置. CORD 服务器端配置 Access-Control-Allow-Origin: 代表允许跨域的域名,可选字段, 默认不允许跨域请求, 如果配置为&quot;*&quot;代表接受任何一个域发送的ajax请求, 也可以指定一个特定的域名, 表示只接受这个域发送的跨域请求, 注意- 不能设置多个域, 要么是通配符&quot;*&quot;, 要么是某一个域 Access-Control-Allow-Credentials: 代表是否允许跨域请求携带cookie, 可选字段, 默认不允许, 设置为true代表允许, 但是这个字段和上面的Access-Control-Allow-Origin有一点冲突的是, 如果设置为true, 那么Access-Control-Allow-Origin只能配置特定的一个允许跨域的域名, 这个时候不能配置通配符&quot;*&quot; Access-Control-Expose-Headers: 代表允许客户端获取的额外的头字段信息, 可选字段, 默认无法拿到自定义的头部字段, CORS请求时，XMLHttpRequest对象的getResponseHeader()方法只能拿到6个基本字段：Cache-Control、Content-Language、Content-Type、Expires、Last-Modified、Pragma。如果想拿到其他字段，就必须在Access-Control-Expose-Headers里面指定。例如可以指定Access-Control-Expose-Headers: FooBar，那么客户端可以通过response.getResponseHeader(&#39;FooBar&#39;)拿到FooBar字段的值。 客户端配置withCredentials: 代表跨域请求是否发送对应域的cookie, 可选字段, 默认不会发送(有的浏览器可能例外, 也可以显示的设置为false), 设置为true代表发送, 需要注意的是客户端是需要和服务端配合使用的, 当设置为true时, 虽然cookie发送过去了, 但是服务器要配置Access-Control-Allow-Credentials: true和Access-Control-Allow-Origin: www.example.com才能正确接收到cookie 当然还有更详细的内容, 如果碰到更多问题, 可以去看一下上面阮一峰的关于跨域的文章, 也可以参考Faremax的一片文章全解跨域请求处理办法. 参考文章聊一聊 cookie全解跨域请求处理办法跨域资源共享 CORS 详解"},{"title":"Content-Type","permalink":"https://kricsleo.github.io/Content-Type/","text":"Content-TypeHTTP/1.1协议规定的HTTP请求方法有OPTIONS、GET、HEAD、POST、PUT、DELETE、TRACE、CONNECT这几种, 用的最多的是GET和POST, 这里主要说一下提交请求时的请求头中Content-Type字段 http请求结构http请求分为三个部分: 状态行, 请求头和消息主体, 结构如下: &lt;method&gt; &lt;request url&gt; &lt;version&gt;&lt;headers&gt;&lt;entity-body&gt; Content-Type类型Content-Type有如下常见的类型: text/plain: 文本类型 text/html: html文件类型 text/css: css文件类型 text/javascript: javascript文件类型 application/x-www-form-urlencoded POST讨论 multipart/form-data POST讨论 application/json POST讨论 text/xml POST中讨论 由于GET方式的数据实际上是以QueryString的方式放在&lt;request url&gt;中的(非ASCII字符会被转码), 例如’https://www.example.com?key1=value1&amp;key2=value2‘, 所以对GET讨论Content-Type没有意义 http协议规定POST提交的数据必须放在消息主体（entity-body）中，但协议并没有规定数据必须使用什么编码方式。实际上，开发者完全可以自己决定消息主体的格式，只要最后发送的HTTP请求满足上面的格式就可以。 服务端通常是根据请求头（headers）中的Content-Type字段来获知请求中的消息主体是用何种方式编码，再对主体进行解析。所以有必要了解Content-Type的内容. 目前在POST请求中所使用的Content-Type主要有如下四种类型: application/x-www-urlencoded, multipart/form-data, application/json, text/xml, 下面详细说一下这四种类型. application/x-www-urlencoded这应该是最常见的POST提交数据的方式了。浏览器的原生&lt;form&gt;表单，如果不设置enctype属性，那么默认就会以这种方式提交数据。这种方式会将表单中的数据按照key1=value1&amp;key2=value2的形式连接成字符串, 同时会将出现的非ASCII字符进行编码, 编码方式可以参考encodeURIComponent()函数, 例如下面这个表单提交时的数据结构: POST http://www.example.com HTTP/1.1Content-Type: application/x-www-form-urlencoded;charset=utf-8title=test&amp;sub%5B%5D=1&amp;sub%5B%5D=2&amp;sub%5B%5D=3 但是需要注意的是这是在&lt;form&gt;表单中没有type=file形内容的时候的提交方式, 如果表单中有二进制内容需要提交, 比如文件或者图片等, 那么就无法使用application/x-www-urlencoded方式, 需要转而使用下面会谈到的multipart/form-data方式. multipart/form-data当需要提交二进制数据如文件或者图片时就需要使用这种multipart/form-data, 一个常见的提交内容结构如下: POST http://www.example.com HTTP/1.1Content-Type:multipart/form-data; boundary=----WebKitFormBoundaryrGKCBY7qhFd3TrwA------WebKitFormBoundaryrGKCBY7qhFd3TrwAContent-Disposition: form-data; name=&quot;text&quot;title------WebKitFormBoundaryrGKCBY7qhFd3TrwAContent-Disposition: form-data; name=&quot;file&quot;; filename=&quot;chrome.png&quot;Content-Type: image/pngPNG ... content of chrome.png ...------WebKitFormBoundaryrGKCBY7qhFd3TrwA-- 请求头中的boundary代表将使用后面这一长串的字符串来分隔不同的字段, 消息主体里按照字段个数又分为多个结构类似的部分，每部分都是以--boundary开始，紧接着是内容描述信息，然后是回车，最后是字段具体内容（文本或二进制）。如果传输的是文件，还要包含文件名和文件类型信息。消息主体最后以--boundary--标示结束, 关于multipart/form-data的详细定义，请前往rfc1867查看。 application/x-www-urlencoded和multipart/form-data都是浏览器原生支持的，而且现阶段标准中原生&lt;form&gt;表单也只支持这两种方式（通过&lt;form&gt;元素的enctype属性指定，默认为 application/x-www-form-urlencoded。其实enctype还支持text/plain，不过用得非常少）。 下面提到的Content-Type属于随着技术的发展, 我们自定义出来的新的数据提交方式, 更为便捷. application/json因为json格式数据的读写性非常好, 用的也极为广泛, 所以application/json这个请求头也用的越来越多, 这个请求头就是告诉服务器发送的数据是序列化后的json字符串, 现在在做的Vue项目中用到的Axios所使用的默认就是application/json, 这里有一个问题就是Axios全局设置Content-Type为application/x-www-urlencoded不生效, 需要在请求发出前拦截方法中修改配置才能生效, 不知道是不是bug, 如下: function _interceptorRequest(config) &#123; config.headers['Content-Type'] = 'application/x-www-form-urlencoded; charset=utf-8'; return config&#125; 使用application/json方式发送的数据结构类似下面这个: POST http://www.example.com HTTP/1.1 Content-Type: application/json;charset=utf-8&#123;&quot;title&quot;:&quot;test&quot;,&quot;sub&quot;:[1,2,3]&#125; json格式可以提交结构复杂的数据,在抓包工具或者调试中查看起来也很方便, 尤其适合RESEful的接口, 需要注意的是不论我们使用application/x-www-urlencoded还是application/json都要注意和服务器相配合, 因为毕竟我们发送的数据是希望服务器来正确接收和处理的, 如果客户端设置的Content-Type与服务端期望接收的Content-Type不一致就很有可能导致服务器无妨正常处理这个请求. text/xml这是一种使用HTTP作为传输协议，XML作为编码方式的远程调用规范, 典型的XML-RPC请求如下: POST http://www.example.com HTTP/1.1Content-Type: text/xml&lt;?xml version=&quot;1.0&quot;?&gt;&lt;methodCall&gt; &lt;methodName&gt;examples.getStateName&lt;/methodName&gt; &lt;params&gt; &lt;param&gt; &lt;value&gt;&lt;i4&gt;41&lt;/i4&gt;&lt;/value&gt; &lt;/param&gt; &lt;/params&gt;&lt;/methodCall&gt; XML-RPC协议简单、功能够用，各种语言的实现都有。它的使用也很广泛，如WordPress的XML-RPCApi，搜索引擎的ping服务等等。JavaScript中，也有现成的库支持以这种方式进行数据交互，能很好的支持已有的 XML-RPC服务。 参考文章 四种常见的POST提交数据方式 HTTP Header之Content-Type"},{"title":"http","permalink":"https://kricsleo.github.io/http/","text":"httphttp虽然内容简单, 容易理解, 但是内容十分庞大, 涉及到现在通信的方方面面, 我打算花点时间陆陆续续的把我接触到的http的相关部分整理出来, 这里作为一个入口页, 后续持续补充. Content-Type关于Content-Type"},{"title":"object-get-set","permalink":"https://kricsleo.github.io/object-get-set/","text":"属性描述符在js的对象中通常会有很多个属性, 例如let person = { name: &#39;john&#39;}中的name就是person这个对象的一个属性, 我们可以定义这个属性的一些特性, 也就是来描述这个属性, 比如这个属性是否是可读写的, 是否是可以被枚举的等等, 由此产生出了属性描述符这个概念.属性描述符分为两种: 数据描述符和存取描述符: 数据描述符是一个拥有可写或不可写值的属性 存取描述符是由一对getter-setter函数功能来描述的属性 属性描述符必须是两种形式其中之一, 不能同时是两者. 我们使用Object.defineProperty()这个方法来定义一个属性的属性描述符. 数据描述符数据描述符有四个: configurable, enumerable, writable和value, 前三个属性在使用Object.defineProperty()定义时默认都是false,第四个属性value默认为undefined, 而如果使用字面量直接添加属性的话, 那么这个属性的前三个属性默认都是true. 下面具体说一下这个四个属性: configurable 是否可以删除目标属性或是否可以再次修改属性的四个特性, 意思是当设置为true时可以随时对configurable, enumerable, writable和value这四个属性进行修改, 但是一旦设置为false, 那么这个四个属性将都不能被更改, 你也无法再次将configurable设置为true, 默认为false enumerable 此属性是否可以被枚举（使用for...in或Object.keys()）。设置为true可以被枚举；设置为false，不能被枚举, 默认为false writable 属性的值是否可以被重写。设置为true可以被重写；设置为false，不能被重写, 默认为false value 属性对应的值,可以使任意类型的值，默认为undefined 使用举例: let person = &#123; name: 'john'&#125;// 定义一个已经有的属性 name, 或者新增一个属性 name, 写法一样Object.defineProperty(person, 'name', &#123; configurable: true | false, enumerable: true | false, writable: true | false, value: 任意类型的值&#125;);// 查看属性Object.getOwnPropertyDescriptor(person, 'name');// =&gt; &#123;// configurable: true,// enumerable: true,// writable: true,// value: 'john'// &#125; ES5有三个操作符会忽略掉对象中enumerable设置为false的属性: for...in循环: 只遍历对象自身的和继承的可枚举的属性 Object.keys()：返回对象自身的所有可枚举的属性的键名 JSON.stringify()：只串行化对象自身的可枚举的属性 ES6新增了一个操作Object.assign()，也会忽略对象中enumerable为false的属性，只拷贝对象自身的可枚举的属性。 存取描述符存取描述符也有四个: configurable, enumerable, get和set, 前两个属性在使用Object.defineProperty()定义时默认都是false, 后两个属性默认是undefined, 而如果使用字面量直接添加属性的话, 那么这个属性的前两个属性默认都是true, 下面具体说一下这个四个属性: configurable 与上面数据描述符中相同 enumerable 与上面数据描述符中相同 get 获取对象中属性值的方法, 它的值应该是一个返回这个属性值的方法, 默认为undefined set 设置对象中属性值的方法, 它的值应该是一个接受一个新值作为参数然后执行设置属性值的方法, 默认为undefined 使用举例: let person = &#123; name: 'john' &#125;;Object.defineProperty(person, 'name', &#123; configurable: true | false, enumerable: true | false, get: function() &#123; return value; &#125; | undefined, set: function(newVal) &#123; if(newVal !== value) &#123; value = newVal; &#125; &#125; | undefined&#125;); 这里的set的用途就很强大了, 比如我们使用的Vue里面的数据绑定就是基于这个set实现的双向数据绑定, 这里埋下一个坑: TODO: 分析Vue的源码中的数据绑定部分 属性的遍历 for...in for...in循环遍历对象自身的和继承的可枚举属性（不含Symbol属性) Object.keys(obj) Object.keys返回一个数组，包括对象自身的（不含继承的）所有可枚举属性（不含Symbol属性）。 Object.getOwnPropertyNames(obj) Object.getOwnPropertyNames返回一个数组，包含对象自身的所有属性（不含Symbol属性，但是包括不可枚举属性）。 Object.getOwnPropertySymbols(obj) Object.getOwnPropertySymbols返回一个数组，包含对象自身的所有Symbol属性。 Reflect.ownKeys(obj) Reflect.ownKeys返回一个数组，包含对象自身的所有属性，不管是属性名是Symbol或字符串，也不管是否可枚举。"},{"title":"MVC-MVP-MVVM","permalink":"https://kricsleo.github.io/MVC-MVP-MVVM/","text":"关于 MV*为了管理有图形界面的应用程序, 先后提出了 MVC, MVP 和 MVVM 等应用架构模式, 我们也许常常听到这几个词, 尤其对我这个前后端都做过的人来说更是时常接触, 但是对于他们之间的区别却不甚了解, 这几天看了不少文章讲这一块, 在看到 Github 上 livoras 写的文章以后才终在心里有所区分, 这里转载一下 livoras 的原文. 作者: livoras原文: https://github.com/livoras/blog/issues/11 另外可以看一下掘金上的这篇文章, 与前端开发结合起来更好理解: 浅析前端开发中的 MVC/MVP/MVVM 模式以下为转载内容. 前言做客户端开发、前端开发对MVC、MVP、MVVM这些名词不了解也应该大致听过，都是为了解决图形界面应用程序复杂性管理问题而产生的应用架构模式。网上很多文章关于这方面的讨论比较杂乱，各种MV模式之间的区别分不清，甚至有些描述都是错误的。本文追根溯源，从最经典的Smalltalk-80 MVC模式开始逐步还原图形界面之下最真实的MV模式。 GUI程序所面临的问题图形界面的应用程序提供给用户可视化的操作界面，这个界面提供给数据和信息。用户输入行为（键盘，鼠标等）会执行一些应用逻辑，应用逻辑（application logic）可能会触发一定的业务逻辑（business logic）对应用程序数据的变更，数据的变更自然需要用户界面的同步变更以提供最准确的信息。例如用户对一个电子表格重新排序的操作，应用程序需要响应用户操作，对数据进行排序，然后需要同步到界面上。 在开发应用程序的时候，以求更好的管理应用程序的复杂性，基于职责分离（Speration of Duties）的思想都会对应用程序进行分层。在开发图形界面应用程序的时候，会把管理用户界面的层次称为View，应用程序的数据为Model（注意这里的Model指的是Domain Model，这个应用程序对需要解决的问题的数据抽象，不包含应用的状态，可以简单理解为对象）。Model提供数据操作的接口，执行相应的业务逻辑。 有了View和Model的分层，那么问题就来了：View如何同步Model的变更，View和Model之间如何粘合在一起。 带着这个问题开始探索MV模式，会发现这些模式之间的差异可以归纳为对这个问题处理的方式的不同。而几乎所有的MV模式都是经典的Smalltalk-80 MVC的修改版。 Smalltalk-80 MVC历史背景早在上个世纪70年代，美国的施乐公司（Xerox）的工程师研发了Smalltalk编程语言，并且开始用它编写图形界面的应用程序。而在Smalltalk-80这个版本的时候，一位叫Trygve Reenskaug的工程师设计了MVC图形应用程序的架构模式，极大地降低了图形应用程序的管理难度。而在四人帮（GoF）的设计模式当中并没有把MVC当做是设计模式，而仅仅是把它看成解决问题的一些类的集合。Smalltalk-80 MVC和GoF描述的MVC是最经典的MVC模式。 MVC的依赖关系MVC出了把应用程序分成View、Model层，还额外的加了一个Controller层，它的职责为进行Model和View之间的协作（路由、输入预处理等）的应用逻辑（application logic）；Model进行处理业务逻辑。Model、View、Controller三个层次的依赖关系如下： Controller和View都依赖Model层，Controller和View可以互相依赖。在一些网上的资料Controller和View之间的依赖关系可能不一样，有些是单向依赖，有些是双向依赖，这个其实关系不大，后面会看到它们的依赖关系都是为了把处理用户行为触发的事件处理权交给Controller。 MVC的调用关系用户的对View操作以后，View捕获到这个操作，会把处理的权利交移给Controller（Pass calls）；Controller会对来自View数据进行预处理、决定调用哪个Model的接口；然后由Model执行相关的业务逻辑；当Model变更了以后，会通过观察者模式（Observer Pattern）通知View；View通过观察者模式收到Model变更的消息以后，会向Model请求最新的数据，然后重新更新界面。如下图： 看似没有什么特别的地方，但是由几个需要特别关注的关键点： view是把控制权交移给Controller，Controller执行应用程序相关的应用逻辑（对来自View数据进行预处理、决定调用哪个Model的接口等等）。 Controller操作Model，Model执行业务逻辑对数据进行处理。但不会直接操作View，可以说它是对View无知的。 View和Model的同步消息是通过观察者模式进行，而同步操作是由View自己请求Model的数据然后对视图进行更新。 需要特别注意的是MVC模式的精髓在于第三点：Model的更新是通过观察者模式告知View的，具体表现形式可以是Pub/Sub或者是触发Events。而网上很多对于MVC的描述都没有强调这一点。通过观察者模式的好处就是：不同的MVC三角关系可能会有共同的Model，一个MVC三角中的Controller操作了Model以后，两个MVC三角的View都会接受到通知，然后更新自己。保持了依赖同一块Model的不同View显示数据的实时性和准确性。我们每天都在用的观察者模式，在几十年前就已经被大神们整合到MVC的架构当中。 这里有一个MVC模式的JavaScript Demo，实现了一个小的TodoList应用程序。经典的Smalltalk-80 MVC不需要任何框架支持就可以实现。目前Web前端框架当中只有一个号称是严格遵循Smalltalk-80 MVC模式的：maria.js。 MVC的优缺点优点: 把业务逻辑和展示逻辑分离，模块化程度高。且当应用逻辑需要变更的时候，不需要变更业务逻辑和展示逻辑，只需要Controller换成另外一个Controller就行了（Swappable Controller）。 观察者模式可以做到多视图同时更新。 缺点: Controller测试困难。因为视图同步操作是由View自己执行，而View只能在有UI的环境下运行。在没有UI环境下对Controller进行单元测试的时候，应用逻辑正确性是无法验证的：Model更新的时候，无法对View的更新操作进行断言。 View无法组件化。View是强依赖特定的Model的，如果需要把这个View抽出来作为一个另外一个应用程序可复用的组件就困难了。因为不同程序的的Domain Model是不一样的 MVC Model 2在Web服务端开发的时候也会接触到MVC模式，而这种MVC模式不能严格称为MVC模式。经典的MVC模式只是解决客户端图形界面应用程序的问题，而对服务端无效。服务端的MVC模式又自己特定的名字：MVC Model 2，或者叫JSP Model 2，或者直接就是Model 2 。Model 2客户端服务端的交互模式如下： 服务端接收到来自客户端的请求，服务端通过路由规则把这个请求交由给特定的Controller进行处理，Controller执行相应的应用逻辑，对Model进行操作，Model执行业务逻辑以后；然后用数据去渲染特定的模版，返回给客户端。 因为HTTP协议是单工协议并且是无状态的，服务器无法直接给客户端推送数据。除非客户端再次发起请求，否则服务器端的Model的变更就无法告知客户端。所以可以看到经典的Smalltalk-80 MVC中Model通过观察者模式告知View更新这一环被无情地打破，不能称为严格的MVC。 Model 2模式最早在1998年应用在JSP应用程序当中，JSP Model 1应用管理的混乱诱发了JSP参考了客户端MVC模式，催生了Model 2。 后来这种模式几乎被应用在所有语言的Web开发框架当中。PHP的ThinkPHP，Python的Dijango、Flask，NodeJS的Express，Ruby的RoR，基本都采纳了这种模式。平常所讲的MVC基本是这种服务端的MVC。 MVPMVP模式有两种： Passive View Supervising Controller 而大多数情况下讨论的都是Passive View模式。本文会对PV模式进行较为详细的介绍，而SC模式则简单提及。 历史背景MVP模式是MVC模式的改良。在上个世纪90年代，IBM旗下的子公司Taligent在用C/C++开发一个叫CommonPoint的图形界面应用系统的时候提出来的。 MVP（Passive View）的依赖关系MVP模式把MVC模式中的Controller换成了Presenter。MVP层次之间的依赖关系如下： MVP打破了View原来对于Model的依赖，其余的依赖关系和MVC模式一致。 MVP（Passive View）的调用关系既然View对Model的依赖被打破了，那View如何同步Model的变更？看看MVP的调用关系： 和MVC模式一样，用户对View的操作都会从View交移给Presenter。Presenter会执行相应的应用程序逻辑，并且对Model进行相应的操作；而这时候Model执行完业务逻辑以后，也是通过观察者模式把自己变更的消息传递出去，但是是传给Presenter而不是View。Presenter获取到Model变更的消息以后，通过View提供的接口更新界面。 关键点： View不再负责同步的逻辑，而是由Presenter负责。Presenter中既有应用程序逻辑也有同步逻辑。 View需要提供操作界面的接口给Presenter进行调用。（关键） 对比在MVC中，Controller是不能操作View的，View也没有提供相应的接口；而在MVP当中，Presenter可以操作View，View需要提供一组对界面操作的接口给Presenter进行调用；Model仍然通过事件广播自己的变更，但由Presenter监听而不是View。 MVP模式，这里也提供一个用JavaScript编写的例子。 MVP（Passive View）的优缺点优点： 便于测试。Presenter对View是通过接口进行，在对Presenter进行不依赖UI环境的单元测试的时候。可以通过Mock一个View对象，这个对象只需要实现了View的接口即可。然后依赖注入到Presenter中，单元测试的时候就可以完整的测试Presenter应用逻辑的正确性。这里根据上面的例子给出了Presenter的单元测试样例。 View可以进行组件化。在MVP当中，View不依赖Model。这样就可以让View从特定的业务场景中脱离出来，可以说View可以做到对业务完全无知。它只需要提供一系列接口提供给上层操作。这样就可以做到高度可复用的View组件。 缺点： Presenter中除了应用逻辑以外，还有大量的View-&gt;Model，Model-&gt;View的手动同步逻辑，造成Presenter比较笨重，维护起来会比较困难。 MVP（Supervising Controller）上面讲的是MVP的Passive View模式，该模式下View非常Passive，它几乎什么都不知道，Presenter让它干什么它就干什么。而Supervising Controller模式中，Presenter会把一部分简单的同步逻辑交给View自己去做，Presenter只负责比较复杂的、高层次的UI操作，所以可以把它看成一个Supervising Controller。 Supervising Controller模式下的依赖和调用关系 因为Supervising Controller用得比较少，对它的讨论就到这里为止。 MVVMMVVM可以看作是一种特殊的MVP（Passive View）模式，或者说是对MVP模式的一种改良。 历史背景MVVM模式最早是微软公司提出，并且了大量使用在.NET的WPF和Sliverlight中。2005年微软工程师John Gossman在自己的博客上首次公布了MVVM模式。 ViewModelMVVM代表的是Model-View-ViewModel，这里需要解释一下什么是ViewModel。ViewModel的含义就是 “Model of View”，视图的模型。它的含义包含了领域模型（Domain Model）和视图的状态（State）。 在图形界面应用程序当中，界面所提供的信息可能不仅仅包含应用程序的领域模型。还可能包含一些领域模型不包含的视图状态，例如电子表格程序上需要显示当前排序的状态是顺序的还是逆序的，而这是Domain Model所不包含的，但也是需要显示的信息。 可以简单把ViewModel理解为页面上所显示内容的数据抽象，和Domain Model不一样，ViewModel更适合用来描述View。 MVVM的依赖MVVM的依赖关系和MVP依赖，只不过是把P换成了VM。 MVVM的调用关系MVVM的调用关系和MVP一样。但是，在ViewModel当中会有一个叫Binder，或者是Data-binding engine的东西。以前全部由Presenter负责的View和Model之间数据同步操作交由给Binder处理。你只需要在View的模版语法当中，指令式地声明View上的显示的内容是和Model的哪一块数据绑定的。当ViewModel对进行Model更新的时候，Binder会自动把数据更新到View上去，当用户对View进行操作（例如表单输入），Binder也会自动把数据更新到Model上去。这种方式称为：Two-way data-binding，双向数据绑定。可以简单而不恰当地理解为一个模版引擎，但是会根据数据变更实时渲染。 也就是说，MVVM把View和Model的同步逻辑自动化了。以前Presenter负责的View和Model同步不再手动地进行操作，而是交由框架所提供的Binder进行负责。只需要告诉Binder，View显示的数据对应的是Model哪一部分即可。 这里有一个JavaScript MVVM的例子，因为MVVM需要Binder引擎。所以例子中使用了一个MVVM的库：Vue.js。 MVVM的优缺点优点： 提高可维护性。解决了MVP大量的手动View和Model同步的问题，提供双向绑定机制。提高了代码的可维护性。 简化测试。因为同步逻辑是交由Binder做的，View跟着Model同时变更，所以只需要保证Model的正确性，View就正确。大大减少了对View同步更新的测试。 缺点： 过于简单的图形界面不适用，或说牛刀杀鸡。 对于大型的图形应用程序，视图状态较多，ViewModel的构建和维护的成本都会比较高。 数据绑定的声明是指令式地写在View的模版当中的，这些内容是没办法去打断点debug的。 结语可以看到，从MVC-&gt;MVP-&gt;MVVM，就像一个打怪升级的过程。后者解决了前者遗留的问题，把前者的缺点优化成了优点。同样的Demo功能，代码从最开始的一堆文件，优化成了最后只需要20几行代码就完成。MV*模式之间的区分还是蛮清晰的，希望可以给对这些模式理解比较模糊的同学带来一些参考和思路。 ReferencesScaling Isomorphic Javascript CodeSmalltalk-80 MVCLearning JavaScript Design PatternsSmalltalk-80 MVC in JavaScriptGUI ArchitecturesThe Model-View-Presenter (MVP) PatternBusiness and application logic?Business logic in MVC"},{"title":"CommonJS-AMD-CMD-ES6","permalink":"https://kricsleo.github.io/CommonJS-AMD-CMD/","text":"JavaScript 模块化远古时期, 我们写的 js 都是都是通过 script 标签进行管理, 这使得项目一旦复杂, 页面内便会写上成堆的 script 标签来引入各种外部 js 文件, 而且我们还需要保证 js 的顺序, 因为一个 js 文件内的方法往往依赖另外的 js 来实现, 我们通过确保书写顺序来确保 js 的加载顺序, 这当然是极不方便的, 后来前端工程师们就开始了尝试 js 模块化的探索之旅. 什么是模块化 在了解这些规范之前，还是先了解一下什么是模块化。模块化是指在解决某一个复杂问题或者一系列的杂糅问题时，依照一种分类的思维把问题进行系统性的分解以之处理。模块化是一种处理复杂系统分解为代码结构更合理，可维护性更高的可管理的模块的方式。可以想象一个巨大的系统代码，被整合优化分割成逻辑性很强的模块时，对于软件是一种何等意义的存在。对于软件行业来说：解耦软件系统的复杂性，使得不管多么大的系统，也可以将管理，开发，维护变得“有理可循”。还有一些对于模块化一些专业的定义为：模块化是软件系统的属性，这个系统被分解为一组高内聚，低耦合的模块。那么在理想状态下我们只需要完成自己部分的核心业务逻辑代码，其他方面的依赖可以通过直接加载被人已经写好模块进行使用即可。首先，既然是模块化设计，那么作为一个模块化系统所必须的能力：定义封装的模块。定义新模块对其他模块的依赖。可对其他模块的引入支持。好了，思想有了，那么总要有点什么来建立一个模块化的规范制度吧，不然各式各样的模块加载方式只会将局搅得更为混乱。那么在JavaScript中出现了一些非传统模块开发方式的规范 CommonJS的模块规范，AMD（Asynchronous Module Definition），CMD（Common Module Definition）等。 –文章 CommonJSCommmonsJS是同步加载模块的, 例如如下代码: // foobar.js// 私有变量var test = 123; // 公有方法function foobar () &#123; this.foo = function () &#123; // do someing ... &#125; this.bar = function () &#123; //do someing ... &#125;&#125; // exports对象上的方法和变量是公有的var foobar = new foobar();exports.foobar = foobar; // test.js// require方法默认读取js文件，所以可以省略js后缀var test = require('./boobar').foobar; test.bar(); CommonJS规定一个单独的 js 文件就是一个模块, 在 js 文件中引入其他的模块需使用关键字require, 例如require(&#39;./a&#39;), 该方法会根据读取这个文件然后返回这个文件内部的exports对象, 文件内需要导出的东西使用关键字exports, 例如exports.foobar = foobar, 需要注意的是CommonJS 是同步加载模块的, 也就是说会在模块加载完毕之后再去执行接下里的代码, 会阻塞 js 的线程, 对于像 Node.js 这样的服务端, 因为各个模块文件都存在本地硬盘上, 加载起来很快, 所以阻塞的时间很短, 属于可以接受的程度, 但是对于浏览器端, 需要通过网络下载下来各个依赖文件, 这个阻塞的时间就比较长了, 所以 CommonJS一般用在 Node.js 中, 同时也因为 Node.js 发扬光大. 那么在浏览器端为了实现异步加载模块, 就产生了 AMD 和 CMD 解决方案. AMDAMD 全称是”Asynchronous Module Definition”, 中文名是”异步模块定义” AMD 定义模块AMD 定义了一个简洁实用的 api, define(id, dependencies?, factory);第一个参数id为字符串类型, 表示模块标志, 为可选参数, 如果不存在则模块标识应该默认定义为在加载器中被请求脚本的标识。如果存在，那么模块标识必须为顶层的或者一个绝对的标识。第二个参数dependencies为数组类型, 表示当前模块所依赖的模块的模块标识.第三个参数factory是一个需要实例化的函数或者一个对象. 可以使用这个 api 进行灵活的模块定义: 定义无依赖的模块 define( &#123; add : function( x, y )&#123; return x + y ; &#125;&#125; ); 定义有依赖的模块 define(['alpha'], function(alpha) &#123; return &#123; verb: function() &#123; return alpha.verb() + 1; &#125; &#125;&#125;); 定义数据对象模块 define(&#123; users: [], members: []&#125;); 具名模块 define('alpha', ['require', 'exports', 'beta'], function(require, exports, beta) &#123; exports.verb = function() &#123; return beta.verb(); // or // return require('beta').verb(); &#125;&#125;); 包装模块 define(function(require, exports, module) &#123; var a = require('a'); exports.action = function() &#123;&#125;&#125;); 除了define外，AMD 还保留一个关键字require. require 作为规范保留的全局标识符，可以实现为 module loader，也可以不实现。AMD模式可以用于浏览器环境并且允许非同步加载模块，也可以按需动态加载模块。 AMD 使用模块api: require(dependencies, callback);第一个参数dependencies为数组类型, 里面是当前回调函数需要依赖的模块第二个参数callback为回调函数, 当依赖加载完毕之后会执行这个回调函数, 函数的参数就是所加载的模块, 可在函数中使用例如: require(['math'], function(math)) &#123; math.add(2, 3);&#125;); AMD 规范的实现者 RequireJSRequireJS 是一个前端的模块化管理的工具库，遵循AMD规范，它的作者就是AMD规范的创始人 James Burke。所以说RequireJS是对AMD规范的阐述一点也不为过。 RequireJS的思想是通过一个函数将所有需要的或者依赖的模块加载进来, 然后返回一个新的函数(或者模块), 我们所有关于新模块的业务代码都在这个函数里面进行, 其内部也可以无限制的使用已经加载进来的模块. &lt;script data-main='scripts/main' src='scripts/require.js'&gt;&lt;/script&gt; 那么scripts下的main.js则是指定的主代码脚本文件，所有的依赖模块代码文件都将从该文件开始异步加载进入执行。RequireJS 的定义define和使用require都与之前说的 AMD 规范一致. CMDCMD 规范seajs CMD是SeaJS 在推广过程中对模块定义的规范化产出, 特点有如下两点: 对于依赖的模块, AMD 是提前执行, 而 CMD 是延迟执行. (不过RequireJS从2.0开始，也改成可以延迟执行, 根据写法不同，处理方式不同.) AMD 推崇依赖前置, CMD 推崇依赖就近 对比: // AMDdefine(['./a', './b'], function() &#123; // 依赖一开始就写好 a.test(); b.test();&#125;);// CMDdefine(function(require, exports, module) &#123; // 依赖就近 var a = require('./a'); a.test(); // 软依赖 if(status) &#123; var b = require('./b'); b.test(); &#125;&#125;) AMD也支持 CMD 的写法, 但依赖前置是官方的推荐做法AMD 的 api 是一个当多个用, CMD 严格的区分推崇职责单一, 例如 AMD 里面的require 分为全局的和局部的, 但是 CMD 里面没有全局的 require, 提供 seajs.use()来实现模块系统的加载启动. UMDUMD 是 CommonJS 和 AMD 的融合. AMD模块以浏览器第一的原则发展，异步加载模块。CommonJS模块以服务器第一原则发展，选择同步加载，它的模块无需包装(unwrapped modules)。这迫使人们又想出另一个更通用的模式UMD （Universal Module Definition）。希望解决跨平台的解决方案。 UMD先判断是否支持Node.js的模块（exports）是否存在，存在则使用Node.js模块模式。在判断是否支持AMD（define是否存在），存在则使用AMD方式加载模块。 判断过程如下: (function(window, factory) &#123; if(typeof exports = 'object') &#123; module.exports = factory(); &#125; else if(typeof define === 'function' &amp;&amp; define.amd) &#123; define(factory); &#125; else &#123; window.eventUtil = factory(); &#125;&#125;)(this, function()&#123; // module...&#125;) ES6 模块化经历了那么多探索以后, ES6终于在语言层面引入了模块化, 旨在成为服务端和浏览器端通用的解决方案, 模块功能主要由两个命令构成, export和import, export命令用于规定模块的对外接口，import命令用于输入其他模块提供的功能。 // 定义模块 module.jslet basicNum = 0;const add = funtion(a, b) &#123; return a + b;&#125;export &#123; basicNum, add&#125;;// 引入模块import &#123; basicNum, add &#125; from './module';function foo() &#123; return add(2, basicNum);&#125; 这种引入方式你需要知道模块内部导出的内容的具体名字, 在你引入的时候需要一字不差的对应上名字, 有很多时候我们并不想去模块内部查看它到底是用的什么名字, 这个时候 ES6 贴心的为我们额外提供了一个export default, 为模块指定一个默认输出, 对应的import不需要使用大括号, 这更加接近AMD 的引用写法. // 定义模块 module.jslet basicNum = 0;const add = funtion(a, b) &#123; return a + b;&#125;export default &#123; basicNum, add &#125;;// 引入模块import module from './module';function foo() &#123; return module.add(2, module.basicNum);&#125; 需要注意的是ES6的模块不是对象, 它的import会被 JavaScript 引擎静态分析, 在编译的时候就引入模块代码, 而不是在运行的时候加载, 所以也就无法实现条件加载. 但是好处是这使得对代码进行静态分析成为可能. ES6模块与 CommonJS 的差异 CommonJS 输出的是一个值得拷贝, ES6输出的是一个值的引用 CommonJS 输出的是一个值的拷贝, 也就是说一旦已经输出, 那么模块内部之后再发生变动也不会影响这个已经输出的值.ES6的运行机制和 CommonJS 不一样, 当 js 引擎在进行静态分析的时候如果发现import那么就会生成一个对应模块的只读引用, 只有在运行的时候才根据这个引用到对应的模块去取值。 换句话说，ES6 的import有点像 Unix 系统的“符号连接”，原始值变了，import加载的值也会跟着变。因此，ES6 模块是动态引用，并且不会缓存值，模块里面的变量绑定其所在的模块。 CommonJS 是运行时加载, ES6是编译时输出接口 运行时加载: CommonJS模块是对象, 即在输入时先加载整个模块, 生成一个对象, 然后再从这个对象上面读取方法, 这种加载称为’运行时加载’ 编译时加载: ES6模块不是对象, 而是通过export命令显示指定输出的代码, import时采取静态命令的形式, 即在import时指定加载某个值, 而不是加载整个模块, 这种加载称为’编译时加载’. 参考文章玉伯的回答模块化七日谈我是豆腐不是渣的文章"},{"title":"AST","permalink":"https://kricsleo.github.io/AST/","text":"ASTAST 简介 在计算机科学中, 抽象语法树(Abstract Syntax Tree, AST)或者简称语法树(Syntax Tree)是源代码语法解构的一种抽象表现, 它以树状的形式表现编程语言的语法结构，树上的每个节点都表示源代码中的一种结构. – 维基百科 而在 JavaScript 中我们通过 JavaScript Parser 把代码转化为一颗抽象语法树（AST），这颗树定义了代码的结构，通过操纵这颗树，我们可以精准的定位到声明语句、赋值语句、运算语句等等，实现对代码的分析、优化、变更等操作. 然后浏览器会把 js 源码通过解析器转为抽象语法树，再进一步转化为字节码或直接生成机器码. – 简书文章 关于 Vue 的语法树解析可以查看这里 AST 生成过程总的来说一段源代码在执行之前会经历如下过程: 分词 / 词法分析: 将一个语句中的关键词进行提取, 例如let a = 3;, 分词提取之后得到let, a, =, 3, ; 解析 / 语法分析: 在对上面已经被拆分提取过的关键词进行分析之后建立一课语法树(AST), 效果可参见下面 底层代码生成: 得到语法树之后执行引擎(例如 chrome 的 v8引擎)会对这颗树进行一定的优化分析, 然后生成更底层的代码或者机器指令交由机器执行 无图不真相, 我们借助一个在线的可视化工具或者esprima来具体看一下过程, 对于如下代码进行生成 AST 树 源码: var a = 42;var b = 5;function addA(d) &#123; return a + d;&#125;var c = addA(2) + b; 词法分析结果 Keyword(var) Identifier(a) Punctuator(=) Numeric(42) Punctuator(;) Keyword(var) Identifier(b) Punctuator(=) Numeric(5) Punctuator(;) Keyword(function) Identifier(addA) Punctuator(() Identifier(d) Punctuator()) Punctuator(&#123;)Keyword(return) Identifier(a) Punctuator(+) Identifier(d)Punctuator(;)Punctuator(&#125;) Keyword(var) Identifier(c) Punctuator(=) Identifier(addA) Punctuator(()Numeric(2) Punctuator()) Punctuator(+) Identifier(b) Punctuator(;) 生成 AST 树 或者我们可以使用 json 格式来查看 &#123; \"type\": \"Program\", \"body\": [ &#123; \"type\": \"VariableDeclaration\", \"declarations\": [ &#123; \"type\": \"VariableDeclarator\", \"id\": &#123; \"type\": \"Identifier\", \"name\": \"a\" &#125;, \"init\": &#123; \"type\": \"Literal\", \"value\": 42, \"raw\": \"42\" &#125; &#125; ], \"kind\": \"var\" &#125;, &#123; \"type\": \"VariableDeclaration\", \"declarations\": [ &#123; \"type\": \"VariableDeclarator\", \"id\": &#123; \"type\": \"Identifier\", \"name\": \"b\" &#125;, \"init\": &#123; \"type\": \"Literal\", \"value\": 5, \"raw\": \"5\" &#125; &#125; ], \"kind\": \"var\" &#125;, &#123; \"type\": \"FunctionDeclaration\", \"id\": &#123; \"type\": \"Identifier\", \"name\": \"addA\" &#125;, \"params\": [ &#123; \"type\": \"Identifier\", \"name\": \"d\" &#125; ], \"body\": &#123; \"type\": \"BlockStatement\", \"body\": [ &#123; \"type\": \"ReturnStatement\", \"argument\": &#123; \"type\": \"BinaryExpression\", \"operator\": \"+\", \"left\": &#123; \"type\": \"Identifier\", \"name\": \"a\" &#125;, \"right\": &#123; \"type\": \"Identifier\", \"name\": \"d\" &#125; &#125; &#125; ] &#125;, \"generator\": false, \"expression\": false, \"async\": false &#125;, &#123; \"type\": \"VariableDeclaration\", \"declarations\": [ &#123; \"type\": \"VariableDeclarator\", \"id\": &#123; \"type\": \"Identifier\", \"name\": \"c\" &#125;, \"init\": &#123; \"type\": \"BinaryExpression\", \"operator\": \"+\", \"left\": &#123; \"type\": \"CallExpression\", \"callee\": &#123; \"type\": \"Identifier\", \"name\": \"addA\" &#125;, \"arguments\": [ &#123; \"type\": \"Literal\", \"value\": 2, \"raw\": \"2\" &#125; ] &#125;, \"right\": &#123; \"type\": \"Identifier\", \"name\": \"b\" &#125; &#125; &#125; ], \"kind\": \"var\" &#125; ], \"sourceType\": \"script\"&#125; AST的作用除了帮助执行引擎去生成底层的代码, AST 在我们常见的代码检查工具或者 webpack 中都可以用来作为代码分析的依据, 通过遍历 AST 树, 找出其中的隐藏问题, 或者提出优化的建议, 又或者是代码高亮或者代码压缩都是在分析这颗树的基础上进行的 浏览器渲染过程首先我们看一下浏览器的深层结构: 用户界面-包括地址栏, 返回按钮等 UI 组件, 除了主窗口 浏览器引擎-用来查询和操作渲染引擎的接口 渲染引擎-负责渲染请求的内容. 比如, 如果请求的资源是html, 那么渲染引擎负责解析 html 和 css, 然后把解析结果渲染到页面中 js 引擎-用来解析执行 JavaScript 代码 网络连接-用于处理网络请求, 如 http 请求. 这一部分是跨平台的 UI 后台-用于渲染基础组件, 比如多选框和窗口等, 它暴露了一个不是特定平台的通用接口, 在底层调用了操作系统的用户接口 数据存储-这是一个持久层. 浏览器在硬盘中存储各式数据, 比如 cookie , localStorage 等 各个组件的关系如下: 我们需要注意的是, js 引擎是单线程的, 但是浏览器是多线程的, 比如浏览器会同时开启js 引擎线程, 界面渲染线程, 事件触发线程, http 请求线程 HTML5提出Web Worker标准，允许JavaScript脚本创建多个线程，但是子线程完全受主线程控制，且不得操作DOM。所以，这个新标准并没有改变JavaScript单线程的本质。 接下来我们着重看一下渲染引擎所做的工作:总的过程是: 解析HTML并构建DOM树 =&gt; 构建render树 =&gt; render树布局 =&gt; render树绘制浏览器引擎开始解析 html, 并把标签转为内容树中的 dom 节点, 同时它也开始解析 css, 外链的 css 以及文件内的 css, 所有这些样式数据以及 html 中的可见性指令都用来构建另外一棵树, – render 树我们以Safari 和 chrome 使用的Webkit 引擎渲染过程如下:firefox使用的Gecko 引擎渲染过程如下: 此小节内容参考与 segmentfault 上cucumber翻译的文章:浏览器工作过程详解（译）（一）浏览器工作过程详解（译）（二）"},{"title":"js-object","permalink":"https://kricsleo.github.io/js-object/","text":"JavaScript的内存机制及按值传递JavaScript是一门轻级的编程语言, 我之前也用过C++和Java, 相比起来JavaScript是一门年轻简约的编程语言, 但是我很看好这门语言, 我记得之前看过一个大牛说现在的前端开发是黎明前的黑暗, 在数年之内必定会清晰明朗起来. 自己深表赞同, JavaScript现在的确是有很多的缺陷, 相比较起来它的依赖库也不如java那般丰富, 但是它一个最大的优点(个人认为)就是它的轻量级, 你仅仅需要一个浏览器(或者Node环境, 但是Node其实也是基于Chrome的V8引擎), 他就能完成自己所有的工作, 我坚信随着各种标准的制定以及已经走在探索路上的前端开发师们能够很快为JavaScript带来它起飞的春天. 上面是我的个人希冀, 说到这篇文章, 主要是记录一下JavaScript的内存机制以及按值传递规则, 因为我在JavaScript的开发过程中会不由自主的把它和我也使用过的C++和Java进行比较, 我认为编程语言是互通的, 但是它们在某些细节上的处理有所不同, 则正是我们需要去注意的. 内存机制在JavaScript中有堆和栈两个存储概念, 堆是用来存储Object型数据的 ,栈是用来存储6种基本数据类型(分别是null, undefined, boolean, number, string和ES6中新引入的symbol), 对于我们平时使用的数组Array其实是Object的继承而已, 可以使用typeof运算符查看一个数据的类型, 例如typeof []就会输出object, 另外一个比较特别的就是函数类型, 函数类型的typeof输出的是function, 但是函数其实也是存储在堆中的, 而且可以认为是以字符串的形式存储的. 为什么有堆和栈之分与垃圾回收机制有关，为了使程序运行时占用的内存最小。当一个方法执行时，每个方法都会建立自己的内存栈，在这个方法内定义的变量会逐个放入这块栈内存里，随着方法的执行结束，这个方法的内存栈也将自然销毁了。因此，所有在方法中定义的变量都是放在栈内存中的;当我们在程序中创建一个对象时，这个对象将被保存到运行时数据区中，以便反复理由(因为对象的创建成本通常比较大),这个运行时数据区就是堆内存。堆内存中的对象不会随方法的结束而销毁，即使方法结束后，这个对象还可能被另一个引用变量所引用(方法的参数传递时很常见),则这个对象依然不会被销毁,只有当一个对象没有任何引用变量引用它时,系统的垃圾回收机制才会在核实的时候回收它。 –参考 在我们知道了JavaScript中的对象是如何存储的之后, 我们就要看一下当我们生成一个变量的时候到底发生了什么. 生成变量假如我们生成的是一个存储基本数据类型的变量, 例如let a = 3或者let b = &#39;hello&#39;, 那么有如下两步: 在栈中直接开辟出一小块空间 把你赋予的数据(3或者hello)存储到这个栈空间中 也就是说数据是直接存储在栈中, 但是当我们生成的是一个存储了对象类型的变量, 例如let c = {name: &#39;krics&#39;}, 那么这个时候过程就要复杂一些: 在堆中开辟一块空间 把你赋予的数据{name: &#39;krics&#39;}存储到这个堆空间中 在栈中开辟一小块空间 将之前存储了对象数据的堆空间的地址(指针形式)存储到现在刚刚开辟的这个栈空间中 所以我们真正的数据其实是存储在堆中的, 我们拿到的c变量里面只是存储了数据的真实地址, 当我们需要访问或者操作数据的时候, JavaScript就会根据这个地址去找到对应的数据, 然后访问或者操作它. 值的拷贝我们需要永远记住最关键的一点: JavaScript中只存在按值传递!!!不同于C++中或者Java中经常出现的指针操作, 在JavaScript中不会出现按引用传递, JavaScript永远只操作一个变量最直接的值, 并不会考虑这个值是基本数据类型还是一个指针, 因为如果是指针, 也并不会去按照指针找到具体的数据, 然后拷贝数据什么的, 是指针, 那我就传递这个指针的字面值, 简单粗暴明了. 例如: let a = 'hello';let b = a;b = 'yell';console.log(a); // =&gt; 'hello'console.log(b); // =&gt; 'yell' 这里发生的故事是: 在栈中开辟了一个空间叫a, 然后在a里面存入了一个字符串hello 在栈中开辟了一个空间叫b, 然后在b里面存入了一个字符串hello(按值传递, 值是hello, 那么就再存一个hello) 修改栈中b的值为yell 输出a的值, 没被改变过, 所以输出hello 输出b的值, 先是hello, 后来被改成了yell, 那么最后输出的就是yell 那么我们举一个对象的例子又如何呢? let c = &#123;name: 'krics'&#125;;let d = c;c.name = 'leo';console.log(d.name); // =&gt; 'leo'd.name = 'troy';console.log(c.name); // =&gt; 'troy' 这里发生的故事是: 先在栈中开辟一块空间名字叫做c, 然后在堆中开辟一块空间, 存入数据{name: &#39;krics&#39;}, 然后把堆中刚存储的数据的地址存到c中 在栈中开辟一块空间名字叫做d, 然后把c中存储的值也就是{name: &#39;krics&#39;}的地址在d中再存储一份 将c指向的对象中的name的值改为字符串leo, d和c指向的是同一个对象, 所以第三步中通过c改了name的值以后, 通过d访问这个name时得到的也是改变后的值leo 第五和第六步与第三和第四步做法类似 这里给出一个很有趣的思考题: var a = &#123;n:1&#125;;var b = a; a.x = a = &#123;n:2&#125;;console.log(a.x); // =&gt; 想想这里 a.x 的值是什么console.log(b.x); // =&gt; 想想这里 b.x 的值是什么 这里给个提示, 上面主要涉及到三个细节点, 一是JavaScript中正常运算顺序为从右到左, 二是.点运算符的优先级高于=等号, 三就是我们之前讨论过的对象如何赋值问题, 答案可以参考luoqua的文章 最后我仍然要强调一点: JavaScript中只存在按值传递!!!(可以参考&lt;JavaScript高级程序设计&gt;一书中第四章’变量. 作用域和内存问题’)"},{"title":"bash","permalink":"https://kricsleo.github.io/bash/","text":"常用的bash命令 删除文件rm -f &lt;file&gt;rm -rf &lt;folder&gt;# 参数说明:# -r: 删除目录下所有文件, 包括目录本身# -f: 强制删除, 不确认# 移动文件mv &lt;originFile&gt; &lt;destDir&gt;# 使用 scp 从本地拷贝文件到远程服务器, 参数调换即可反向拷贝# 参数: 添加 -r 代表文件目录拷贝scp &lt;localFile&gt; username@hostname:&lt;remoteDir&gt; # linux查询系统版本lsb_release -a# 查看网络端口占用netstat -antp# 开启 nginx 在 nginx 目录下./sbin/nginx# 关闭 nginx./sbin/nginx -s stop mac清除 dns 缓存sudo killall mDNSResponder"},{"title":"flex","permalink":"https://kricsleo.github.io/flex/","text":"flex布局关于flex布局的笔记"},{"title":"vue","permalink":"https://kricsleo.github.io/vue/","text":"Vue 学习笔记最近开始学习 Vue 了, 在这里记录一下学习笔记. 最近像没头的苍蝇一样盯着 Vue, 感觉好些地方不甚了解, 博客也搁置了快五天没动过笔了… Vue.extend()和Vue.component()两者都是使用参数来返回一个构建模板的构造方法, 不同的是vue.extend()返回的是一个匿名的构造器, 需要自己接收返回值注册名字, vue.component()可以在生成构造的函数的时候将组件名绑定上去, 所以后者可以看做是前者的语法糖. –参考 Vue.set(target, prop, value)给实例添加动态响应的属性, 注意 target 不能是实例本身或者实例的根属性, 也就是说你不能给 data 加上根级的属性, 可以给 data 中的对象加上新属性,例如Vue.set(this.$data, &#39;name&#39;, &#39;krics&#39;)是会报错的, 但是Vue.set(this.$data.info, &#39;name&#39;, &#39;krics&#39;)是正确的. 编译在生成单页面的 vue 应用时, 有模板与有 render 函数的区别"},{"title":"Docker","permalink":"https://kricsleo.github.io/docker/","text":"docker学习笔记参考文档Docker是一个开源的引擎，可以轻松的为任何应用创建一个轻量级的、可移植的、自给自足的容器。开发者在笔记本上编译测试通过的容器可以批量地在生产环境中部署，包括VMs（虚拟机）、bare metal、OpenStack 集群和其他的基础应用平台. 如无特殊说明, 以下操作环境均为CentOS 7, 内核版本位3.10.0-693.2.2.el7.x86_64(查看内核版本: uname -r) docker常用命令# 安装dockeryum install -y docker# 启动docker服务service docker start# 给个hello-world的测试例子, 由于本地没有hello-world这个镜像，所以会下载一个hello-world的镜像，并在容器内运行。docker run hello-world# 停止容器docker stop CONTAINER [CONTAINER...]# 启动已经停止的容器docker start CONTAINER [CONTAINER...]# 重启容器docker restart CONTAINER [CONTAINER...]# 删除容器docker rm CONTAINER [CONTAINER...]# 获取容器的输出信息docker logs CONTAINER [CONTAINER...]# 容器文件拷贝到主机docker cp ed0f8bb24f3e:/opt/webapp/app.py d:/www# 参数说明# ed0f8bb24f3e： 容器id# /opt/webapp/app.py: 容器中的文件# d:/www： 主机文件夹# 主机文件拷贝到容器docker cp d:/www/文件 ed0f8bb24f3e:/opt/webapp/ 数据卷docker中使用mysql# 下载mysql镜像docker pull mysql# 查看已下载的镜像# 或 docker image lsdocker images # 从镜像创建并运行一个容器docker run --name first-mysql -p 3306:3306 -e MYSQL\\_ROOT\\_PASSWORD=root -d mysql# 参数说明:# --name 指定容器独一无二的名字# -p mysql容器的端口映射# -e &lt;key=value&gt; 设置进入后可以使用的环境变量，这样动态指定比较灵活# -d 表示使用守护进程, 即服务挂在后台# 查看当前已经运行的容器(可以看到容器id: CONTAINER_ID)docker ps# 进入容器内部(推荐使用exec)docker exec -it CONTAINER_ID /bin/bash# 参数说明# -i 以交互方式运行，是阻塞式的# -t 分配一个伪终端，这个参数通常与-i参数一起使用，然后， 在后面跟上容器里的/bin/bash，这样就把我们带到容器里去了。# -d 以后台方式执行，这样，我们执行完这条命令，还可以干其他事情，写脚本最常用 在我本机连接阿里云上的ECS中的mysql容器时无法连接, 后来排查使用如下解决方案: 编辑ECS的安全组规则把mysql的通信端口3306加入到允许列表中, 如果你是把docker里面的mysql的端口映射到ECS的其它端口, 比如3307, 那么这里你就把这个映射之后的端口3307加入到运行列表即可; 编辑ECS的防火墙ECS的防火墙可能会拦截3306端口的通信, 那么你需要打开这个端口, 让防火墙允许端口通信, 我的ECS系统是CentOS7, 在CentOS7中是使用firewall来管理端口通信的, 那么使用如下方法加入306端口: # 永久加入3306端口firewall-cmd --zone=public --add-port=3306/tcp --permanent# 参数说明:# –zone 作用域# –add-port=80/tcp 添加端口，格式为：端口/通讯协议# –permanent 永久生效，没有此参数重启后失效# 重启防火墙生效firewall-cmd --reload 另外附上常用防火墙命令: # 关闭防火墙systemctl stop firewalld#打开防火墙systemctl start firewalld#查看防火墙状态firewall-cmd --state"},{"title":"Practical-Function-In-Javascript","permalink":"https://kricsleo.github.io/practical-function-in-javascript/","text":"JavaScript中的常用函数本文主要整理了平时JavaScript中常用的函数, 持续更新. 数组Array.concat()作用: 合并数组, 返回新数组, 不影响原数组备注: 字符串中也有此同名函数, 作用可类比 Array.filter()作用: 对数组每个元素进行测试, 返回符合条件的元素组成的新数组, 不影响原数组 Array.find()作用: 返回数组中满足提供的测试函数的第一个元素的值, 否则返回 undefined Array.forEach()作用: 对数组的每个元素执行一次提供的函数, 不影响原数组 Array.includes()作用: 判断数组是否包含某个值, 是则返回true, 否则返回false备注: 字符串中也有此同名函数String.includes(subSring, fromIndex), 用于判断字符串是否包含另一个字符串 Array.indexOf()作用: 返回数组中给定元素的索引值，若给定元素不存在，则返回值是-1备注: 字符串中也有此同名函数, 作用可类比 Array.join()作用: 将数组中的所有元素用给定方式连接成一个字符串，默认用，连接, 可用空字符串&#39;&#39;连接, 返回连接后的字符串, 不影响原数组 Array.map() 作用: 对数组中的每个元素都调用一个提供的函数后返回的结果组成一个新数组, 返回新数组, 不影响原数组 Array.reduce(callback[accumulator, currentValue, currentIndex, array], initialValue)作用: 对累加器和数组中的每个元素（从左到右）应用一个函数，将其减少为单个值, 返回最后的计算结果, 此函数功能强大, 建议参考官方文档 Array.slice()作用: 将数组的制定部分(包括开始位置, 不包括结束位置)浅拷贝到一个新数组, 返回拷贝的新数组, 不影响原数组备注: 字符串中也有此同名函数, 作用可类比 Array.splice()作用: 通过删除现有元素和/或添加新元素来更改一个数组的内容, 返回被删除的元素组成的数组, 如果没有删除, 则返回空数组, 会改变原数组, 此函数功能强大, 建议参考官方文档 字符串String.charAt()作用: 返回字符串中指定位置的字符, 不存在则返回空字符串&quot;&quot; String.charCodeAt()作用: 返回字符串中指定位置的字符的UTF-16代码单元值的数, 在0到65535之间, 超出范围返回NaN String.match()作用: 将字符串与正则表达式匹配, 返回匹配后的结果数组,数组的第一项是进行匹配完整的字符串，之后的项是用圆括号捕获的结果。如果没有匹配到，返回null, 不影响原数组如果给的参数不是正则表达式, 那么会隐式的转换成正则表达式, 此函数功能很强大, 请参考官方文档 备注: RegExp.text()用来测试字符串是否与正则匹配 速度会更快, 如果匹配则返回true, 否则返回falseString.search()也类似test()方法, 只不过返回的值是第一个匹配的地方的索引值, 如果没有匹配则返回-1RegExp.exec()的行为和String.match()很相似, 在非全局匹配下表示一样, 但是对于全局匹配/g他们的表现就不同, 简单来说就是match()的全局匹配会一次找到全部的匹配项放在数组中返回, 但是exec()的全局匹配是每调用一次exec()就返回在上一次执行的基础上继续搜索的下一个匹配结果, 直到最后找不到的时候就会返回null, 参考这里 Sring.replace()作用: 将字符串中的匹配值(字符串或者正则表达式匹配到的值)用另外的值(替换的字符串或者一个方法返回的值)替换, 然后返回新的字符串, 不影响原字符串使用字符串匹配时只会替换第一个匹配的结果关于第二个参数如果使用字符串, 那么$&amp;, $n, ...等能够作为代替匹配的结果字符串使用, 如果使用函数, 那么match, p1, p2, ...能够代替匹配的结果在函数参数中使用, 具体请参见官方文档可使用正则表达式全局匹配实现全局替换, 例如&#39;hello, yello&#39;.replace(/llo/g, &#39;yes&#39;) String.split()作用: 将字符串按照匹配的字符串或者正则表达式进行分割, 返回分割的结果组成的数组, 不影响原字符串关于分割的结果中有时会产生空字符串&#39;&#39;的原因可以参考KevinYue的这篇文章, 评论中的’切黄瓜’的比喻也有助于理解, 另外使用正则表达式时会忽略全局匹配符/g String.substr()作用: 将字符串中从指定位置开始的指定长度(不指定长度则到字符串末尾)的部分拷贝为新字符串返回, 不影响原字符串 String.substring()作用: 将字符串中从指定位置开始(包含)到指定位置结束(不包含)(或者默认到结尾)的部分拷贝伟新字符串返回, 不影响原字符串 String.trim()作用: 返回字符串开头和结尾的空白字符(包括space, tab, no-break space等以及所有行终止符字符如 LF，CR)都移出的新字符串, 不影响原字符串 其他平时的笔记 Object.freeze(obj)冻结一个对象, 冻结了之后这个对象的所有属性都不可被修改, 尝试修改不报错但是会不生效, 返回被冻结之后的对象, 并不是传入参数的一个副本, 而是传入的对象本身, 只是进行了属性冻结. Element.scrollIntoView()HTML5原生的滚动API, 使得一个元素滚动到试图中, 兼容到IE8, 主流浏览器均支持.三种调用形式: element.scrollIntoView(); // 等同于element.scrollIntoView(true) element.scrollIntoView(alignToTop); // Boolean型参数(true代表元素顶部尽可能与浏览器顶部对齐, false代表元素底部尽可能与浏览器底部对齐) element.scrollIntoView(scrollIntoViewOptions); // Object型参数scrollIntoViewOptions里面支持三个参数:&#123; behavior: \"auto\" | \"instant\" | \"smooth\", // 默认 auto, 滚动动画, auto 和 instant 都是无动画立即到底目的位置, smooth 为带动画 block: \"start\" | \"center\" | \"end\" | \"nearest\", // 默认 center, 垂直方向对齐方式, start 顶部对齐, center 中间对齐, end 底部对齐, nearest 就近对齐(意思是现在的位置靠近哪种对齐方式就采用哪种对齐方式, 移动最小) inline: \"start\" | \"center\" | \"end\" | \"nearest\", // 默认 nearest, 水平方向对齐方式, 具体参数含义和 block 类似&#125; 参考文档1"},{"title":"Mini-Program","permalink":"https://kricsleo.github.io/Mini-Program/","text":"微信小程序跳坑记录开发微信小程序还是踩了不少坑的, 官方的文档并不详细, 更新也不及时, 碰到问题还是多 google 吧. 摘要小程序的逻辑层和渲染层是分开的, 逻辑层运行在 JSCore 中 并没有一个完整的浏览器对象, 因而缺少相关的 DOM API 和 BOM API.小程序的运行环境 –参考 运行环境 逻辑层 渲染层 IOS JavaScriptCore WKWebView 安卓 2 X5 J\bSCore X5 浏览器 开发工具 NWJS Chrome WebView 小程序的 Native 和 js 之间的交互是通过 JSBridge 实现小程序的视图线程和服务线程的交互生命周期 小程序的文件编译过程: WXml -&gt; js -&gt; Virtual DOM -&gt; DOM Tree WXSS -&gt; js -&gt; CSS 数据绑定微信小程序通过状态模式-单向数据流来实现数据绑定.状态模式定义一个对象, 当对象发生改变时, 状态就发生改变, 然后通知与之绑定的视图刷新, 注意: 数据流向是单向的, \b 即视图变化不会引起对象状态变化.如果想要视图改变的时候让对象状态也一并改变, 那么就需要依赖事件来实现, 即视图变化 -&gt; 触发事件 -&gt; 捕获事件 -&gt; 回调处理(在这里可以操作对象) 生命周期小程序整个小程序有三个生命阶段: 小程序初始化完成时: onLaunch 小程序启动，或从后台进入前台显示时: onShow 小程序从前台进入后台时: onHide 关于小程序的销毁有如下机制: 点击左上角关闭或者’Home’键离开微信, 小程序将在后台运行, 只有在后台超过一定时间或者系统内存占用过高时才会真正销毁小程序 –参考 页面栈目前页面栈最大深度是 10 层 –来源一旦达到 10 层, 将无法再使用wx.navigatoTo()或同等方式打开新页面, 必须使用其他方式清除一定的栈空间以后才能再打开新页面 路由方式: 五种 wx.navigateTo()或者点击&lt;navigator open-type=&quot;navigateTo&quot;/&gt;组件页面栈变化: 仅目标页面(不能是tab页)入栈 wx.navigateBack()或者点击&lt;navigator open-type=&quot;navigateBack&quot;&gt;组件或者点击左上角返回按钮页面栈变化: 仅源页面出栈备注: 该方法可在参数(Ojbject)中额外附加一个 Number 型参数delta, 表示返回的页面数, 也就是要退几次页面栈, 如果delta大于当前栈数, 则返回首页 wx.redirectTo()或者点击&lt;navigator open-type=&quot;redirectTo&quot;/&gt;组件页面栈变化: 源页面出栈 -&gt; 目标页面(不能是tab页)入栈 wx.switchTab()或者点击&lt;navigator open-type=&quot;switchTab&quot;/&gt;组件页面栈变化: 清空页面栈 -&gt; 目标页面(必须是tab页)入栈 wx.reLaunch()或者点击组件&lt;navigator open-type=&quot;reLaunch&quot;/&gt;组件页面栈变化: 清空页面栈 -&gt; 目标页面(任意页面)入栈 同一页面如果被压栈多次, 那么就会在栈中相应的存在多次, 相当于页面顺序浏览的历史记录 页面生命周期从页面栈的变化解释页面的生命周期: 页面刚入栈在栈顶: onLoad -&gt; onShow -&gt; onReady 页面从栈顶被压栈到第二层: onHide 页面从栈的第二层到最底层之间活动: 无事件 页面退栈刚到栈顶: onShow 页面从栈顶出栈: onUnload (注意: 页面出栈即被销毁, 不会触发onHide, 直接触发onUnload) 一个页面要正常显示，必须经历 3 个生命周期：加载 -&gt; 显示 -&gt; 渲染, 对应回调函数顺序:onLoad -&gt; onShow -&gt; onReady.官方给出的示例中onReady放在onShow之前, 但是这并不是真正的顺序, 容易误导开发者 组件 hidden 属性首先强调一点: 不要使用hidden属性! 语法正确的写法是hidden=&quot;true&quot;和hidden=&quot;false&quot;, 遵循Mustache语法, 双大括号不能省略, 因为hidden的值是Boolean型的, 必须使用Mustache计算值才行, 如果省略了双大括号, 比如hidden=&quot;false&quot;(填写其它内容也一样)), 那么就会把&quot;false&quot;作为字符串处理, 此时字符串不为空, 那么结果就是true, 此组件仍然会被隐藏. 为什么不要使用该属性hidden属性的表现相当怪异.根据不完全测试, 在view, navigator等组件上表现为会给你的组件添加一个 css 属性display: none;, 如果你是通过id或者class来给组件加上自定义的display属性的话, 那么hidden添加的那个display属性优先级比你的高, 此时组件会被隐藏; 如果你是使用的内联样式style=&quot;display: flex;&quot;来给组件添加display属性, 那么你这里添加的display属性优先级会比较高, 此时hidden属性不生效;在button组件上添加hidden=&quot;true&quot;表现为会给你的组件上添加一个 css 属性display: none !important;, 这里相比之前多了!important关键字, 所以此时的hidden属性的优先级是最高的, 不会被你自定义的给覆盖掉;在text组件上又是一种表示了, 如果你为text组件添加hidden=&quot;true&quot;, 那么只要你给这个组件自定义了display属性, 你的优先级就会比hidden的高, hidden处于不生效的状态, 如果你没有自定义, 那么hidden才会生效;基于上面的种种怪异的表现, 已经不需要去测试更多的组件了, 因为这已经有足够充分的理由不去使用hidden属性了. 替代办法我们使用hidden属性无非是想控制组件的显示与否, 那么可以采取如下的替代方案: &lt;view style=\"display: &#123;&#123;isHidden ? 'none' : 'flex'&#125;&#125;;\"&gt;&lt;/view&gt; 备注对于不怎么切换显示隐藏的组件可以使用wx:if, 这样的渲染支出是可以接受的, 但是如果一个组件会经常的切换显示隐藏, 那么最好考虑采取display: &quot;none;&quot;的方法, 因为这样不需要重复渲染组件, 只要切换显示隐藏即可, 可以减少 cpu 支出, 提高页面效率. 官方说法 scroll-view注意：使用竖向滚动时，需要给scroll-view一个固定高度, 否则无法点击回到顶部以及滚动到指定位置 texttext组件内只支持嵌套text requestGET一般都正常, 但是POST请求真可谓是’一千个读者有一千个哈姆雷特’, 各种失败的情况都有, 可尝试如下方法: 首先method是必须设置为POST的; header中设置&quot;Content-Type&quot;: &quot;application/x-www-form-urlencoded&quot;, 也有说小写&quot;content-type&quot;: &quot;application/x-www-form-urlencoded&quot;能成功; data 有说不能直接传json格式, 需要先转格式: function json2Form(json) &#123; var str = []; for(var p in json)&#123; str.push(encodeURIComponent(p) + \"=\" + encodeURIComponent(json[p])); &#125; return str.join(\"&amp;\");&#125;let data = &#123; name: '张三', age: '23'&#125;;const ajaxData = json2Form(data); // 然后将`ajaxData`附在请求的`data`中字段中 也有说服务端必须是https的; 实在不行服务端就改成GET吧… 域名小程序对于服务器的域名有要求, 在开发时如果没有 https 的服务器, 那么 pc 端可以把微信开发工具里的域名校验展示关闭, ios 端打开调试模式运行小程序, 安卓端打不打开调试模式都可以, 之后如果申请到了 https 的服务器, 那么把服务器域名加入到微信管理平台的域名列表中, 然后就可以关闭各种之前调试的东西正常使用了. 源码分析对小程序的源码分析应该会是比较大的工作量, 所以我打算另外用一篇文章来记录, 这里先挖下一个坑 微信小程序源码分析"},{"title":"ASCII-Unicode-UTF8","permalink":"https://kricsleo.github.io/unicode-utf8/","text":"ASCII, Unicode和UTF8之间的关系本文主要了解一下ASCII码、Unicode码和UTF-8码的来源和相互之间的关系, 顺便也理了一下中文编码GB2312, GBK, GB18030的关系。 ASCII码在上世纪60年代，美国制定了ASCII码，主要目的是为了用二进制编码的方式来表达英文字符，用一个8位的字节大小对应了128个字符，其中包括了可打印出来的96个字符和32个不可打印的控制字符, 规则是二进制中第1位固定为0, 后面7位用来编码, 刚好可以表示27 = 128个字符, 例如规定空格SPACE的编码为00100000, 十进制是32, 大写字母A的编码为01000001, 十进制是65, 附上ASCII码表 GB2312, GBK, GB18030 GB2312 是对 ASCII 的中文扩展, 一个小于127的字符的意义与ASCII码相同, 但是当两个大于127的字符连在一起时就表示汉字, 同时GB2312在127之外的地方把ASCII已经有的数字, 标点和字母又重新加入了一遍, 这些重新加入的字符占用两个字节的空间, 也就是说在GB2312中有两套数字, 字母和标点, 码值小于127的那一套因为是ASCII码, 只占用一个字节, 就叫’半角’符号, 而新加入的一套数字, 字母和标点就叫’全角’符号. 因为GB2312只收录了6763个汉字, 很多的汉字也需要加入编码中, 所以微软对GB2312进行了扩展, 规定只要第一个字节大于127, 那么就不管后面一个字节是不是大于127的, 通通都认为这两个字节一起表示了一个汉字, 这样就又增加了近20000个新的汉字（包括繁体字）和符号, 扩充之后就成为GBK标准, 它向下兼容GB2312编码，出现于Windows 95简体中文版中, 但是这个是微软标准, 并不是国家标准. 后来又加入了少数民族文字，于是我们再扩展，又加了几千个新的少数民族的字，GBK扩成了GB18030, GB18030成为了国家标准. Unicode码ASCII码虽然满足了美国的需求,但是对于其它语言而言128个字符是远远不够的, 比如法语中字母上方有注音, 这是ASCII码无法表示的, 又比如汉字有10万左右, 这也是超出了ASCII码的范围, 所以后来Unicode码出现了.Unicode码有着很大的容量, 现在的规模可以容纳100多万个符号, 每个符号的编码都不一样, 比如，U+0639表示阿拉伯字母Ain，U+0041表示英语的大写字母A，U+4E25表示汉字严。你可以使用在线的工具来转换成Unicode码. Unicode码编码方式Unicode码只是定义了每个字符对应的二进制代码是什么, 但是并没有规定字符对应的二进制应该以什么样的形式存储, Unicode统一规定，每个符号用三个或四个字节表示. 比如汉字严的Unicode码是十六进制数4E25, 转换成二进制就是100111000100101一共是15位, 至少占用2个字节的空间, 而其他的字符可能有更多的二进制位数, 而之前的ASCII码是固定为8位的, 如果采取将前面多余的位数全都置0的话, 那么在存储原来的ASCII码编码的文件时就会浪费大量的空间来存储无用的0信息, 这是不可接受的. 所以如何合理的用Unicode码来兼容原先的ASCII码信息就产生出了多种具体的实现方式. UTF-8实现UnicodeUTF-8是目前使用最多的Unicode编码实现方式, 除此之外也有 UTF-16（字符用两个字节或四个字节表示）和 UTF-32（字符用四个字节表示）实现方式, 不过基本不使用.UTF-8 最大的一个特点，就是它是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。按照如下两条规则来编码字符: 对于单(n = 1)字节的符号，字节的第一位设为0，后面7位为这个符号的 Unicode 码。因此对于英语字母，UTF-8 编码和 ASCII 码是相同的。 对于多(n &gt; 1)字节的符号，第一个字节的前n位都设为1，第n + 1位设为0，后面字节的前两位一律设为10。剩下的没有提及的二进制位，全部为这个符号的 Unicode 码。下表总结了编码规则，字母x表示可用编码的位。 Unicode符号范围 | UTF-8编码方式(十六进制) | （二进制）----------------------+---------------------------------------------0000 0000-0000 007F | 0xxxxxxx0000 0080-0000 07FF | 110xxxxx 10xxxxxx0000 0800-0000 FFFF | 1110xxxx 10xxxxxx 10xxxxxx0001 0000-0010 FFFF | 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx 在解码的时候现查看二进制的第一位, 如果是0, 那么说明是单字节的字符, 直接将该字节按照Unicode码表转换成对应的字符即可, 如果第一位是1, 那么继续查看有几个连续的1, 有n个, 则说明连续的n个字节代表一个字符.以汉字严为例, \b严的Unicode码是4E25(二进制为100111000100101), 根据上表, 4E25处于0000 0800 - 0000 FFFF范围, 那么严的编码格式就是1110xxxx 10xxxxxx 10xxxxxx, 也就是说严的UTF-8编码方式就需要占用三个字节, 我们把严的二进制按照顺序填到x的位置, 最后得到的结果就是11100100 10111000 10100101, 转成16进制就是E4B8A5, 这就是严的UTF-8编码结果.总得来说, 严的Unicode码为4E25, UTF-8编码为E4B8A5, 这就好比你的身份证是123456, 在学校站队时老师按照一定的排队方式把你编排到了五组三排第二个, 这两者最后的结果是可以相互转换的, 你可借助在线工具验证. JavaScript中的Unicode与UTF-8javascript程序是使用Unicode字符集编写的, 所以我们在JavaScript中经常使用的字符或者字符串实际上内部是采用Unicode编码的, 在有些情况下, 比如我们的服务器要求接受的二进制内容的编码必须是UTF-8, 那么我们在把JavaScript中的字符串发送到服务器之前就需要进行转码, 将Unicode字符串转为UTF-8字符串. 我们在前端有时候会看到的服务器返回的json数据中乱码实际上就是因为服务器发送数据的编码跟我们客户端接受数据的编码方式不一致导致的, 你可以试着将乱码字段拷贝到在线工具中进行转码, 比如选择将Unicode转为UTF-8, 然后你就能看到正确的信息. 除了数据交互之外, 浏览器的URI也是我们能够了解这种编码转换的地方, 因为URI中的querystring必须按照UTF8的编码进行传输, 但是JavaScript中是Unicode的, 如果没有中文信息还好, 因为英文字符在这两者之间的码值是保持一致的, JavaScript的字符串hello到了URI中也还是hello, 如果你不手动去转换也是ok的, 但是一旦涉及到中文(包括其它非英文字符), 比如汉字严, 它的Unicode码值和UTF-8码值就差的很远, 如果你不进行手动转换, 直接将JavaScript中的字符严丢到地址栏的URI中, 那么就会导致URI乱码, 你再想从URI中把之前放进去的严取出来就会发现得到的根本不是汉字严, 而是一串乱码. 在JavaScript中如何转换Unicode与UTF-8 浏览器提供了三对方法来进行编码转换,escape/unescape, encodeURI/decodeURI和encodeURIComponent/decodeURIComponent. 第一对escape/unescape是非标准的, 已经被废弃, 这里只说一下它的转码方式, escape在处理大于127的字符时是在字符的Unicode码前面直接加上一个%u, 例如严的Unicode码为4E25, 那么escape(&#39;严&#39;)的结果就是%u4E25, 再次强调, 请不要使用escape/unescape, 它已被废弃; 第二对encodeURI/decodeURI是用来给整个URL进行转码的, 它不会转义&amp;, ?, /, =这样的功能字符; 第三对encodeURIComponent/decodeURIComponent是用来给URL的部分字段进行转码的, 它会对&amp;, ?, /, =这些特殊字符进行转义, 一般用来处理key-value形式的query字段.encodeURI和encodeURIComponent都是先将非英文字符的Unicode码转为UTF-8码, 然后在每个字节前面都加上一个%, 比如汉字严的Unicode码是4E25, 使用encodeURI编码时会先转成UTF-8码E4 B8 A5, 在用%连接起来就得到最后结果%E4%B8%A5.//编码encodeURIComponent('严'); // =&gt; '%E4%B8%A5'//解码decodeURIComponent('%E4%B8%A5'); // =&gt; '严'//encodeURI和encodeURIComponent对比encodeURI('www.kricsleo.com?name=\"张三\"'); // =&gt; \"www.kricsleo.com?name=%22%E5%BC%A0%E4%B8%89%22\"encodeURIComponent('www.kricsleo.com?name=\"张三\"') // =&gt; \"www.kricsleo.com%3Fname%3D%22%E5%BC%A0%E4%B8%89%22\" 我们也可以自己用js来使用Unicode和UTF-8之间的相互转换 /** * 将字符串格式化为UTF8编码的字节 */const toUTF8 = function (str, isGetBytes) &#123; var back = []; var byteSize = 0; for (var i = 0; i &lt; str.length; i++) &#123; var code = str.charCodeAt(i); if (0x00 &lt;= code &amp;&amp; code &lt;= 0x7f) &#123; byteSize += 1; back.push(code); &#125; else if (0x80 &lt;= code &amp;&amp; code &lt;= 0x7ff) &#123; byteSize += 2; back.push((192 | (31 &amp; (code &gt;&gt; 6)))); back.push((128 | (63 &amp; code))) &#125; else if ((0x800 &lt;= code &amp;&amp; code &lt;= 0xd7ff) || (0xe000 &lt;= code &amp;&amp; code &lt;= 0xffff)) &#123; byteSize += 3; back.push((224 | (15 &amp; (code &gt;&gt; 12)))); back.push((128 | (63 &amp; (code &gt;&gt; 6)))); back.push((128 | (63 &amp; code))) &#125; &#125; for (i = 0; i &lt; back.length; i++) &#123; back[i] &amp;= 0xff; &#125; if (isGetBytes) &#123; return back &#125; if (byteSize &lt;= 0xff) &#123; return [0, byteSize].concat(back); &#125; else &#123; return [byteSize &gt;&gt; 8, byteSize &amp; 0xff].concat(back); &#125;&#125;toUTF8('严'); // =&gt; [0, 3, 228, 184, 165]/** * 读取UTF8编码的字节，并转为Unicode的字符串 */const fromUTF8 = function (arr) &#123; if (typeof arr === 'string') &#123; return arr; &#125; var UTF = '', _arr = arr; for (var i = 0; i &lt; _arr.length; i++) &#123; var one = _arr[i].toString(2), v = one.match(/^1+?(?=0)/); if (v &amp;&amp; one.length == 8) &#123; var bytesLength = v[0].length; var store = _arr[i].toString(2).slice(7 - bytesLength); for (var st = 1; st &lt; bytesLength; st++) &#123; store += _arr[st + i].toString(2).slice(2) &#125; UTF += String.fromCharCode(parseInt(store, 2)); i += bytesLength - 1 &#125; else &#123; UTF += String.fromCharCode(_arr[i]) &#125; &#125; return UTF&#125;fromUTF8([0, 3, 228, 184, 165]); // =&gt; '严' 参考资料: 阮一峰的博客: https//www.ruanyifeng.com/blog/2007/10/ascii_unicode_and_utf-8.html segmentfault上张亚涛的专栏: https://segmentfault.com/a/1190000005794963"},{"title":"Airbnb-JavaScript-Style-Guide","permalink":"https://kricsleo.github.io/Airbnb-JavaScript-Style-Guide/","text":"Airbnb JavaScript Style Guide 阅读笔记Airbnb的JavaScript代码风格是世界上最流行的JavaScript代码风格之一, 在阅读的时候结合我自己的使用经验记录如下重点, 日后多次阅读应该会持续更新.在线阅读地址: https://github.com/airbnb/javascript(中文翻译版: https://github.com/yuche/javascript) 对象 使用字面值创建对象 // badconst item = new Object();// goodconst item = &#123;&#125;; 使用对象方法的简写 // badconst atom = &#123; value: 1, addValue: function (value) &#123; return atom.value + value; &#125;,&#125;;// goodconst atom = &#123; value: 1, addValue(value) &#123; return atom.value + value; &#125;,&#125;; 数组 使用字面值创建数组 // badconst items = new Array();// goodconst items = []; 使用扩展运算符...复制数组 // badconst len = items.length;const itemsCopy = [];let i;for (i = 0; i &lt; len; i++) &#123; itemsCopy[i] = items[i];&#125;// goodconst itemsCopy = [...items]; 使用Array#from把类数组对象转为数组 const foo = document.querySelectorAll('.foo');const nodes = Array.from(foo); 解构 使用解构存取和使用多属性对象 // badfunction getFullName(user) &#123; const firstName = user.firstName; const lastName = user.lastName; return `$&#123;firstName&#125; $&#123;lastName&#125;`;&#125;// goodfunction getFullName(obj) &#123; const &#123; firstName, lastName &#125; = obj; return `$&#123;firstName&#125; $&#123;lastName&#125;`;&#125;// bestfunction getFullName(&#123; firstName, lastName &#125;) &#123; return `$&#123;firstName&#125; $&#123;lastName&#125;`;&#125; 对数组使用解构赋值 const arr = [1, 2, 3, 4];// badconst first = arr[0];const second = arr[1];// goodconst [first, second] = arr; 回传对个对象时, 使用对象解构, 而不是数组解构 为什么？增加属性或者改变排序不会改变调用时的位置。 // badfunction processInput(input) &#123; // then a miracle occurs return [left, right, top, bottom];&#125;// 调用时需要考虑回调数据的顺序。const [left, __, top] = processInput(input);// goodfunction processInput(input) &#123; // then a miracle occurs return &#123; left, right, top, bottom &#125;;&#125;// 调用时只选择需要的数据const &#123; left, right &#125; = processInput(input); 字符串 程序化生成字符串时使用模板字符串代替字符串连接 模板字符串更简洁, 根据可读性 // badfunction sayHi(name) &#123; return 'How are you, ' + name + '?';&#125;// badfunction sayHi(name) &#123; return ['How are you, ', name, '?'].join();&#125;// goodfunction sayHi(name) &#123; return `How are you, $&#123;name&#125;?`; 函数 使用函数声明代替函数表达式 因为函数声明是可命名的, 所以他们在调用栈中更容易\b被识别.此外函数声明会把整个函数提升(hoisted), 而函数表达式只会把函数的引用变量名提升. 这条规则是的箭头函数可以取代函数表达式. // badconst foo = function () &#123;&#125;;// goodfunction foo() &#123;&#125; 函数表达式 // 立即调用的函数表达式(IIFE)(() =&gt; &#123; console.log('welcome!')&#125;)() 不要使用arguments。可以选择rest语法...替代 // badfunction concatenateAll() &#123; const args = Array.prototype.slice.call(arguments); return args.join('');&#125;// goodfunction concatenateAll(...args) &#123; return args.join('');&#125; 直接给函数的参数指定默认值，不要使用一个变化的函数参数。 // really badfunction handleThings(opts) &#123; // 不！我们不应该改变函数参数。 // 更加糟糕: 如果参数 opts 是 false 的话，它就会被设定为一个对象。 // 但这样的写法会造成一些 Bugs。 //（译注：例如当 opts 被赋值为空字符串，opts 仍然会被下一行代码设定为一个空对象。） opts = opts || &#123;&#125;; // ...&#125;// still badfunction handleThings(opts) &#123; if (opts === void 0) &#123; opts = &#123;&#125;; &#125; // ...&#125;// goodfunction handleThings(opts = &#123;&#125;) &#123; // ...&#125; 构造器 总是使用class, 避免使用prototype 因为class语法更易读 // badfunction Queen(contents = []) &#123; this._quene = [...contents];&#125;Quene.prototype.pop = function() &#123; const value = this._quene[0]; this._quene.splice(0, 1); return value;&#125;// goodclass Queen &#123; constructor(contents = []) &#123; this._quene = [...contents]; &#125; pop() &#123; const value = this._quene[0]; this._quene.splice(0, 1); return value; &#125;&#125; Iterators and Generators 不要使用iterators, 使用高阶函数如map或者reduce来代替for-ofconst numbers = [1, 2, 3, 4, 5];// badlet sum = 0;for (let num of numbers) &#123; sum += num;&#125;sum === 15;// goodlet sum = 0;numbers.forEach((num) =&gt; sum += num);sum === 15// best (use the functional force)const sum = numbers.reduce((total, num) =&gt; total += num, 0)sum === 15 比较运算符和等号条件表达式例如 if 语句通过抽象方法ToBoolean强制计算它们的表达式并且总是遵守下面的规则： 对象 被计算为 true Undefined 被计算为 false Null 被计算为 false 布尔值 被计算为 布尔的值 数字 如果是 +0、-0、或 NaN 被计算为 false, 否则为 true 字符串 如果是空字符串 ‘’ 被计算为 false，否则为 true注释 给注释增加 FIXME 或 TODO 的前缀可以帮助其他开发者快速了解这是一个需要复查的问题，或是给需要实现的功能提供一个解决方式。这将有别于常见的注释，因为它们是可操作的。使用 FIXME – need to figure this out 或者 TODO – need to implement。class Calculator &#123; constructor() &#123; // FIXME: shouldn't use a global here total = 0; &#125;&#125;class Calculator &#123; constructor() &#123; // TODO: total should be configurable by an options param this.total = 0; &#125;&#125; 空白 使用2个空格作为缩进。 在文件末尾插入一个空行。逗号 增加结尾的逗号: 需要。 JavaScript支持这种做法,并且会自动处理结尾多余的逗号, 好处是会让git diff更干净, 新增字段更方便.另外，像 babel 这样的转译器会移除结尾多余的逗号，也就是说你不必担心老旧浏览器的尾逗号问题。 // bad - git diff without trailing commaconst hero = &#123; firstName: 'Florence',- lastName: 'Nightingale'+ lastName: 'Nightingale',+ inventorOf: ['coxcomb graph', 'modern nursing']&#125;// good - git diff with trailing commaconst hero = &#123; firstName: 'Florence', lastName: 'Nightingale',+ inventorOf: ['coxcomb chart', 'modern nursing'],&#125;// badconst hero = &#123; firstName: 'Dana', lastName: 'Scully'&#125;;const heroes = [ 'Batman', 'Superman'];// goodconst hero = &#123; firstName: 'Dana', lastName: 'Scully',&#125;;const heroes = [ 'Batman', 'Superman',]; 类型转换 字符串 // =&gt; this.reviewScore = 9;// badconst totalScore = this.reviewScore + '';// goodconst totalScore = String(this.reviewScore); 如果因为某些原因 parseInt 成为你所做的事的瓶颈而需要使用位操作解决性能问题时，留个注释说清楚原因和你的目的。 // good/** * 使用 parseInt 导致我的程序变慢， * 改成使用位操作转换数字快多了。 */const val = inputValue &gt;&gt; 0; 命名规则 别保存this的引用。使用箭头函数或Function#bind。 // badfunction foo() &#123; const self = this; return function() &#123; console.log(self); &#125;;&#125;// badfunction foo() &#123; const that = this; return function() &#123; console.log(that); &#125;;&#125;// goodfunction foo() &#123; return () =&gt; &#123; console.log(this); &#125;;&#125; 如果你的文件只输出一个类，那你的文件名必须和类名完全保持一致。 // file contentsclass CheckBox &#123; // ...&#125;export default CheckBox;// in some other file// badimport CheckBox from './checkBox';// badimport CheckBox from './check_box';// goodimport CheckBox from './CheckBox'; 当你导出默认的函数时使用驼峰式命名。你的文件名必须和函数名完全保持一致。 function makeStyleGuide() &#123;&#125;export default makeStyleGuide; 当你导出单例、函数库、空对象时使用帕斯卡式命名。 const AirbnbStyleGuide = &#123; es6: &#123; &#125;&#125;;export default AirbnbStyleGuide; 事件 当给事件附加数据时（无论是 DOM 事件还是私有事件），传入一个哈希而不是原始值。这样可以让后面的贡献者增加更多数据到事件数据而无需找出并更新事件的每一个处理器。// bad$(this).trigger('listingUpdated', listing.id);...$(this).on('listingUpdated', function(e, listingId) &#123; // do something with listingId&#125;);// good$(this).trigger('listingUpdated', &#123; listingId : listing.id &#125;);...$(this).on('listingUpdated', function(e, data) &#123; // do something with data.listingId&#125;);"},{"title":"Base64-md5","permalink":"https://kricsleo.github.io/base64-md5/","text":"Base64编码与md5摘要算法探究及日常应用Base64编码和md5摘要算法我们经常听到,本文主要对着两者算法做一个简单的了解探究 Base64Base64是一种基于64个可打印字符来表示二进制数据的表示方法,常用于在通常处理文本数据的场合，表示、传输、存储一些二进制数据，包括MIME的电子邮件及XML的一些复杂数据。 Base64来源Base64来源于电子邮件的发展,早期的电子邮件是不支持二进制文件(例如图片)的,并且邮件中也不支持非英语字符,邮件也不能有附件,再后来的发展中工程师对电子邮件的技术规范就行了扩充,也就产生了常说的MIME,全称是全”Multipurpose Internet Mail Extensions”，中译为”多用途互联网邮件扩展”,它包括了多项技术规范.一封传统的电子邮件格式如下:From: &quot;Tommy Lee&quot; &lt;lee@example.com&gt;To: &quot;Jack Zhang&quot; &lt;zhang@example.com&gt;Subject: TestDate: Wed, 17 May 2000 19:08:29 -0400Message-ID: &lt;NDBBIAKOPKHFGPLCODIGIEKBCHAA.lee@example.com&gt;Hello World. 它包含两个部分,第一部分是信封,里面包含发件人,收件人,邮件主题,邮件发送时间,邮件的唯一标识Message-ID,第二部分是正文,也就是邮件的内容,第一部分和第二部分之间用一个空行隔开, MIME对传统邮件的扩展体现在在信封里面新增了三行语句 MIME-Version: 1.0这行语句标志着该邮件使用了MIME规范,收信端将按照该规范进行解析邮件内容 Content-Type: text/plain; charset=”UTF-8”这行语句说明了改邮件的信息类型和编码方式 Content-Type表明信息类型，缺省值为” text/plain” 它包含了主要类型（primary type）和次要类型（subtype）两个部分，两者之间用”/“分割。主要类型有9种，分别是application、audio、example、image、message、model、multipart、text、video,每种主要类型下面又分为多种次要类型,常用的一些Content-Type类型如下: text/plain：纯文本，文件扩展名.txttext/html：HTML文本，文件扩展名.htm和.htmlimage/jpeg：jpeg格式的图片，文件扩展名.jpgimage/gif：GIF格式的图片，文件扩展名.gifaudio/x-wave：WAVE格式的音频，文件扩展名.wavaudio/mpeg：MP3格式的音频，文件扩展名.mp3video/mpeg：MPEG格式的视频，文件扩展名.mpgapplication/zip：PK-ZIP格式的压缩文件，文件扩展名.zip 如果信息的主要类型是”text”，那么还必须指明编码类型”charset”，缺省值是ASCII，其他可能值有”ISO-8859-1”、”UTF-8”、”GB2312”等等。 Content-transfer-encoding: Base64这里我们的主角就登场了,这行语句表明邮件编码转换的方式,因为现代邮件里面会有图片或者其它原始邮件不支持的内容,那么在发送的时候就需要对内容进行编码转换,将内容转换成邮件支持的ASCII字符,Content-transfer-encoding的值有5种—-“7bit”、”8bit”、”binary”、”quoted-printable”和”Base64”—-其中”7bit”是缺省值，即不用转化的ASCII字符。真正常用是”quoted-printable”和”Base64”两种. quoted-printable编码关于’quoted-printable’简单介绍一下,它主要用于ACSII文本中夹杂少量非ASCII码字符的情况，不适合于转换纯二进制文件.它规定将每一个8位的字节，转换为3个字符,规则如下: 所有可打印的ASCII码字符（十进制值从33到126）都保持原样不变，”=”（十进制值61）除外,其余的字符都要进行编码。 编码后第一个字符是”=”号，这是固定不变的; 编码后二个字符是二个十六进制数，分别代表了这个字节前四位和后四位的数值。例如ASCII码中的换页键的码值是12,那么先转成8位的二进制是00001100,再转成16进制是0C,然后再在前面加上一个’=’号,最后的编码结果是’=0C’. Base64编码首先选出一个字符集,分别是小写字母a-z、大写字母A-Z、数字0-9、符号”+”、”/“加起来是64个,另外有一个垫字符’=’,然后将其它所有不在这个字符集里面的字符都转换到到这个字符集里面去,转换规则如下: 将每三个字节作为一组，一共是24个二进制位; 再将这24个二进制位分为四组，每个组有6个二进制位; 在每组前面加两个00，扩展成32个二进制位，即四个字节; 查询字符表,找到每个字节在表中对应的符号，这就是Base64的编码值;所以分析最终的结果的话,原始的三个字节经过转换以后会变成4个字节,因此Base64编码后的文本，会比原文本大出三分之一左右。 Base64编码示例编码译文单词’six’:s i x -&lt;转为对应的ASCII值&gt;&gt;&gt; 115 105 120 -&lt;转为对应的二进制&gt;&gt; 01110011 01101001 01111000 -&lt;二进制分为四组&gt;&gt; 011100 110110 100101 111000 -&lt;每组前面添加两个0&gt;&gt; 00011100 00110110 00100101 00111000 -&lt;每组转为对应的10进制&gt;&gt; 28 54 37 56 -&lt;查询Base64字符表转为对应字符&gt;&gt; c 2 l 4则’six’编码后的结果是’c2l4’,你可以用这个工具来验证你的转码结果是否正确. 如果字节数不足三，则处理如下: 二个字节的情况：将这二个字节的一共16个二进制位，按照上面的规则，转成三组，最后一组除了前面加两个0以外，后面也要加两个0。这样得到一个三位的Base64编码，再在末尾补上一个”=”号。比如，”Ma”这个字符串是两个字节，可以转化成三组00010011、00010110、00010000以后，对应Base64值分别为T、W、E，再补上一个”=”号，因此”Ma”的Base64编码就是TWE=。 一个字节的情况：将这一个字节的8个二进制位，按照上面的规则转成二组，最后一组除了前面加二个0以外，后面再加4个0。这样得到一个二位的Base64编码，再在末尾补上两个”=”号。比如，”M”这个字母是一个字节，可以转化为二组00010011、00010000，对应的Base64值分别为T、Q，再补上二个”=”号，因此”M”的Base64编码就是’TQ==’。 再举一个中文的例子，汉字”严”如何转化成Base64编码？ 这里需要注意，汉字本身可以有多种编码，比如gb2312、utf-8、gbk等等，每一种编码的Base64对应值都不一样。下面的例子以utf-8为例。 首先，”严”的utf-8编码为E4B8A5，写成二进制就是三字节的”11100100 10111000 10100101”。将这个24位的二进制字符串，按照第3节中的规则，转换成四组一共32位的二进制值”00111001 00001011 00100010 00100101”，相应的十进制数为57、11、34、37，它们对应的Base64值就为5、L、i、l。 所以，汉字”严”（utf-8编码）的Base64值就是5Lil。 Base64在js中的使用Base64的js实现如下:/**** Base64 encode / decode** @author haitao.tu* @date 2010-04-26* @email tuhaitao@foxmail.com**/ function Base64() &#123; true// private propertytrue_keyStr = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=\"; true// public method for encodingtruethis.encode = function (input) &#123;truetruevar output = \"\";truetruevar chr1, chr2, chr3, enc1, enc2, enc3, enc4;truetruevar i = 0;truetrueinput = _utf8_encode(input);truetruewhile (i &lt; input.length) &#123;truetruetruechr1 = input.charCodeAt(i++);truetruetruechr2 = input.charCodeAt(i++);truetruetruechr3 = input.charCodeAt(i++);truetruetrueenc1 = chr1 &gt;&gt; 2;truetruetrueenc2 = ((chr1 &amp; 3) &lt;&lt; 4) | (chr2 &gt;&gt; 4);truetruetrueenc3 = ((chr2 &amp; 15) &lt;&lt; 2) | (chr3 &gt;&gt; 6);truetruetrueenc4 = chr3 &amp; 63;truetruetrueif (isNaN(chr2)) &#123;truetruetruetrueenc3 = enc4 = 64;truetruetrue&#125; else if (isNaN(chr3)) &#123;truetruetruetrueenc4 = 64;truetruetrue&#125;truetruetrueoutput = output +truetruetrue_keyStr.charAt(enc1) + _keyStr.charAt(enc2) +truetruetrue_keyStr.charAt(enc3) + _keyStr.charAt(enc4);truetrue&#125;truetruereturn output;true&#125; true// public method for decodingtruethis.decode = function (input) &#123;truetruevar output = \"\";truetruevar chr1, chr2, chr3;truetruevar enc1, enc2, enc3, enc4;truetruevar i = 0;truetrueinput = input.replace(/[^A-Za-z0-9\\+\\/\\=]/g, \"\");truetruewhile (i &lt; input.length) &#123;truetruetrueenc1 = _keyStr.indexOf(input.charAt(i++));truetruetrueenc2 = _keyStr.indexOf(input.charAt(i++));truetruetrueenc3 = _keyStr.indexOf(input.charAt(i++));truetruetrueenc4 = _keyStr.indexOf(input.charAt(i++));truetruetruechr1 = (enc1 &lt;&lt; 2) | (enc2 &gt;&gt; 4);truetruetruechr2 = ((enc2 &amp; 15) &lt;&lt; 4) | (enc3 &gt;&gt; 2);truetruetruechr3 = ((enc3 &amp; 3) &lt;&lt; 6) | enc4;truetruetrueoutput = output + String.fromCharCode(chr1);truetruetrueif (enc3 != 64) &#123;truetruetruetrueoutput = output + String.fromCharCode(chr2);truetruetrue&#125;truetruetrueif (enc4 != 64) &#123;truetruetruetrueoutput = output + String.fromCharCode(chr3);truetruetrue&#125;truetrue&#125;truetrueoutput = _utf8_decode(output);truetruereturn output;true&#125; true// private method for UTF-8 encodingtrue_utf8_encode = function (string) &#123;truetruestring = string.replace(/\\r\\n/g,\"\\n\");truetruevar utftext = \"\";truetruefor (var n = 0; n &lt; string.length; n++) &#123;truetruetruevar c = string.charCodeAt(n);truetruetrueif (c &lt; 128) &#123;truetruetruetrueutftext += String.fromCharCode(c);truetruetrue&#125; else if((c &gt; 127) &amp;&amp; (c &lt; 2048)) &#123;truetruetruetrueutftext += String.fromCharCode((c &gt;&gt; 6) | 192);truetruetruetrueutftext += String.fromCharCode((c &amp; 63) | 128);truetruetrue&#125; else &#123;truetruetruetrueutftext += String.fromCharCode((c &gt;&gt; 12) | 224);truetruetruetrueutftext += String.fromCharCode(((c &gt;&gt; 6) &amp; 63) | 128);truetruetruetrueutftext += String.fromCharCode((c &amp; 63) | 128);truetruetrue&#125; truetrue&#125;truetruereturn utftext;true&#125; true// private method for UTF-8 decodingtrue_utf8_decode = function (utftext) &#123;truetruevar string = \"\";truetruevar i = 0;truetruevar c = c1 = c2 = 0;truetruewhile ( i &lt; utftext.length ) &#123;truetruetruec = utftext.charCodeAt(i);truetruetrueif (c &lt; 128) &#123;truetruetruetruestring += String.fromCharCode(c);truetruetruetruei++;truetruetrue&#125; else if((c &gt; 191) &amp;&amp; (c &lt; 224)) &#123;truetruetruetruec2 = utftext.charCodeAt(i+1);truetruetruetruestring += String.fromCharCode(((c &amp; 31) &lt;&lt; 6) | (c2 &amp; 63));truetruetruetruei += 2;truetruetrue&#125; else &#123;truetruetruetruec2 = utftext.charCodeAt(i+1);truetruetruetruec3 = utftext.charCodeAt(i+2);truetruetruetruestring += String.fromCharCode(((c &amp; 15) &lt;&lt; 12) | ((c2 &amp; 63) &lt;&lt; 6) | (c3 &amp; 63));truetruetruetruei += 3;truetruetrue&#125;truetrue&#125;truetruereturn string;true&#125;&#125; md5摘要算法Base64我们说的差不多了,下面说说md5.md5全称’MD5消息摘要算法’（英语：MD5 Message-Digest Algorithm）,其最明显的作用就是对一段文本或者二进制文件进行运算之后得出一个128位的值,我们通常会把计算结果转换成32个16进制的数来表示. 对文本进行运算常用于密码的加密,比如对’password2018’这个字符串进行加密之后得到’f4654d5ac34aca487f0e3cb08d769f8a’,由于md5发生碰撞的概率极低,也就是不同的文本加密后得到同样的结果的可能性微乎其微,所以一般可以认为’f4654d5ac34aca487f0e3cb08d769f8a’这样的结果就唯一标识了’password2018’这个字符串.加密容易解密难,如果你想通过’f4654d5ac34aca487f0e3cb08d769f8a’这个结果去逆向运算得到’password2018’这个原始数据几乎是不可能的,付出的成本也相当于是天价,所以我们的网站登录经常会采取用md5加密用户密码的方式来验证和存储用户账户密码. 对二进制文件的运算常用于确保文件的完整性,比如在一些正规的网站上下载东西时常常附带会有一个.md5的文件,里面的内容类似于MD5 (tanajiya.tar.gz) = 38b8c2c1093dd0fec383a9d9ac940515这样,这里面记录的一串字符就是你要下载的这个文件的md5的运算结果,因为之前说过了一个东西的md5值是唯一的,一个md5结果也同样标识着唯一的一个东西,类似于每个人都有自己独特的指纹一样,一旦这个文件被人篡改过,那么再次对这个文件计算md5就会得到与之前不一样的md5值,所以我们常常会用这个md5结果来验证确保文件的完整性. md5的js实现如下:/* * A JavaScript implementation of the RSA Data Security, Inc. MD5 Message * Digest Algorithm, as defined in RFC 1321. * Version 2.1 Copyright (C) Paul Johnston 1999 - 2002. * Other contributors: Greg Holt, Andrew Kepert, Ydnar, Lostinet * Distributed under the BSD License * See https//pajhome.org.uk/crypt/md5 for more info. *//* * Configurable variables. You may need to tweak these to be compatible with * the server-side, but the defaults work in most cases. */var hexcase = 0; /* hex output format. 0 - lowercase; 1 - uppercase */var b64pad = \"\"; /* base-64 pad character. \"=\" for strict RFC compliance */var chrsz = 8; /* bits per input character. 8 - ASCII; 16 - Unicode *//* * These are the functions you'll usually want to call * They take string arguments and return either hex or base-64 encoded strings */function hex_md5(s)&#123; return binl2hex(core_md5(str2binl(s), s.length * chrsz));&#125;function b64_md5(s)&#123; return binl2b64(core_md5(str2binl(s), s.length * chrsz));&#125;function str_md5(s)&#123; return binl2str(core_md5(str2binl(s), s.length * chrsz));&#125;function hex_hmac_md5(key, data) &#123; return binl2hex(core_hmac_md5(key, data)); &#125;function b64_hmac_md5(key, data) &#123; return binl2b64(core_hmac_md5(key, data)); &#125;function str_hmac_md5(key, data) &#123; return binl2str(core_hmac_md5(key, data)); &#125;/* * Perform a simple self-test to see if the VM is working */function md5_vm_test()&#123; return hex_md5(\"abc\") == \"900150983cd24fb0d6963f7d28e17f72\";&#125;/* * Calculate the MD5 of an array of little-endian words, and a bit length */function core_md5(x, len)&#123; /* append padding */ x[len &gt;&gt; 5] |= 0x80 &lt;&lt; ((len) % 32); x[(((len + 64) &gt;&gt;&gt; 9) &lt;&lt; 4) + 14] = len; var a = 1732584193; var b = -271733879; var c = -1732584194; var d = 271733878; for(var i = 0; i &lt; x.length; i += 16) &#123; var olda = a; var oldb = b; var oldc = c; var oldd = d; a = md5_ff(a, b, c, d, x[i+ 0], 7 , -680876936); d = md5_ff(d, a, b, c, x[i+ 1], 12, -389564586); c = md5_ff(c, d, a, b, x[i+ 2], 17, 606105819); b = md5_ff(b, c, d, a, x[i+ 3], 22, -1044525330); a = md5_ff(a, b, c, d, x[i+ 4], 7 , -176418897); d = md5_ff(d, a, b, c, x[i+ 5], 12, 1200080426); c = md5_ff(c, d, a, b, x[i+ 6], 17, -1473231341); b = md5_ff(b, c, d, a, x[i+ 7], 22, -45705983); a = md5_ff(a, b, c, d, x[i+ 8], 7 , 1770035416); d = md5_ff(d, a, b, c, x[i+ 9], 12, -1958414417); c = md5_ff(c, d, a, b, x[i+10], 17, -42063); b = md5_ff(b, c, d, a, x[i+11], 22, -1990404162); a = md5_ff(a, b, c, d, x[i+12], 7 , 1804603682); d = md5_ff(d, a, b, c, x[i+13], 12, -40341101); c = md5_ff(c, d, a, b, x[i+14], 17, -1502002290); b = md5_ff(b, c, d, a, x[i+15], 22, 1236535329); a = md5_gg(a, b, c, d, x[i+ 1], 5 , -165796510); d = md5_gg(d, a, b, c, x[i+ 6], 9 , -1069501632); c = md5_gg(c, d, a, b, x[i+11], 14, 643717713); b = md5_gg(b, c, d, a, x[i+ 0], 20, -373897302); a = md5_gg(a, b, c, d, x[i+ 5], 5 , -701558691); d = md5_gg(d, a, b, c, x[i+10], 9 , 38016083); c = md5_gg(c, d, a, b, x[i+15], 14, -660478335); b = md5_gg(b, c, d, a, x[i+ 4], 20, -405537848); a = md5_gg(a, b, c, d, x[i+ 9], 5 , 568446438); d = md5_gg(d, a, b, c, x[i+14], 9 , -1019803690); c = md5_gg(c, d, a, b, x[i+ 3], 14, -187363961); b = md5_gg(b, c, d, a, x[i+ 8], 20, 1163531501); a = md5_gg(a, b, c, d, x[i+13], 5 , -1444681467); d = md5_gg(d, a, b, c, x[i+ 2], 9 , -51403784); c = md5_gg(c, d, a, b, x[i+ 7], 14, 1735328473); b = md5_gg(b, c, d, a, x[i+12], 20, -1926607734); a = md5_hh(a, b, c, d, x[i+ 5], 4 , -378558); d = md5_hh(d, a, b, c, x[i+ 8], 11, -2022574463); c = md5_hh(c, d, a, b, x[i+11], 16, 1839030562); b = md5_hh(b, c, d, a, x[i+14], 23, -35309556); a = md5_hh(a, b, c, d, x[i+ 1], 4 , -1530992060); d = md5_hh(d, a, b, c, x[i+ 4], 11, 1272893353); c = md5_hh(c, d, a, b, x[i+ 7], 16, -155497632); b = md5_hh(b, c, d, a, x[i+10], 23, -1094730640); a = md5_hh(a, b, c, d, x[i+13], 4 , 681279174); d = md5_hh(d, a, b, c, x[i+ 0], 11, -358537222); c = md5_hh(c, d, a, b, x[i+ 3], 16, -722521979); b = md5_hh(b, c, d, a, x[i+ 6], 23, 76029189); a = md5_hh(a, b, c, d, x[i+ 9], 4 , -640364487); d = md5_hh(d, a, b, c, x[i+12], 11, -421815835); c = md5_hh(c, d, a, b, x[i+15], 16, 530742520); b = md5_hh(b, c, d, a, x[i+ 2], 23, -995338651); a = md5_ii(a, b, c, d, x[i+ 0], 6 , -198630844); d = md5_ii(d, a, b, c, x[i+ 7], 10, 1126891415); c = md5_ii(c, d, a, b, x[i+14], 15, -1416354905); b = md5_ii(b, c, d, a, x[i+ 5], 21, -57434055); a = md5_ii(a, b, c, d, x[i+12], 6 , 1700485571); d = md5_ii(d, a, b, c, x[i+ 3], 10, -1894986606); c = md5_ii(c, d, a, b, x[i+10], 15, -1051523); b = md5_ii(b, c, d, a, x[i+ 1], 21, -2054922799); a = md5_ii(a, b, c, d, x[i+ 8], 6 , 1873313359); d = md5_ii(d, a, b, c, x[i+15], 10, -30611744); c = md5_ii(c, d, a, b, x[i+ 6], 15, -1560198380); b = md5_ii(b, c, d, a, x[i+13], 21, 1309151649); a = md5_ii(a, b, c, d, x[i+ 4], 6 , -145523070); d = md5_ii(d, a, b, c, x[i+11], 10, -1120210379); c = md5_ii(c, d, a, b, x[i+ 2], 15, 718787259); b = md5_ii(b, c, d, a, x[i+ 9], 21, -343485551); a = safe_add(a, olda); b = safe_add(b, oldb); c = safe_add(c, oldc); d = safe_add(d, oldd); &#125; return Array(a, b, c, d);&#125;/* * These functions implement the four basic operations the algorithm uses. */function md5_cmn(q, a, b, x, s, t)&#123; return safe_add(bit_rol(safe_add(safe_add(a, q), safe_add(x, t)), s),b);&#125;function md5_ff(a, b, c, d, x, s, t)&#123; return md5_cmn((b &amp; c) | ((~b) &amp; d), a, b, x, s, t);&#125;function md5_gg(a, b, c, d, x, s, t)&#123; return md5_cmn((b &amp; d) | (c &amp; (~d)), a, b, x, s, t);&#125;function md5_hh(a, b, c, d, x, s, t)&#123; return md5_cmn(b ^ c ^ d, a, b, x, s, t);&#125;function md5_ii(a, b, c, d, x, s, t)&#123; return md5_cmn(c ^ (b | (~d)), a, b, x, s, t);&#125;/* * Calculate the HMAC-MD5, of a key and some data */function core_hmac_md5(key, data)&#123; var bkey = str2binl(key); if(bkey.length &gt; 16) bkey = core_md5(bkey, key.length * chrsz); var ipad = Array(16), opad = Array(16); for(var i = 0; i &lt; 16; i++) &#123; ipad[i] = bkey[i] ^ 0x36363636; opad[i] = bkey[i] ^ 0x5C5C5C5C; &#125; var hash = core_md5(ipad.concat(str2binl(data)), 512 + data.length * chrsz); return core_md5(opad.concat(hash), 512 + 128);&#125;/* * Add integers, wrapping at 2^32. This uses 16-bit operations internally * to work around bugs in some JS interpreters. */function safe_add(x, y)&#123; var lsw = (x &amp; 0xFFFF) + (y &amp; 0xFFFF); var msw = (x &gt;&gt; 16) + (y &gt;&gt; 16) + (lsw &gt;&gt; 16); return (msw &lt;&lt; 16) | (lsw &amp; 0xFFFF);&#125;/* * Bitwise rotate a 32-bit number to the left. */function bit_rol(num, cnt)&#123; return (num &lt;&lt; cnt) | (num &gt;&gt;&gt; (32 - cnt));&#125;/* * Convert a string to an array of little-endian words * If chrsz is ASCII, characters &gt;255 have their hi-byte silently ignored. */function str2binl(str)&#123; var bin = Array(); var mask = (1 &lt;&lt; chrsz) - 1; for(var i = 0; i &lt; str.length * chrsz; i += chrsz) bin[i&gt;&gt;5] |= (str.charCodeAt(i / chrsz) &amp; mask) &lt;&lt; (i%32); return bin;&#125;/* * Convert an array of little-endian words to a string */function binl2str(bin)&#123; var str = \"\"; var mask = (1 &lt;&lt; chrsz) - 1; for(var i = 0; i &lt; bin.length * 32; i += chrsz) str += String.fromCharCode((bin[i&gt;&gt;5] &gt;&gt;&gt; (i % 32)) &amp; mask); return str;&#125;/* * Convert an array of little-endian words to a hex string. */function binl2hex(binarray)&#123; var hex_tab = hexcase ? \"0123456789ABCDEF\" : \"0123456789abcdef\"; var str = \"\"; for(var i = 0; i &lt; binarray.length * 4; i++) &#123; str += hex_tab.charAt((binarray[i&gt;&gt;2] &gt;&gt; ((i%4)*8+4)) &amp; 0xF) + hex_tab.charAt((binarray[i&gt;&gt;2] &gt;&gt; ((i%4)*8 )) &amp; 0xF); &#125; return str;&#125;/* * Convert an array of little-endian words to a base-64 string */function binl2b64(binarray)&#123; var tab = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/\"; var str = \"\"; for(var i = 0; i &lt; binarray.length * 4; i += 3) &#123; var triplet = (((binarray[i &gt;&gt; 2] &gt;&gt; 8 * ( i %4)) &amp; 0xFF) &lt;&lt; 16) | (((binarray[i+1 &gt;&gt; 2] &gt;&gt; 8 * ((i+1)%4)) &amp; 0xFF) &lt;&lt; 8 ) | ((binarray[i+2 &gt;&gt; 2] &gt;&gt; 8 * ((i+2)%4)) &amp; 0xFF); for(var j = 0; j &lt; 4; j++) &#123; if(i * 8 + j * 6 &gt; binarray.length * 32) str += b64pad; else str += tab.charAt((triplet &gt;&gt; 6*(3-j)) &amp; 0x3F); &#125; &#125; return str;&#125;"},{"title":"IIFE","permalink":"https://kricsleo.github.io/IIFE/","text":"[增][转][译]JavaScript：立即执行函数表达式（IIFE） 原文: https//benalman.com/news/2010/11/immediately-invoked-function-expression/#iife译文: https://segmentfault.com/a/1190000003985390 by Murphywuwu 可能你并没有注意到，我是一个对于专业术语有一点坚持细节人。所有，当我听到流行的但是还存在误解的术语“自执行匿名函数”多次时，我最终决定将我的想法写进这篇文章里。 除了提供关于这种模式事实上是如何工作的一些全面的信息，更进一步的，实际上我建议我们应该知道我们应该叫它什么。而且，如果你想跳过这里，你可以直接跳到立即调用函数表达式进行阅读，但是我建议你读完整篇文章。 它是什么在 JavaScript 里，每个函数，当被调用时，都会创建一个新的执行上下文。因为在函数里定义的变量和函数是唯一在内部被访问的变量，而不是在外部被访问的变量，当调用函数时，函数提供的上下文提供了一个非常简单的方法创建私有变量。function makeCounter() &#123; var i = 0; return function()&#123; console.log(++i); &#125;; &#125;//记住：`counter`和`counter2`都有他们自己的变量 `i`var counter = makeCounter();counter();//1counter();//2var counter2 = makeCounter();counter2();//1counter2();//2i;//ReferenceError: i is not defined(它只存在于makeCounter里) 在许多情况下，你可能并不需要makeWhatever这样的函数返回多次累加值，并且可以只调用一次得到一个单一的值，在其他一些情况里，你甚至不需要明确的知道返回值。 它的核心现在，无论你定义一个函数像这样function foo(){}或者var foo = function(){}，调用时，你都需要在后面加上一对圆括号，像这样foo()。//向下面这样定义的函数可以通过在函数名后加一对括号进行调用，像这样`foo()`，//因为foo相对于函数表达式`function()&#123;/* code */&#125;`只是一个引用变量var foo = function()&#123;/* code */&#125;//那这可以说明函数表达式可以通过在其后加上一对括号自己调用自己吗？function()&#123; /* code */&#125;(); //SyntaxError: Unexpected token ( 正如你所看到的，这里捕获了一个错误。当圆括号为了调用函数出现在函数后面时，无论在全局环境或者局部环境里遇到了这样的function关键字，默认的，它会将它当作是一个函数声明，而不是函数表达式，如果你不明确的告诉圆括号它是一个表达式，它会将其当作没有名字的函数声明并且抛出一个错误，因为函数声明需要一个名字。 (个人理解: 见扩展’函数声明与函数表达式’) 问题1：这里我么可以思考一个问题，我们是不是也可以像这样直接调用函数var foo = function(){console.log(1)}()，答案是可以的。 问题2：同样的，我们还可以思考一个问题，像这样的函数声明在后面加上圆括号被直接调用，又会出现什么情况呢？请看下面的解答。 函数，圆括号，错误有趣的是，如果你为一个函数指定一个名字并在它后面放一对圆括号，同样的也会抛出错误，但这次是因为另外一个原因。 (个人理解: 见扩展’报错原因分析’) 当圆括号放在一个函数表达式后面指明了这是一个被调用的函数，而圆括号放在一个声明后面便意味着完全的和前面的函数声明分开了，此时圆括号只是一个简单的代表一个括号(用来控制运算优先的括号)。//然而函数声明语法上是无效的，它仍然是一个声明，紧跟着的圆括号是无效的，因为圆括号里需要包含表达式function foo()&#123; /* code */ &#125;();//SyntaxError: Unexpected token//现在，你把一个表达式放在圆括号里，没有抛出错误...,但是函数也并没有执行，因为：function foo()&#123;/* code */&#125;(1)//它等同于如下，一个函数声明跟着一个完全没有关系的表达式:function foo()&#123;/* code */&#125;(1); 立即执行函数表达式（IIFE）幸运的是，修正语法错误很简单。最流行的也最被接受的方法是将函数声明包裹在圆括号里来告诉语法分析器去表达一个函数表达式，因为在Javascript里，圆括号不能包含声明。因为这点，当圆括号为了包裹函数碰上了function关键词，它便知道将它作为一个函数表达式去解析而不是函数声明。注意理解这里的圆括号和上面的圆括号遇到函数时的表现是不一样的，也就是说。 当圆括号出现在匿名函数的末尾想要调用函数时，它会默认将函数当成是函数声明。 当圆括号包裹函数时，它会默认将函数作为表达式去解析，而不是函数声明。 //这两种模式都可以被用来立即调用一个函数表达式，利用函数的执行来创造私有变量(function()&#123;/* code */&#125;());//Crockford recommends this one，括号内的表达式代表函数立即调用表达式(function()&#123;/* code */&#125;)();//But this one works just as well，括号内的表达式代表函数表达式// Because the point of the parens or coercing operators is to disambiguate// between function expressions and function declarations, they can be// omitted when the parser already expects an expression (but please see the// \"important note\" below).var i = function()&#123;return 10;&#125;();true &amp;&amp; function()&#123;/*code*/&#125;();0,function()&#123;&#125;();//如果你并不关心返回值，或者让你的代码尽可能的易读，你可以通过在你的函数前面带上一个一元操作符来存储字节!function()&#123;/* code */&#125;();~function()&#123;/* code */&#125;();-function()&#123;/* code */&#125;();+function()&#123;/* code */&#125;();// Here's another variation, from @kuvos - I'm not sure of the performance// implications, if any, of using the `new` keyword, but it works.// https//twitter.com/kuvos/status/18209252090847232new function()&#123; /* code */ &#125;new function()&#123; /* code */ &#125;() // Only need parens if passing arguments 关于括号的重要笔记在一些情况下，当额外的带着歧义的括号围绕在函数表达式周围是没有必要的(因为这时候的括号已经将其作为一个表达式去表达)，但当括号用于调用函数表达式时，这仍然是一个好主意。 这样的括号指明函数表达式将会被立即调用，并且变量将会储存函数的结果，而不是函数本身。当这是一个非常长的函数表达式时，这可以节约比人阅读你代码的时间，不用滚到页面底部去看这个函数是否被调用。 作为规则，当你书写清楚明晰的代码时，有必要阻止 JavaScript 抛出错误的，同样也有必要阻止其他开发者对你抛出错误WTFError! 保存闭包的状态就像当函数通过他们的名字被调用时，参数会被传递，而当函数表达式被立即调用时，参数也会被传递。一个立即调用的函数表达式可以用来锁定值并且有效的保存此时的状态，因为任何定义在一个函数内的函数都可以使用外面函数传递进来的参数和变量(这种关系被叫做闭包)。(个人理解: 见扩展’关于闭包’)// 它的运行原理可能并不像你想的那样，因为`i`的值从来没有被锁定。// 相反的，每个链接，当被点击时（循环已经被很好的执行完毕），因此会弹出所有元素的总数，// 因为这是 `i` 此时的真实值。var elems = document.getElementsByTagName('a');for(var i = 0;i &lt; elems.length; i++ ) &#123; elems[i].addEventListener('click',function(e)&#123; e.preventDefault(); alert('I am link #' + i) &#125;,false);&#125;// 而像下面这样改写，便可以了，因为在IIFE里，`i`值被锁定在了`lockedInIndex`里。// 在循环结束执行时，尽管`i`值的数值是所有元素的总和，但每一次函数表达式被调用时，// IIFE 里的 `lockedInIndex` 值都是`i`传给它的值,所以当链接被点击时，正确的值被弹出。var elems = document.getElementsByTagName('a');for(var i = 0;i &lt; elems.length;i++) &#123; (function(lockedInIndex)&#123; elems[i].addEventListener('click',function(e)&#123; e.preventDefault(); alert('I am link #' + lockedInIndex); &#125;,false) &#125;)(i);&#125;//你同样可以像下面这样使用IIFE，仅仅只用括号包括点击处理函数，并不包含整个`addEventListener`。//无论用哪种方式，这两个例子都可以用IIFE将值锁定，不过我发现前面一个例子更可读var elems = document.getElementsByTagName( 'a' );for ( var i = 0; i &lt; elems.length; i++ ) &#123; elems[ i ].addEventListener( 'click', (function( lockedInIndex )&#123; return function(e)&#123; e.preventDefault(); alert( 'I am link #' + lockedInIndex ); &#125;; &#125;)( i ),false); &#125; 记住，在这最后两个例子里，lockedInIndex可以没有任何问题的访问i,但是作为函数的参数使用一个不同的命名标识符可以使概念更加容易的被解释。 立即执行函数一个最显著的优势是就算它没有命名或者说是匿名，函数表达式也可以在没有使用标识符的情况下被立即调用，一个闭包也可以在没有当前变量污染的情况下被使用。 自执行匿名函数(“Self-executing anonymous function”)有什么问题呢？你看到它已经被提到好几次了，但是它仍然不是那么清楚的被解释，我提议将术语改成”Immediately-Invoked Function Expression”，或者，IIFE，如果你喜欢缩写的话。 什么是Immediately-Invoked Function Expression呢？它使一个被立即调用的函数表达式。就像引导你去调用的函数表达式。 我想Javascript社区的成员应该可以在他们的文章里或者陈述里接受术语，Immediately-Invoked Function Expression和 IIFE，因为我感觉这样更容易让这个概念被理解，并且术语”self-executing anonymous function”真的也不够精确。//下面是个自执行函数，递归的调用自己本身function foo()&#123;foo();&#125;;//这是一个自执行匿名函数。因为它没有标识符，它必须是使用`arguments.callee`属性来调用它自己var foo = function()&#123;arguments.callee();&#125;;//这也许算是一个自执行匿名函数，但是仅仅当`foo`标识符作为它的引用时，如果你将它换成用`foo`来调用同样可行var foo = function()&#123;foo();&#125;;//有些人像这样叫'self-executing anonymous function'下面的函数,即使它不是自执行的，因为它并没有调用它自己。然后，它只是被立即调用了而已。(function()&#123; /*code*/ &#125;());//为函数表达式增加标识符(也就是说创造一个命名函数)对我们的调试会有很大帮助。一旦命名，函数将不再匿名。(function foo()&#123;/* code */&#125;());//IIFEs同样也可以自执行，尽管，也许他不是最有用的模式(function()&#123;arguments.callee();&#125;())(function foo()&#123;foo();&#125;())// One last thing to note: this will cause an error in BlackBerry 5, because// inside a named function expression, that name is undefined. Awesome, huh?(function foo()&#123; foo(); &#125;()); 希望上面的例子可以让你更加清楚的知道术语’self-executing’是有一些误导的，因为他并不是执行自己的函数，尽管函数已经被执行。同样的，匿名函数也没用必要特别指出，因为，Immediately Invoked Function Expression，既可以是命名函数也可以匿名函数。 最后：模块模式当我调用函数表达式时，如果我不至少一次的提醒我自己关于模块模式，我便很可能会忽略它。如果你并不熟悉JavaScript里的模块模式，它和我下面的例子很像，但是返回值用对象代替了函数。var counter = (function()&#123; var i = 0; return &#123; get: function()&#123; return i; &#125;, set: function(val)&#123; i = val; &#125;, increment: function()&#123; return ++i; &#125; &#125; &#125;()); counter.get();//0 counter.set(3); counter.increment();//4 counter.increment();//5 conuter.i;//undefined (`i` is not a property of the returned object) i;//ReferenceError: i is not defined (it only exists inside the closure) 模块模式方法不仅相当的厉害而且简单。非常少的代码，你可以有效的利用与方法和属性相关的命名，在一个对象里，组织全部的模块代码即最小化了全局变量的污染也创造了使用变量。 扩展补充以下内容为我个人对原文及译文的扩展分析 1. 函数声明与函数表达式关于这两者的定义你可以参看MDN的说明文档:函数表达式和函数声明共同点: 两者都可以用function关键字来创建一个函数，用法也很类似，例如// 函数声明function foo() &#123;console.log(1)&#125;//函数表达式,这样生成的是一个具名函数,叫`bar`var foo = function bar()&#123;console.log(1)&#125;//或者函数表达式也可以这样写,这样生成的是一个匿名函数,`foo`只是这个匿名函数的引用var foo = function ()&#123;console.log(1)&#125; 可以看出我们使用函数声明和函数表达式都可以用来创建一个实现某些功能的函数不同点: 从上面的例子我们可以看出函数声明只有一种写法,你必须给出函数的名字才行,如foo;而函数表达式则有两种写法,第一种是生成命名函数叫bar,后一种是生成匿名函数,注意函数表达式中的foo并不是函数名,它只是函数的一个引用而已,代表你可以使用foo来间接的调用真正的函数; 函数声明存在提升,而函数表达式不存在提升,这意味着如果你是用函数声明的方法创建一个函数,那么你可以在定义这个函数之前就去使用它;但是如果你是用函数表达式的方法来创建一个函数,那么你就必须要在函数被创建了以后才可以去使用这个函数,例如: console.log(foo); // ƒ foo()&#123;console.log(1)&#125;function foo()&#123;console.log(1)&#125;consol.log(foo2); // Uncaught ReferenceError: consol is not definedvar foo2 = function bar()&#123;console.log(1)&#125; 你也可以参考这里给出的例子 额外的一点是我们经常使用函数表达式的方式来创建匿名函数,进而创建IIFE,这一点就跟本文主要内容联系起来了; 还有一个区别是有条件的创建函数,当函数声明出现在非功能模块（比如 if）中时,虽然官方是禁止这样做的,但是实际上浏览器都支持这种做法,但是各个浏览器的处理方式有不同,这一点兼容性问题实在很头疼,所以我们不应该在生成环境代码中使用这种方式，应该使用函数表达式来代替。 2. 报错原因function (){console.log(1)}()报错出现在第一个括号，因为声明一个函数需要名字，这里声明没有给出名字，所以直接报错，走不到第二个括号，但是function foo(){console.log(1)}()报错出现在第二括号，因为这里声明函数是正确的，当处理到第二个括号时，发现第二个括号内没有任何东西，这是不允许的,所以报错,理由参见文章中注释处 3. 关于闭包在ES6之前只存在两种作用域,一是全局作用域,此作用域当浏览器打开一个页面时就会被创建,你可以通过window对象来访问这个全局作用域中的成员,另外一个就是函数作用域,当js引擎执行一个函数时就会为这个函数创建一个属于该函数的作用域,(在ES6中引入了新的作用域:块级作用域,使用let标识符来生成一个只在块级范围内可访问的变量,关于let的特性你可以参见这里ECMAScript 6 入门).function foo() &#123; let i = 1; return function log() &#123; console.log(++i) &#125;&#125;let logger = foo();logger(); // 2logger(); // 3 理解闭包必须先理解js的函数作用域,之前说过了每次执行一个函数时就会为这个函数创建一个属于它自己的函数作用域,一旦这个函数运行完毕,那么它的作用域就会被销毁,其中的保存的信息一般也会被销毁,但是,这是一般的情况,那么什么是不一般的情况呢? 这时我们就要利用浏览器销毁变量及作用域的特性来搞事了,浏览器的垃圾回收机制(有两种垃圾回收机制,这里以最常用的标记清除法为例)会定时的检查变量是否被引用,也就是是否有指针指向该数据的存储区域,如果有,那么说明有人可能要使用该数据,则不能销毁该区域,如果没有,说明没人再能够访问这个数据了,那么就可以放心的去销毁该区域来回收内存. 而闭包正好利用了这个特性,例如上面的例子中,函数foo每次执行时会返回一个新函数叫做log,log函数内部需要访问它外面的变量i才能正常工作,返回的新函数被赋给了变量logger,那么这里的指向关系是logger -&gt; log -&gt; i,那么在之后的js执行过程中,由于外部的变量logger通过一系列的指向,最终时能够访问的最开始的那个变量i的,那么按照垃圾回收机制,函数foo的作用域将一直不能够被销毁,因为它内部的变量i还有人用着呢!并且我们发现类似i这样的变量能够保存很重要的一些信息,比如函数被调用的次数等等,我们就可以用来计数或者其它你能发挥创造力的用途. 关于缺点的话也是很明显的,因为闭包内的变量一直将被保留着,如果我们创建大量这样的变量或者大量的闭包,那么浏览器可用内存就会越来越小造成卡顿,应该考虑情况适当使用."},{"title":"ssh-git","permalink":"https://kricsleo.github.io/ssh-git/","text":"github的https和ssh连接方式探究在本机连接github仓库提交代码时有两种可选方法，一种是使用github账号的用户名和密码的认证方式通过https连接，另一种是使用ssh-key的认证方式通过ssh连接，本文主要研究这两种方式的工作过程以及可能会扩展探究一些相关的知识。 ssh1995年芬兰赫尔辛基理工大学的塔图·于勒宁编写了secure shell, 简称SSH, 在这之前已经有不安全的shell, 但是SSH的提出保证了在非安全网络中可以加密完整可靠的传输数据, 要注意的是SSH只是一种通信协议, 存在则多种实现, 下面使用的是其中应用最广泛其中之一的开源实现OpenSSH.SSH基于公钥和私钥形式的非对称加密实现身份验证, 其默认的通信端口是22, 在登录验证时有两种方式: 1.密码认证;2.公钥认证. 密码认证1.用户使用SSH向远程主机发起连接请求; 2.远程主机收到请求后把自己的公钥发给用户; 3.用户使用公钥对自己的登录密码进行加密, 然后发送给远程主机; 4.远程主机使用自己的密钥对发来的加密信息进行解密, 然后验证解密出来的用户密码是否正确, 如果密码正确则允许用户连接, 登录成功, 然后用户会把远程主机的公钥加入到自己本地的$HOME/.ssh/known_hosts中.仔细分析这个过程我们会发现一个漏洞, 假如我是个黑客, 我出现在了用户和服务器中间的位置, 当在上面第二步的过程时我把我自己的公钥发送给用户, 然后用户就会用我的公钥加密他的密码然后发送给我, 这样我再用我的私钥来解密消息, 就可以获得用户的明文密码了, 这其实就是著名的中间人攻击Main-in-the-middle attack(MITM). 如何应对中间人攻击可以参加下面. 密钥认证密钥认证比密码认证安全一些, 因为不涉及用户密码的传输过程. 过程大致如下: 1.用户生成自己的一对公钥和密钥, 然后将公钥存储在远程主机上; 2.用户登录的时候向远程主机发送用私钥签名的包含用户名和公钥等信息; 2.远程主机收到请求后检查自己的$HOME/.ssh/authorized_keys中是否有用户发送的消息中的公钥信息, 如果有则证明该消息的公钥信息合法, 然后就会使用该公钥解密消息. 中间人攻击那么SSH如何应对之前提到的中间人攻击呢?在我们第一次连接一个远程主机例如ssh user@host连接时, 我们会收到如下提示信息: The authenticity of host ‘host (12.18.429.21)’ can’t be established.RSA key fingerprint is 98:2e:d7:e0:de:9f:ac:67:28:c2:42:2d:37:16:58:4d.Are you sure you want to continue connecting (yes/no)? 这就是在提示我们是第一次连接这个主机, 然后消息里面给出了这个主机的公钥的md5摘要信息98:2e:d7:e0:de:9f:ac:67:28:c2:42:2d:37:16:58:4d, 我们可以通过确认这个摘要值是不是我们想要连接的主机的, 如果是就输入yes回车确认连接, 并且会自动把这个主机加入到我们的本地known hosts（已知主机）名单里面, 以后都不再提示.因为中间人攻击核心就是使用假的公钥来替代真正的远程主机的公钥, 那么可以通过如下两种解决方案来应对: 远程主机把自己的公钥拿到CA处做认证，申请一个数字证书有关数字证书和数字签名的区别可以查看这里, 以后只要确认这个证书是正规可信的, 那就可以对应的信任该公钥 远程主机把自己公钥的指纹信息公布出来, 让大家自己来查看对比比如放在自己的网站上面供想要连接的人执行对比查阅通过上面两种做法都可以是的用户确认自己当前加密信息所使用的公钥确定是正确的远程主机的公钥, 而不是中间人的公钥关于SSH, 你也可以参考这里或者阮一峰的博客 git的两种通信协议实际上git可以使用四种通信协议:本地传输，SSH协议，Git协议和HTTP/S协议, 我们这里只讨论其中的SSH协议和HTTP/S协议.使用中最明显的区别是SSH协议只能操作我们有管理权限的项目, 但是HTTP/S协议允许我们clone没有管理权限的项目(不能修改, 只能clone查看).一般我们使用SSH协议比较多, 因为服务器一般是linux系统的, 它内置了SSH, 使用方便, 而且SSH也更安全. 首先在本机下载安装Git，一路点next默认安装即可; 配置个人信息使用git提交更改的时候会为本次提交附上提交人的\b一些信息，比如提交人的用户名及邮箱信息，我们可以使用git提供的配置功能来提前配置好这些信息，使用如下： git config --global user.name \"John Doe\"git config --global user.email \"johndoe@example.com\"# 参数说明：# git config: 表示使用git的配置工具# --global: 表示配置全局的信息，你也可以在某个项目下面单独配置这个信息，只需要去掉'--global'即可，# &lt;- 这样不同的项目就会有不同提交人信息# user.name / user.email: 后面跟上你自己的用户名和邮箱信息即可# 之后我们可以使用如下命令来查看我们配置的信息#git config user.name#git config user.email 按照下面步骤尝试clone一个github上的项目到本地 使用https协议以我的博客所使用hexo的materialFlow主题项目为例(这个项目我没有管理权限)，一行命令git clone https://github.com/stkevintan/hexo-theme-material-flow.git即可clone到本地, 因为这个项目我没有权限, 如果我是用SSH协议方式那么就会报错, 见下面.在修改了代码以后想要提交git push的时候会提示我们输入用户名和密码, 这里就涉及到新版智能HTTP/S协议(Git1.6.6之后引入), 你可参考这里, 在弹出的一个窗口输入用户名和密码, 之后你再提交的时候不会要求输入用户名和密码, 如果你使用的时候不是这样(Git版本太低或者服务器不支持智能HTTP/S协议), 那么可以参考这里配置https协议下的认证, 这样就不用每次提交的时候都要求输入用户名和密码. 使用ssh协议此时你就无法直接使用git clone git@github.com:stkevintan/hexo-theme-material-flow.git命令来clone上面那个项目到本地，会产生如下错误提示： fatal: Could not read from remote repository.Please make sure you have the correct access rights and the repository exists. 因为ssh的方式是需要进行认证的，你必须是这个项目的所有者或者管理者，才能有权限去使用ssh方式clone该项目，而上面的https方式则允许任何一个人在不需要验证的情况下去clone项目. 那么接下来看一下对于一个我们有管理权限的仓库应该如何使用ssh方式去clone到本地 ssh方式是基于不对称性加密来通信的，你需要使用不对称性算法来生成一对密钥，然后将私钥放置在你本机上，将公钥放置在github服务器上，之后在进行ssh通信时将会使用这对秘钥来完成认证登陆及加密和解密信息，在window上和mac上我们都可以使用ssh-keygen这个命令行工具来生成我们需要的密钥，这是我们想要使用ssh通信的第一步 生成一对密钥打开你的命令行（window下使用cmd.exe，mac下使用terminal.app），然后按照\b如下命令来生成密钥 ssh-keygen -t rsa -b 4096 -C \"your_email@example.com\"# 参数说明： # ssh-keygen: 表示将要使用ssh-keygen这个工具来生成密钥# -t: 指定要生成的密钥类型，有rsa1(SSH1),dsa(SSH2),ecdsa(SSH2),rsa(SSH2)等类型，较为常用的是rsa类型，此处指定为rsa类型# -b: 指定要生成的密钥长度 (单位:bit)，对于RSA类型的密钥，最小长度768bits,默认长度为2048bits。DSA密钥必须是1024bits，此处指定为4096bits# -C: 制定要生成的密钥的注释，这个可以自己随意填写，就相当于给这个密钥留个名，好分辨，比如此处可以用注册github的邮箱号 之后会出现如下提示内容： Generating public/private rsa key pair.Enter file in which to save the key (C:/Users/xxxxx/.ssh/id_rsa): 意思是让你输入这个密钥文件的文件名，一般情况保存默认就可以，直接回车确认。(如果你有多个git的账号需要配置，比如你自己在github上有账号需要提交代码，同时自己在公司也有git的账号，有时候需要提交代码到公司的仓库里，那么这时候你就需要额外的配置来保证提交的时候不会冲突，详见下面)然后会出现下一个提示内容： Enter passphrase (empty for no passphrase): 意思是要不要对私钥设置口令（passphrase），如果担心私钥的安全，你可以设置一个，这里一般不设置，直接回车确认即可，最后会出现类似如下的提示内容： +—[RSA 4096]—-+| o+o .. .o || oo… o … = ||+ +.+ o.o.o.+ o ||oB =.o..E.o* o ||o = o.o Soo+= || . o .+++ . || o.o || .. || .. |+—-[SHA256]—–+ 那\b么恭喜你，你已经生成了一对密钥文件，\b他们存储在C:/Users/xxxxx/.ssh/（windows）或者~/.ssh（mac）目录下，默认的文件是id_rsa（私钥文件名）和id_rsa.pub（公钥文件名），你可以去打开查看一下里面的内容。 部署密钥之前说过了你需要将私钥保存在本机，公钥放置在服务器上，这样之后才能用这对密钥建立ssh通信，那么在github上我们按照如下做法来部署密钥 用文本编辑器打开刚才生成的公钥文件id_rsa.pub，拷贝里面的全部内容； 打开浏览器登陆你的github账户，依次打开你头像上的Settings &gt; SSH and GPG keys &gt; New SSH key; 填写相关信息，title可以类似之前生成密钥时填写的注释信息那样填写你的邮箱名，然后key里面填上刚才拷贝的公钥内容，点击Add SSH key之后输入一次你的github账户密码进行确认，然后你的公钥就被保存部署到github服务器上了； 测试连接，使用如下命令来测试是否能够通过ssh连接到github ssh git@github.com# 参数说明：# ssh: 使用ssh进行连接# git@github.com: ssh连接时需要指定登陆用户名和远程主机名，这里的git就是github的远程服务器的用户名，github.com就是远程服务器的主机名，用'@'符号连接起来 当你是第一次连接的时候会提示你如下信息： The authenticity of host ‘github.com (52.74.223.119)’ can’t be established.RSA key fingerprint is SHA256:nThbg6kXUpJWGl7E1IGOCspRomTxdCARLviKw6E5SY8.Are you sure you want to continue connecting (yes/no)? 这是因为你是第一次连接该主机，该主机不在你本机的known hosts（已知主机）名单里面，所以询问你是否要继续连接这个陌生的主机，输入yes然后回车确认即可，之后再次连接的时候就不会有这个提示信息了。这里提示信息中的RSA key fingerprint代表的是公钥的md5摘要值, 因为RSA算法生成的公钥长度很长(一般为1024位或者2018位, 可以自己在生成时指定), 这里就用了对公钥进行摘要后的比较短的值来代表公钥.如果你配置步骤没问题的话应该可以看到下面的连接上之后的欢迎信息(xxxxx代表你的github的账户名)： Warning: Permanently added ‘github.com,52.74.223.119’ (RSA) to the list of known hosts.PTY allocation request failed on channel 0Hi xxxxx! You’ve successfully authenticated, but GitHub does not provide shell access.Connection to github.com closed. 使用ssh方式clone项目之前说过了ssh方式只能操作我们有管理权限的项目，所以这里我拿自己做的一个微信小程序的虚拟车牌键盘的项目为例git clone git@github.com:kricsleo/vehicleKeyboard.git 这个时候我们就能顺利clone该项目到本机了，因为在我们上面这条命令请求数据的过程中，我们本机和github的服务器会使用我们之前生成的那对密钥来进行相互认证，从而使我们不需要手动输入github的账户名和密码信息来完成认证登陆，同时我们以后修改了项目代码在进行提交的时候也可直接进行提交等相关操作，无需再考虑登陆及连接的问题，git的使用可以参考我之前的一篇小总结 关于git使用https和ssh方式的区别你也可以查看这里 多git账户配置如果你需要生成多对密钥，比如你需要和两个不一样的服务器A和B进行ssh通信，那么这个时候你就可以生成两对密钥，一对用来和A通信，另一对用来和B通信，最常见的情况就是我们自己在github上面会有自己的github账户，自己平时会开发一些自己的项目，然后提交到github上面，在公司里面公司一般会有自己的gitlab服务器，然后给员工开通一个gitlab的账号，有关公司内部的项目就会让员工用gitlab的账户进行开发，然后提交代码到公司的gitlab上面，那么这时候我们可以按照如下的方法来配置一下，保证自己随时提交代码的时候都是能够提交到正确的地方，而不会混乱。 再生成一对密钥在上面的操作中你已经生成了一对密钥，名字叫做id_rsa和id_rsa.pub（如果你没有改名的话），这个密钥我们已经拿来和github进行通信了，此时我们要想和公司的gitlab通信就需要再生成一对密钥，为了避免这次生成的密钥覆盖我们之前的那对密钥，可以执行如下命令：ssh-keygen -t rsa -b 4096 -C \"youremail@yourcompany.com” -f ~/.ssh/id_rsa_xx# 参数说明# 这次我们生成密钥的命令只比之前多了一个参数： -f# -f: 表示将这次什么的密钥文件保存为id_rsa_xx，同样放在了之前的那个文件夹，这个文件名你可以自己随意指定，不过最好容易区分一些 后面你的操作就和之前生成密钥一样了，生成好密钥之后再看下一步 部署新生成的密钥和之前部署github密钥的步骤类似，你登录你公司的gitlab，找到添加ssh-key的地方，然后拷贝新生成的公钥id_rsa_xx.pub文件内容到gitlab里面去并且保存，这样你公司的gitlab服务器上的公钥信息就配置好了 新建配置文件因为现在我们本机上有了两对密钥，提交代码到github时需要使用之前生成的那一对，提交代码到公司的gitlab上需要我们现在刚刚生成的这一对，那么我们就要写一个简单的配置文件来告诉git该如何再提交代码时选择正确的密钥，实际上就是编写SSH的用户配置文件config。在目录~/.ssh(mac环境)或者C:/Users/xxxxx/.ssh/下新建文件config，注意没有后缀名的，然后在里面填写上如下内容： #githubHost github.com HostName github.com User git IdentityFile ~/.ssh/id_rsa#yourcompanyHost git.XXXXX.com HostName git.XXXXX.com User git IdentityFile ~/.ssh/id_rsa_XX# 参数说明，此段内容不用拷贝，是为了加以说明# Host: 别名，为了方便记忆和区分，可以任意填写# HostName： 主机名 服务器的主机名，也可以是服务器的ip地址，需要准确填写# User： 用户名，ssh登录服务器时的用户名，一般是git# IdentityFile： 密钥文件的路径，填写上你要用来和这个服务器通信使用的密钥文件的路径# PreferredAuthentications：可选值 'publickey'和'password',强制使用密钥验证或者密码认证，我这里没有要求这个，你也可以按自己需求加上 测试连接使用如下命令来分别测试能否连接到对应的服务器 # 测试连接公司ssh git@git.XXXXX.com# 测试连接githubssh git@github.com 如果能分别看到对应的欢迎信息，那么恭喜你配置正确了。 配置个人信息这次我们因为有不同的项目，提交时需要附加上的个人信息也不一样，你提交github时会用你自己的github账户名和邮箱信息，但是提交公司的gitlab时会使用公司给你的账户名和公司个人邮箱，那么我们就需要到具体的项目下面执行如下的命令：git config user.name \"yourname\"git config user.email \"youremail@XXXXX.com\"# 参数说明# 与之前我们执行的那条配置个人信息命令相比，只是少了个'--global'参数，因为我们现在不是在全局配置，而是在个别项目中单独配置 到这里为止，你的多git账户依旧配置完毕了，后面就可以和平常一样使用git来提交代码了，ssh会为你选择正确的密钥来和服务器认证和通信。"},{"title":"markdown","permalink":"https://kricsleo.github.io/markdown/","text":"markdown语法整理经常使用markdown来做笔记，这里把现在常用的语法先记录一下，万一老年人了记忆不好，也可以查一查 标题# h1......###### h6分隔符最少三个---或*** 目录(部分markdown软件不支持)[TOC] 引用&gt; quote(\b每行最后添加两个空格即表示换行) quote &gt; quote(或者采取每行前面都添加引用标志)&gt; quote&gt; quote(多行嵌套引用)&gt;&gt; quote2&gt;&gt;&gt; quote3 代码行内代码`code`行内代码多行代码，[支持\b高亮语言](https://blog.csdn.net/qq_32126633/article/details/78838494#language_key) 链接[个人博客](https://kricsleo.github.io/ 'krics的个人博客')或者[blog]: https://kricsleo.github.io/ 'krics的个人博客'[个人博客][blog] 图片![个人头像](https://kricsleo.github.io/images/avatar.jpg 'krics的个人头像')或者[avatar]: https://kricsleo.github.io/images/avatar.jpg 'krics的个人头像'![个人头像][avatar]图片带链接[![个人头像](https://kricsleo.github.io/images/avatar.jpg 'krics的个人头像')](https://kricsleo.github.io/images/avatar.jpg) 序表有序节点1. 节点1 1. 节点1.12. 节点2无序节点- 节点$ - 节点$.^- 节点# - 节点#.&amp; 任务- [ ] 未完成- [x] 已完成 表格# 附上[在线生成表格工具](https//www.tablesgenerator.com/markdown_tables)| a | b | c ||:-------:|:------------- | ----------:|| 居中 | 左对齐 | 右对齐 | 语义性*斜体* or &lt;i&gt;斜体&lt;/i&gt;**加粗** or &lt;b&gt;加粗&lt;/b&gt;***斜体加粗*** or &lt;em&gt;强调&lt;/em&gt;~~删除线~~上标&lt;sup&gt;u&lt;/sup&gt;下标&lt;sub&gt;d&lt;/sub&gt;键盘按键&lt;kbd&gt;Ctrl&lt;/kbd&gt; 格式化显示&lt;pre&gt; ...&lt;pre&gt; 公式 目前还不常用，之后补齐 脚注Markdown[^1]在页面底端注解[^1]: Markdown是一种纯文本标记语言 定义型列表Markdown: Markdown是一种纯文本标记语言 (冒号后跟一个'Tab'或者四个空格) 邮箱&lt;xxx@163.com&gt; 流程图markdown的代码绘制流程图个人感觉比较复杂，个人使用的在线绘制工具ProcessOn"},{"title":"git-workflow","permalink":"https://kricsleo.github.io/git-workflow/","text":"git的日常使用流程记录内容参考于阮一峰老师的Git使用规范流程，记录一下git的日常使用流程。 1. 新建分支开发新功能时都应该新建一个分支，在分支上开发，当功能开发完成时再合并到主分支，并销毁新建的分支。# git checkout——检出，是我们的常用命令。最为常用的两种情形是创建分支和切换分支# 先切换到主分支，获取最新代码git checkout mastergit pull# 然后新建分支，在这个分支上进行新功能开发git checkout -b myfeature 2. 提交分支新功能开发完成以后提交代码# 默认保存所有改动 --allgit add# 查看发生改动的地方git status# 提交改动，也可以跟上 --verbose，然后就可以列出diff比较的结果，并且附上本次提交信息git commit 3. 同步代码开发过程中可以经常同步主分支的最新代码，保证一直在最新的基础上进行开发# git fetch 表示取回最新代码git fetch origin# 将有更新的代码与当前分支合并# 所取回的更新，在本地主机上要用\"远程主机名/分支名\"的形式读取。比如origin主机的master，就要用origin/master读取。git merge origin/masterdfdf 4. 合并多个commit新功能开发过程中一般会多次commit，但是在功能开发完成以后需要合并到主干时，一般把之前的commit合并成一个或几个关键的commit# git rebase命令的i参数表示互动（interactive），具体如何合并请参见原文git rebase -i origin/master 5. 推送到远程仓库多个commit经过合理的处理以后就可以把当前分支推送到远程仓库了# git push命令要加上force参数，因为rebase以后，分支历史改变了，跟远程分支不一定兼容，有可能要强行推送git push --force master myfeature 6. 发出Pull Request提交到远程仓库以后，就可以发出 Pull Request 到master分支，然后请求别人进行代码review，确认可以合并到master。 参考文档: https//www.ruanyifeng.com/blog/2014/06/git_remote.html (end)"}]}